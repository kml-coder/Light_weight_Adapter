import requests
import time
import html
from bs4 import BeautifulSoup

def clean_html(html_text):
    """HTMLì—ì„œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ"""
    soup = BeautifulSoup(html_text, "html.parser")
    return soup.get_text(" ", strip=True)



def extract_text_from_paragraph(paragraph):
    if isinstance(paragraph, list):
        return "".join(seg.get("text", "") for seg in paragraph).strip()

    if isinstance(paragraph, str):
        real_html = html.unescape(paragraph)
        soup = BeautifulSoup(real_html, "html.parser")
        return soup.get_text(" ", strip=True)

    return ""


def get_naver_examples(query, max_pages=10, save_file="examples_raw.txt", save_clean="examples_clean.txt"):
    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
                      "AppleWebKit/537.36 (KHTML, like Gecko) "
                      "Chrome/123.0.0.0 Safari/537.36",
        "Referer": "https://ko.dict.naver.com/"
    }

    raw_results = []
    clean_results = []

    for page in range(1, max_pages + 1):
        url = f"https://ko.dict.naver.com/api3/koko/search?query={query}&range=example&page={page}"
        print(f"\n=== ğŸ“„ ìš”ì²­: page {page} ===")
        print(url)

        # 1. HTTP ìš”ì²­
        try:
            res = requests.get(url, headers=headers, timeout=5)
        except Exception as e:
            print(f"âŒ ìš”ì²­ ì‹¤íŒ¨: {e}")
            continue

        if res.status_code != 200:
            print(f"âŒ ìƒíƒœ ì½”ë“œ ì˜¤ë¥˜: {res.status_code}")
            continue

        # 2. JSON íŒŒì‹±
        try:
            data = res.json()
        except:
            print("âŒ JSON íŒŒì‹± ì‹¤íŒ¨ (HTMLì¼ ê°€ëŠ¥ì„±)")
            print(res.text[:300])
            continue

        # 3. ì˜ˆë¬¸ ë°ì´í„° ì¶”ì¶œ
        try:
            items = data["searchResultMap"]["searchResultListMap"]["EXAMPLE"]["items"]
        except:
            print("âš ï¸ ë°ì´í„° ì—†ìŒ â†’ ë§ˆì§€ë§‰ í˜ì´ì§€ì¼ ê°€ëŠ¥ì„±")
            break

        # 4. ì˜ˆë¬¸ ì €ì¥
        for item in items:
            html = item.get("paragraph", "")
            text = extract_text_from_paragraph(html)
            raw_results.append(text)
            clean_results.append(clean_html(text))

        print(f"âœ” í˜ì´ì§€ {page} ìˆ˜ì§‘: {len(items)}ê°œ")

        time.sleep(0.3)

    # ---------------------------
    # íŒŒì¼ë¡œ ì €ì¥
    # ---------------------------
    with open(save_file, "w", encoding="utf-8") as f:
        for line in raw_results:
            f.write(line + "\n")

    with open(save_clean, "w", encoding="utf-8") as f:
        for line in clean_results:
            f.write(line + "\n")

    print(f"\nğŸ’¾ ì €ì¥ ì™„ë£Œ:")
    print(f"- Raw HTML ì €ì¥: {save_file}")
    print(f"- Clean Text ì €ì¥: {save_clean}")
    print(f"ì´ {len(clean_results)}ê°œ ì˜ˆë¬¸")


if __name__ == "__main__":
    get_naver_examples("ì²´ë©´", max_pages=12)
