{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d157bc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/kyungmin/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/kyungmin/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84853d6",
   "metadata": {},
   "source": [
    "# Eng and Korean txt Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dc4b5c",
   "metadata": {},
   "source": [
    "## Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8b1988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Day 1: ë°ì´í„° êµ¬ì¶• ë° ì„ë² ë”© ì¶”ì¶œ ---\n",
      "\n",
      "===== BUILD_EDU DEBUG START =====\n",
      "ì´ ë¬¸ì¥ ìˆ˜: 159\n",
      "----------------------------------\n",
      "\n",
      "â–¶ [INDEX 0] í˜„ì¬ ë¬¸ì¥: CHAPTER II.\n",
      "  â†’ ì¼ë°˜ ë¬¸ì¥ â†’ EDU 1ê°œ ìƒì„±\n",
      "\n",
      "â–¶ [INDEX 1] í˜„ì¬ ë¬¸ì¥: The Pool of Tears\n",
      "  â†’ ì¼ë°˜ ë¬¸ì¥ â†’ EDU 1ê°œ ìƒì„±\n",
      "\n",
      "â–¶ [INDEX 2] í˜„ì¬ ë¬¸ì¥: â€œCuriouser and curiouser!â€\n",
      "  â†’ ì¸ìš©ë¶€ ì‹œì‘ ê°ì§€: â€œCuriouser and curiouser!â€\n",
      "  â†’ ì²« ì¸ìš©ë¬¸ ì €ì¥: ['â€œCuriouser and curiouser!â€']\n",
      "  â†’ ë‹¨ë¬¸ ì¸ìš©ë¶€ íŒì •ë¨\n",
      "    ë‹¤ìŒ ë¬¸ì¥ í™•ì¸: cried Alice\n",
      "    â†’ ê´„í˜¸ë¬¸ì¥ ì•„ë‹˜ â†’ ë‹¨ë¬¸ ì¸ìš©ë¶€ ë’¤ì— ë¬¸ì¥ 1ê°œ ìë™ í¬í•¨\n",
      "  â†’ ë‹¨ë¬¸ ì¸ìš©ë¶€ EDU í™•ì •: ['â€œCuriouser and curiouser!â€', 'cried Alice']\n",
      "\n",
      "â–¶ [INDEX 4] í˜„ì¬ ë¬¸ì¥: (she was so much surprised, that for the moment she quite forgot how to speak good English);\n",
      "  â†’ ì¼ë°˜ ë¬¸ì¥ â†’ EDU 1ê°œ ìƒì„±\n",
      "\n",
      "â–¶ [INDEX 5] í˜„ì¬ ë¬¸ì¥: â€œnow Iâ€™m opening out like the largest telescope that ever was!\n",
      "  â†’ ì¸ìš©ë¶€ ì‹œì‘ ê°ì§€: â€œnow Iâ€™m opening out like the largest telescope that ever was!\n",
      "  â†’ ì²« ì¸ìš©ë¬¸ ì €ì¥: ['â€œnow Iâ€™m opening out like the largest telescope that ever was!']\n",
      "  â†’ ì¥ë¬¸ ì¸ìš©ë¶€ ì²˜ë¦¬ ì‹œì‘\n",
      "    â†’ ë‹«í˜ ì¸ìš©ë¶€ ì¶”ê°€: Good-bye, feet!â€\n",
      "  â†’ ì¥ë¬¸ ì¸ìš©ë¶€ ì „ì²´ ë¸”ë¡: ['â€œnow Iâ€™m opening out like the largest telescope that ever was!', 'Good-bye, feet!â€']\n",
      "    â†’ EDU ê·¸ë£¹ ìƒì„±[0~2]: ['â€œnow Iâ€™m opening out like the largest telescope that ever was!', 'Good-bye, feet!â€']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[200], line 453\u001b[0m\n\u001b[1;32m    451\u001b[0m eng_paragraph \u001b[38;5;241m=\u001b[39m split_paragraphs(eng_raw)\n\u001b[1;32m    452\u001b[0m eng_sentences \u001b[38;5;241m=\u001b[39m split_sentences(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(eng_paragraph))\n\u001b[0;32m--> 453\u001b[0m eng_edu \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_edu\u001b[49m\u001b[43m(\u001b[49m\u001b[43meng_sentences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m kor_raw \u001b[38;5;241m=\u001b[39m load_and_segment_text(KOR_FILE_PATH)\n\u001b[1;32m    456\u001b[0m kor_paragraph \u001b[38;5;241m=\u001b[39m split_paragraphs(kor_raw)\n",
      "Cell \u001b[0;32mIn[200], line 239\u001b[0m, in \u001b[0;36mbuild_edu\u001b[0;34m(sentences)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# for idx, group in enumerate(edu_groups):\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;66;03m#     print(f\"  â†’ ê·¸ë£¹ {idx} ë¬¸ì¥ ë³‘í•©: {group}\")\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m#     full = \" \".join(group)\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m#     chunks = split_quote_block_into_sentences(full)\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m#     print(f\"    â†’ !/? ë¶„í•  ê²°ê³¼: {chunks}\")\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m edu_groups:\n\u001b[0;32m--> 239\u001b[0m     final_edus\u001b[38;5;241m.\u001b[39mappend(\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m())\n\u001b[1;32m    241\u001b[0m \u001b[38;5;66;03m# -----------------------\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;66;03m# Step 3: ë§ˆì§€ë§‰ EDU ë’¤ ë¬¸ì¥ 1ê°œ ìë™ í¬í•¨\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# -----------------------\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m N:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "import kss\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "\n",
    "# --- 0. ì„¤ì • ë° íŒŒì¼ ê²½ë¡œ ---\n",
    "ENG_FILE_PATH = \"eng_testp1.txt\"\n",
    "KOR_FILE_PATH = \"kor_testp1.txt\"\n",
    "OUTPUT_FILE = \"day1_aligned_data.npz\"\n",
    "EMBEDDING_DIM = 768\n",
    "LABSE = \"setu4993/LaBSE\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def save_sentences(sent_list, path):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for s in sent_list:\n",
    "            f.write(s.strip() + \"\\n\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\n{2,}', '<PARA>', text)\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = text.replace(\"<PARA>\", \"\\n\\n\")\n",
    "    return text\n",
    "# -----------------------------------------------------\n",
    "# 1. í…ìŠ¤íŠ¸ ë¡œë”©\n",
    "# -----------------------------------------------------\n",
    "def load_and_segment_text(file_path):\n",
    "    \"\"\"íŒŒì¼ì„ ì½ê³  í…ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜ (ë¬¸ì¥ ë¶„ë¦¬ëŠ” ì•„ë˜ì—ì„œ ìˆ˜í–‰).\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "        return text\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ì˜¤ë¥˜: íŒŒì¼ ì—†ìŒ â†’ {file_path}\")\n",
    "        return \"\" \n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 2. ë¬¸ì¥ ë¶„ë¦¬\n",
    "# -----------------------------------------------------\n",
    "\n",
    "\n",
    "def split_paragraphs(raw_text):\n",
    "    # ë¬¸ë‹¨ êµ¬ë¶„ (\\n\\n ì´ìƒ)\n",
    "    raw_paragraphs = re.split(r'\\n\\s*\\n+', raw_text)\n",
    "\n",
    "    # ë¬¸ë‹¨ ë‚´ë¶€ ì¤„ë°”ê¿ˆì€ ê³µë°±ìœ¼ë¡œ merge\n",
    "    paragraphs = [\n",
    "        re.sub(r'\\n+', ' ', p).strip()\n",
    "        for p in raw_paragraphs if p.strip()\n",
    "    ]\n",
    "    return paragraphs\n",
    "\n",
    "\n",
    "def split_by_punctuation(text):\n",
    "    # ë¬¸ì¥ë¶€í˜¸ ê¸°ë°˜ ë¶„ë¦¬\n",
    "    parts = re.split(r'(?<=[.!?])\\s+(?=[A-Za-z0-9â€œ\"â€˜\\'ê°€-í£])', text)\n",
    "    return parts\n",
    "\n",
    "def split_sentences(text):\n",
    "\n",
    "    # 1) Normalize spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    sentences = []\n",
    "\n",
    "    # 2) ë¨¼ì € ë”°ì˜´í‘œ ë¸”ë¡ ë¶„ë¦¬\n",
    "    quote_blocks = re.split(r'(â€œ[^â€]+â€|\"[^\"]+\")', text)\n",
    "\n",
    "    for block in quote_blocks:\n",
    "        if not block.strip():\n",
    "            continue\n",
    "\n",
    "        # 3) blockì´ ë”°ì˜´í‘œë¡œ ë‘˜ëŸ¬ì‹¸ì—¬ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë¬¸ì¥ í›„ë³´ì— ë„£ê³  ë‚´ë¶€ ì²˜ë¦¬\n",
    "        if (block.startswith(\"â€œ\") and block.endswith(\"â€\")) or \\\n",
    "           (block.startswith('\"') and block.endswith('\"')):\n",
    "            sentences.extend(split_by_punctuation(block))\n",
    "            continue\n",
    "\n",
    "        # 4) ê´„í˜¸ ë¸”ë¡ ë¶„ë¦¬\n",
    "        paren_blocks = re.split(r'(\\([^()]+\\)[.!?;,]?)', block)\n",
    "\n",
    "        for pblock in paren_blocks:\n",
    "            if not pblock.strip():\n",
    "                continue\n",
    "\n",
    "            if pblock.startswith(\"(\") and pblock.endswith(\")\"):\n",
    "                sentences.extend(split_by_punctuation(pblock))\n",
    "            else:\n",
    "                sentences.extend(split_by_punctuation(pblock))\n",
    "\n",
    "    return [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "\n",
    "def split_quote_block_into_sentences(block):\n",
    "    \"\"\"\n",
    "    ì¸ìš©ë¶€ ì•ˆì—ì„œ ! ? ê¸°ì¤€ ë¶„í• í•˜ë˜,\n",
    "    '!â€', '?â€', '.\"' ê°™ì´ ë‹«í˜ ë”°ì˜´í‘œì™€ ë¶™ì–´ìˆëŠ” ë¬¸ì¥ë¶€í˜¸ëŠ” ë¶„ë¦¬í•˜ì§€ ì•ŠëŠ”ë‹¤.\n",
    "    \"\"\"\n",
    "\n",
    "    text = block.strip()\n",
    "\n",
    "    # 1) ë³´í˜¸ íŒ¨í„´ ì¹˜í™˜\n",
    "    protect_map = {\n",
    "        '!â€': '<EXCL_QUOTE>',\n",
    "        '?â€': '<Q_QUOTE>',\n",
    "        '.\"': '<DOT_QUOTE>',\n",
    "        '.â€': '<DOT_QUOTE2>',\n",
    "    }\n",
    "    for k, v in protect_map.items():\n",
    "        text = text.replace(k, v)\n",
    "\n",
    "    # 2) ë¬¸ì¥ë¶€í˜¸ ê¸°ë°˜ ë¶„ë¦¬\n",
    "    # ë‹¨, ì¹˜í™˜ëœ íŒ¨í„´ì€ ë¶„ë¦¬ë˜ì§€ ì•ŠìŒ\n",
    "    tokens = re.split(r'([!?])', text)\n",
    "\n",
    "    sentences = []\n",
    "    curr = \"\"\n",
    "\n",
    "    for t in tokens:\n",
    "        if t in ['!', '?']:   # ë¬¸ì¥ ë\n",
    "            curr += t\n",
    "            sentences.append(curr.strip())\n",
    "            curr = \"\"\n",
    "        else:\n",
    "            curr += t\n",
    "\n",
    "    if curr.strip():\n",
    "        sentences.append(curr.strip())\n",
    "\n",
    "    # 3) íŒ¨í„´ ë³µì›\n",
    "    result = []\n",
    "    for s in sentences:\n",
    "        for k, v in protect_map.items():\n",
    "            s = s.replace(v, k)\n",
    "        result.append(s)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def build_edu(sentences):\n",
    "    \"\"\"\n",
    "    split_sentences ê²°ê³¼(ë¬¸ì¥ ë°°ì—´) â†’ EDU ë°°ì—´ë¡œ ë°”ê¾¸ëŠ” ìµœì¢… ê·œì¹™ í•¨ìˆ˜\n",
    "    (ë””ë²„ê¹… ì¶œë ¥ ê°•í™” ë²„ì „)\n",
    "    \"\"\"\n",
    "    edu_list = []\n",
    "    N = len(sentences)\n",
    "    i = 0\n",
    "\n",
    "    print(\"\\n===== BUILD_EDU DEBUG START =====\")\n",
    "    print(f\"ì´ ë¬¸ì¥ ìˆ˜: {N}\")\n",
    "    print(\"----------------------------------\")\n",
    "\n",
    "    while i < N:\n",
    "        sent = sentences[i].strip()\n",
    "        print(f\"\\nâ–¶ [INDEX {i}] í˜„ì¬ ë¬¸ì¥: {sent}\")\n",
    "\n",
    "        # -----------------------\n",
    "        # A. ì¸ìš©ë¶€ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš°\n",
    "        # -----------------------\n",
    "        if sent.startswith(\"â€œ\") or sent.startswith(\"\\\"\"):\n",
    "            print(f\"  â†’ ì¸ìš©ë¶€ ì‹œì‘ ê°ì§€: {sent}\")\n",
    "\n",
    "            quote_block = [sent]\n",
    "            i += 1\n",
    "            print(f\"  â†’ ì²« ì¸ìš©ë¬¸ ì €ì¥: {quote_block}\")\n",
    "\n",
    "            # -----------------------\n",
    "            # 1) ë‹¨ë¬¸ ì¸ìš©ë¶€ ì²˜ë¦¬\n",
    "            # -----------------------\n",
    "            if quote_block[0].rstrip().endswith(\"â€\") or quote_block[0].rstrip().endswith(\"\\\"\"):\n",
    "                print(\"  â†’ ë‹¨ë¬¸ ì¸ìš©ë¶€ íŒì •ë¨\")\n",
    "\n",
    "                if i < N:\n",
    "                    nxt = sentences[i].strip()\n",
    "                    print(f\"    ë‹¤ìŒ ë¬¸ì¥ í™•ì¸: {nxt}\")\n",
    "\n",
    "                    if not (nxt.startswith(\"(\") or nxt.startswith(\"â€œ\") or nxt.startswith(\"\\\"\")):\n",
    "                        print(\"    â†’ ê´„í˜¸ë¬¸ì¥ ì•„ë‹˜ â†’ ë‹¨ë¬¸ ì¸ìš©ë¶€ ë’¤ì— ë¬¸ì¥ 1ê°œ ìë™ í¬í•¨\")\n",
    "                        quote_block.append(nxt)\n",
    "                        i += 1\n",
    "                    else:\n",
    "                        print(\"    â†’ ê´„í˜¸ë¬¸ì¥ì´ë¼ ìë™ í¬í•¨ ìŠ¤í‚µ\")\n",
    "\n",
    "                print(f\"  â†’ ë‹¨ë¬¸ ì¸ìš©ë¶€ EDU í™•ì •: {quote_block}\")\n",
    "                edu_list.append(\" \".join(quote_block))\n",
    "                continue\n",
    "\n",
    "            # -----------------------\n",
    "            # 2) ì¥ë¬¸ ì¸ìš©ë¶€ ì²˜ë¦¬\n",
    "            # -----------------------\n",
    "            print(\"  â†’ ì¥ë¬¸ ì¸ìš©ë¶€ ì²˜ë¦¬ ì‹œì‘\")\n",
    "\n",
    "            while i < N and not (\n",
    "                sentences[i].strip().endswith(\"â€\") or sentences[i].strip().endswith(\"\\\"\")\n",
    "            ):\n",
    "                print(f\"    â†’ ì¸ìš©ë¶€ ê³„ì† ì¶”ê°€: {sentences[i].strip()}\")\n",
    "                quote_block.append(sentences[i].strip())\n",
    "                i += 1\n",
    "\n",
    "            # ë‹«í˜ ì¸ìš©ë¶€ í¬í•¨\n",
    "            if i < N:\n",
    "                print(f\"    â†’ ë‹«í˜ ì¸ìš©ë¶€ ì¶”ê°€: {sentences[i].strip()}\")\n",
    "                quote_block.append(sentences[i].strip())\n",
    "                i += 1\n",
    "\n",
    "            print(f\"  â†’ ì¥ë¬¸ ì¸ìš©ë¶€ ì „ì²´ ë¸”ë¡: {quote_block}\")\n",
    "\n",
    "            # -----------------------\n",
    "            # Step 1: 3ë¬¸ì¥ ë‹¨ìœ„ EDU ê·¸ë£¹í™”\n",
    "            # -----------------------\n",
    "            edu_groups = []\n",
    "            for k in range(0, len(quote_block), 3):\n",
    "                group = quote_block[k:k+3]\n",
    "                print(f\"    â†’ EDU ê·¸ë£¹ ìƒì„±[{k}~{k+2}]: {group}\")\n",
    "                edu_groups.append(group)\n",
    "\n",
    "            # -----------------------\n",
    "            # Step 2: ! ? ë¶„í• \n",
    "            # -----------------------\n",
    "            final_edus = []\n",
    "            for idx, group in enumerate(edu_groups):\n",
    "                print(f\"  â†’ ê·¸ë£¹ {idx} ë¬¸ì¥ ë³‘í•©: {group}\")\n",
    "                full = \" \".join(group)\n",
    "                chunks = split_quote_block_into_sentences(full)\n",
    "                print(f\"    â†’ !/? ë¶„í•  ê²°ê³¼: {chunks}\")\n",
    "\n",
    "                for c in chunks:\n",
    "                    final_edus.append(c.strip())\n",
    "\n",
    "            # -----------------------\n",
    "            # Step 3: ë§ˆì§€ë§‰ EDU ë’¤ ë¬¸ì¥ 1ê°œ ìë™ í¬í•¨\n",
    "            # -----------------------\n",
    "            if i < N:\n",
    "                nxt = sentences[i].strip()\n",
    "                print(f\"  â†’ ë§ˆì§€ë§‰ EDU ë’¤ ë¬¸ì¥ í›„ë³´: {nxt}\")\n",
    "\n",
    "                if not (nxt.startswith(\"(\") or nxt.startswith(\"â€œ\") or nxt.startswith(\"\\\"\")):\n",
    "                    print(\"    â†’ í¬í•¨ë¨\")\n",
    "                    final_edus[-1] = final_edus[-1] + \" \" + nxt\n",
    "                    i += 1\n",
    "                else:\n",
    "                    print(\"    â†’ ê´„í˜¸ë¬¸ì¥ì´ë¼ í¬í•¨ ì•ˆ í•¨\")\n",
    "\n",
    "            print(f\"  â†’ ìµœì¢… EDUë“¤ ì¶”ê°€: {final_edus}\")\n",
    "\n",
    "            edu_list.extend(final_edus)\n",
    "\n",
    "        else:\n",
    "            # -----------------------\n",
    "            # ì¼ë°˜ ë¬¸ì¥ EDU\n",
    "            # -----------------------\n",
    "            print(\"  â†’ ì¼ë°˜ ë¬¸ì¥ â†’ EDU 1ê°œ ìƒì„±\")\n",
    "            edu_list.append(sentences[i].strip())\n",
    "            i += 1\n",
    "\n",
    "    print(\"\\n===== BUILD_EDU DEBUG END =====\\n\")\n",
    "    return edu_list\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 3. ëª¨ë¸ ì„ë² ë”© ìƒì„±\n",
    "# -----------------------------------------------------\n",
    "def get_embeddings(sentences, model_name):\n",
    "    print(f\"  -> ëª¨ë¸ ë¡œë“œ: {model_name}\")\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModel.from_pretrained(model_name).to(DEVICE)\n",
    "    except Exception as e:\n",
    "        print(f\"  [ê²½ê³ ]: {model_name} ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        return np.random.rand(len(sentences), EMBEDDING_DIM).astype(np.float32)\n",
    "\n",
    "    model.eval()\n",
    "    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "\n",
    "    all_embeddings = []\n",
    "    batch_size = 32\n",
    "\n",
    "    for i in tqdm(range(0, len(sentences), batch_size), desc=f\"  -> ì„ë² ë”© ì¶”ì¶œ ({model_name})\"):\n",
    "        batch_inputs = {k: v[i:i+batch_size] for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch_inputs)\n",
    "            cls_emb = outputs.last_hidden_state[:, 0, :]\n",
    "            all_embeddings.append(cls_emb.cpu().numpy())\n",
    "\n",
    "    return np.vstack(all_embeddings)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 4. ë¬¸ì¥ ì •ë ¬ (LaBSE + Hungarian matching)\n",
    "# -----------------------------------------------------\n",
    "def align_sentences(eng_sents, kor_sents):\n",
    "    print(\"  -> LaBSE ì„ë² ë”© ì¶”ì¶œ ì‹œì‘...\")\n",
    "\n",
    "    labse_eng = get_embeddings(eng_sents, LABSE)\n",
    "    labse_kor = get_embeddings(kor_sents, LABSE)\n",
    "\n",
    "    sim_matrix = cosine_similarity(labse_eng, labse_kor)\n",
    "    cost_matrix = -sim_matrix\n",
    "\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "\n",
    "    aligned = []\n",
    "    TH = 0.7\n",
    "\n",
    "    for i, j in zip(row_ind, col_ind):\n",
    "        if sim_matrix[i, j] >= TH:\n",
    "            aligned.append({\n",
    "                \"eng\": eng_sents[i],\n",
    "                \"kor\": kor_sents[j],\n",
    "                \"sim\": sim_matrix[i, j]\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(aligned)\n",
    "\n",
    "def dp_align(eng_emb, kor_emb):\n",
    "    N = len(eng_emb)\n",
    "    M = len(kor_emb)\n",
    "\n",
    "    dp = np.zeros((N+1, M+1))\n",
    "    ptr = np.zeros((N+1, M+1, 2), dtype=int)\n",
    "\n",
    "    sim = cosine_similarity(eng_emb, kor_emb)\n",
    "\n",
    "    for i in range(1, N+1):\n",
    "        for j in range(1, M+1):\n",
    "            # 1:1 match\n",
    "            score1 = dp[i-1][j-1] + sim[i-1][j-1]\n",
    "\n",
    "            # 1:N (skip Korean)\n",
    "            score2 = dp[i][j-1] - 0.3\n",
    "\n",
    "            # N:1 (skip English)\n",
    "            score3 = dp[i-1][j] - 0.3\n",
    "\n",
    "            best = max(score1, score2, score3)\n",
    "\n",
    "            dp[i][j] = best\n",
    "\n",
    "            if best == score1:\n",
    "                ptr[i][j] = (i-1, j-1)\n",
    "            elif best == score2:\n",
    "                ptr[i][j] = (i, j-1)\n",
    "            else:\n",
    "                ptr[i][j] = (i-1, j)\n",
    "\n",
    "    # backtrack\n",
    "    i, j = N, M\n",
    "    alignment = []\n",
    "    unused_eng = set()\n",
    "    unused_kor = set()\n",
    "\n",
    "    while i > 0 or j > 0:\n",
    "        ni, nj = ptr[i][j]\n",
    "        if ni < i and nj < j:\n",
    "            alignment.append((i-1, j-1))\n",
    "        elif ni == i and nj <j:\n",
    "            unused_kor.add(j-1)\n",
    "        elif ni < i and nj == j:  \n",
    "            unused_eng.add(i-1)\n",
    "        i, j = ni, nj\n",
    "    print(f\"ì•ˆ ì“°ì¸ ì˜ì–´ ë¬¸ì¥ ê°¯ìˆ˜: {len(unused_eng)}, ì•ˆ ì“°ì¸ í•œêµ­ì–´ ë¬¸ì¥ ê°¯ìˆ˜: {len(unused_kor)}\")\n",
    "    return alignment[::-1]\n",
    "\n",
    "def dp_align_sentences(eng_sents, kor_sents, th=0.45):\n",
    "    \"\"\"\n",
    "    DP(Vecalign) ë°©ì‹ìœ¼ë¡œ M:N ë¬¸ì¥ ì •ë ¬ í›„ DataFrame ë°˜í™˜\n",
    "    \"\"\"\n",
    "\n",
    "    LABSE = \"setu4993/LaBSE\"\n",
    "\n",
    "    print(\"ğŸ”¥ Extracting LaBSE embeddings...\")\n",
    "    emb_eng = get_embeddings(eng_sents, LABSE)\n",
    "    emb_kor = get_embeddings(kor_sents, LABSE)\n",
    "\n",
    "    print(\"ğŸ”¥ Computing similarity matrix...\")\n",
    "    sim = cosine_similarity(emb_eng, emb_kor)\n",
    "\n",
    "    print(\"ğŸ”¥ Running DP alignment...\")\n",
    "    pairs = dp_align(emb_eng, emb_kor)\n",
    "\n",
    "    print(f\"ğŸ”¥ Raw aligned pairs (DP) = {len(pairs)}\")\n",
    "\n",
    "    aligned_rows = []\n",
    "    for i, j in pairs:\n",
    "        score = sim[i, j]\n",
    "        if score >= th:   # threshold filtering\n",
    "            aligned_rows.append({\n",
    "                \"eng\": eng_sents[i],\n",
    "                \"kor\": kor_sents[j],\n",
    "                \"sim\": float(score)\n",
    "            })\n",
    "\n",
    "    print(f\"ğŸ”¥ Filtered aligned pairs â‰¥ {th} : {len(aligned_rows)}\")\n",
    "\n",
    "    return pd.DataFrame(aligned_rows)\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 5. KoBERT ì„ë² ë”©\n",
    "# -----------------------------------------------------\n",
    "def get_kobert_embeddings(sentences):\n",
    "    from kobert_tokenizer import KoBERTTokenizer\n",
    "    from transformers import BertModel\n",
    "\n",
    "    tokenizer = KoBERTTokenizer.from_pretrained(\"skt/kobert-base-v1\")\n",
    "    model = BertModel.from_pretrained(\"skt/kobert-base-v1\").to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        sentences,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "\n",
    "    embs = []\n",
    "    batch_size = 32\n",
    "\n",
    "    for i in tqdm(range(0, len(sentences), batch_size), desc=\"  -> KoBERT ì„ë² ë”© ì¶”ì¶œ\"):\n",
    "        batch = {k: v[i:i+batch_size] for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            out = model(**batch)\n",
    "            cls_emb = out.last_hidden_state[:, 0, :]\n",
    "            embs.append(cls_emb.cpu().numpy())\n",
    "\n",
    "    return np.vstack(embs)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 6. ë©”ì¸ ì‹¤í–‰\n",
    "# -----------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"--- Day 1: ë°ì´í„° êµ¬ì¶• ë° ì„ë² ë”© ì¶”ì¶œ ---\")\n",
    "\n",
    "    eng_raw = load_and_segment_text(ENG_FILE_PATH)\n",
    "    eng_paragraph = split_paragraphs(eng_raw)\n",
    "    eng_sentences = split_sentences(\"\\n\".join(eng_paragraph))\n",
    "    eng_edu = build_edu(eng_sentences)\n",
    "\n",
    "    kor_raw = load_and_segment_text(KOR_FILE_PATH)\n",
    "    kor_paragraph = split_paragraphs(kor_raw)\n",
    "    kor_sentences = split_sentences(\"\\n\".join(kor_paragraph))\n",
    "    kor_edu = build_edu(kor_sentences)\n",
    "\n",
    "\n",
    "    # eng_sents = split_eng(eng_processed)\n",
    "    # eng_sents = split_eng_spacy(eng_processed)\n",
    "    # kor_sents = split_kor(kor_processed)\n",
    "\n",
    "    save_sentences(eng_edu, \"eng_edu.txt\")\n",
    "    save_sentences(kor_edu, \"kor_edu.txt\")\n",
    "\n",
    "    print(f\"ë¬¸ë‹¨ ì¶”ì¶œ: ENG={len(eng_edu)}, KOR={len(kor_edu)}\")\n",
    "\n",
    "    # #---------------------------------------------------------------------------------------#\n",
    "\n",
    "    # save_sentences(eng_paragraph, \"eng_paragraph.txt\")\n",
    "    # save_sentences(kor_paragraph, \"kor_paragraph.txt\")\n",
    "\n",
    "    # print(f\"ë¬¸ë‹¨ ì¶”ì¶œ: ENG={len(eng_paragraph)}, KOR={len(kor_paragraph)}\")\n",
    "\n",
    "    # aligned_paragraph = align_sentences(eng_paragraph, kor_paragraph)\n",
    "    # print(f\"ì •ë ¬ëœ ë¬¸ë‹¨ ìˆ˜: {len(aligned_paragraph)}\")\n",
    "\n",
    "    # print(\"ì˜ì–´ ì„ë² ë”© ìƒì„± ì¤‘...\")\n",
    "    # final_par_eng = get_embeddings(aligned_paragraph[\"eng\"].tolist(), \"bert-base-uncased\")\n",
    "\n",
    "    # print(\"í•œêµ­ì–´ ì„ë² ë”© ìƒì„± ì¤‘...(KoBERT)\")\n",
    "    # final_par_kor = get_kobert_embeddings(aligned_paragraph[\"kor\"].tolist())\n",
    "\n",
    "    # np.savez(\n",
    "    #     \"day1_paragraph_aligned_data.npz\",\n",
    "    #     eng_embs=final_par_eng,\n",
    "    #     kor_embs=final_par_kor,\n",
    "    #     eng_sents=aligned_paragraph[\"eng\"].values,\n",
    "    #     kor_sents=aligned_paragraph[\"kor\"].values\n",
    "    # )\n",
    "    # #---------------------------------------------------------------------------------------#\n",
    "\n",
    "    # save_sentences(eng_sentences, \"eng_sentences.txt\")\n",
    "    # save_sentences(kor_sentences, \"kor_sentences.txt\")\n",
    "\n",
    "    # print(\"Normal sentence Alignment\")\n",
    "\n",
    "    # print(f\"ë¬¸ì¥ ì¶”ì¶œ: ENG={len(eng_sentences)}, KOR={len(kor_sentences)}\")\n",
    "\n",
    "    # aligned = align_sentences(eng_sentences, kor_sentences)\n",
    "    # print(f\"ì •ë ¬ëœ ë¬¸ì¥ ìˆ˜: {len(aligned)}\")\n",
    "\n",
    "\n",
    "    # print(\"ì˜ì–´ ì„ë² ë”© ìƒì„± ì¤‘...\")\n",
    "    # final_normal_eng = get_embeddings(aligned[\"eng\"].tolist(), \"bert-base-uncased\")\n",
    "\n",
    "    # print(\"í•œêµ­ì–´ ì„ë² ë”© ìƒì„± ì¤‘...(KoBERT)\")\n",
    "    # final_normal_kor = get_kobert_embeddings(aligned[\"kor\"].tolist())\n",
    "\n",
    "    # np.savez(\n",
    "    #     OUTPUT_FILE,\n",
    "    #     eng_embs=final_normal_eng,\n",
    "    #     kor_embs=final_normal_kor,\n",
    "    #     eng_sents=aligned[\"eng\"].values,\n",
    "    #     kor_sents=aligned[\"kor\"].values\n",
    "    # )\n",
    "    # #---------------------------------------------------------------------------------------#\n",
    "    print(\"DP sentence Alignment\")\n",
    "    print(f\"ë¬¸ì¥ ì¶”ì¶œ: ENG={len(eng_edu)}, KOR={len(kor_edu)}\")\n",
    "\n",
    "    dp_aligned = dp_align_sentences(eng_edu, kor_edu)\n",
    "    print(f\"ì •ë ¬ëœ ë¬¸ì¥ ìˆ˜: {len(dp_aligned)}\")\n",
    "\n",
    "    print(\"ì˜ì–´ ì„ë² ë”© ìƒì„± ì¤‘...\")\n",
    "    final_dp_eng = get_embeddings(dp_aligned[\"eng\"].tolist(), \"bert-base-uncased\")\n",
    "\n",
    "    print(\"í•œêµ­ì–´ ì„ë² ë”© ìƒì„± ì¤‘...(KoBERT)\")\n",
    "    final_dp_kor = get_kobert_embeddings(dp_aligned[\"kor\"].tolist())\n",
    "\n",
    "    np.savez(\n",
    "        \"day1_dp_aligned_data.npz\",\n",
    "        eng_embs=final_dp_eng,\n",
    "        kor_embs=final_dp_kor,\n",
    "        eng_sents=dp_aligned[\"eng\"].values,\n",
    "        kor_sents=dp_aligned[\"kor\"].values\n",
    "    )\n",
    "\n",
    "    print(f\"ì €ì¥ ì™„ë£Œ â†’ {OUTPUT_FILE}, day1_paragraph_aligned.npz, day1_dp_aligned_data.npz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a31b7c",
   "metadata": {},
   "source": [
    "## New One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b51b089a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Day 1: ë°ì´í„° êµ¬ì¶• ë° ì„ë² ë”© ì¶”ì¶œ ---\n",
      "ë¬¸ë‹¨ ì¶”ì¶œ: ENG=27, KOR=30\n",
      "  -> LaBSE ì„ë² ë”© ì¶”ì¶œ ì‹œì‘...\n",
      "  -> ëª¨ë¸ ë¡œë“œ: setu4993/LaBSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  -> ì„ë² ë”© ì¶”ì¶œ (setu4993/LaBSE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:01<00:00, 24.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> ëª¨ë¸ ë¡œë“œ: setu4993/LaBSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  -> ì„ë² ë”© ì¶”ì¶œ (setu4993/LaBSE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:01<00:00, 27.49it/s]\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì •ë ¬ëœ ë¬¸ë‹¨ ìˆ˜: 26\n",
      "ì˜ì–´ ì„ë² ë”© ìƒì„± ì¤‘...\n",
      "  -> ëª¨ë¸ ë¡œë“œ: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  -> ì„ë² ë”© ì¶”ì¶œ (bert-base-uncased): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:01<00:00, 20.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•œêµ­ì–´ ì„ë² ë”© ìƒì„± ì¤‘...(KoBERT)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
      "The class this function is called from is 'KoBERTTokenizer'.\n",
      "  -> KoBERT ì„ë² ë”© ì¶”ì¶œ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:01<00:00, 21.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal sentence Alignment\n",
      "ë¬¸ì¥ ì¶”ì¶œ: ENG=156, KOR=215\n",
      "  -> LaBSE ì„ë² ë”© ì¶”ì¶œ ì‹œì‘...\n",
      "  -> ëª¨ë¸ ë¡œë“œ: setu4993/LaBSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  -> ì„ë² ë”© ì¶”ì¶œ (setu4993/LaBSE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [00:04<00:00, 32.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> ëª¨ë¸ ë¡œë“œ: setu4993/LaBSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  -> ì„ë² ë”© ì¶”ì¶œ (setu4993/LaBSE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 215/215 [00:06<00:00, 33.19it/s]\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì •ë ¬ëœ ë¬¸ì¥ ìˆ˜: 135\n",
      "ì˜ì–´ ì„ë² ë”© ìƒì„± ì¤‘...\n",
      "  -> ëª¨ë¸ ë¡œë“œ: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  -> ì„ë² ë”© ì¶”ì¶œ (bert-base-uncased): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:04<00:00, 33.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•œêµ­ì–´ ì„ë² ë”© ìƒì„± ì¤‘...(KoBERT)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
      "The class this function is called from is 'KoBERTTokenizer'.\n",
      "  -> KoBERT ì„ë² ë”© ì¶”ì¶œ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:04<00:00, 33.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP sentence Alignment\n",
      "ë¬¸ì¥ ì¶”ì¶œ: ENG=156, KOR=215\n",
      "ğŸ”¥ Extracting LaBSE embeddings...\n",
      "  -> ëª¨ë¸ ë¡œë“œ: setu4993/LaBSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  -> ì„ë² ë”© ì¶”ì¶œ (setu4993/LaBSE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 156/156 [00:04<00:00, 32.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> ëª¨ë¸ ë¡œë“œ: setu4993/LaBSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  -> ì„ë² ë”© ì¶”ì¶œ (setu4993/LaBSE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 215/215 [00:06<00:00, 32.17it/s]\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ Computing similarity matrix...\n",
      "ğŸ”¥ Running DP alignment...\n",
      "ì•ˆ ì“°ì¸ ì˜ì–´ ë¬¸ì¥ ê°¯ìˆ˜: 2, ì•ˆ ì“°ì¸ í•œêµ­ì–´ ë¬¸ì¥ ê°¯ìˆ˜: 61\n",
      "ğŸ”¥ Raw aligned pairs (DP) = 154\n",
      "ğŸ”¥ Filtered aligned pairs â‰¥ 0.45 : 147\n",
      "ì •ë ¬ëœ ë¬¸ì¥ ìˆ˜: 147\n",
      "ì˜ì–´ ì„ë² ë”© ìƒì„± ì¤‘...\n",
      "  -> ëª¨ë¸ ë¡œë“œ: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  -> ì„ë² ë”© ì¶”ì¶œ (bert-base-uncased): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 147/147 [00:04<00:00, 31.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•œêµ­ì–´ ì„ë² ë”© ìƒì„± ì¤‘...(KoBERT)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
      "The class this function is called from is 'KoBERTTokenizer'.\n",
      "  -> KoBERT ì„ë² ë”© ì¶”ì¶œ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 147/147 [00:04<00:00, 32.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì €ì¥ ì™„ë£Œ â†’ day1_aligned_data.npz, day1_paragraph_aligned.npz, day1_dp_aligned_data.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "import kss\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# ğŸ”¥ 0. NLTK punkt ìë™ ì„¤ì¹˜ (ì´ê±¸ë¡œ LookupError 100% í•´ê²°)\n",
    "# -----------------------------------------------------\n",
    "# -----------------------------------------------------\n",
    "# ğŸ”¥ NLTK punkt + punkt_tab ìë™ ì„¤ì¹˜ (ì™„ì „ í•´ê²°)\n",
    "# -----------------------------------------------------\n",
    "# def ensure_punkt():\n",
    "#     try:\n",
    "#         nltk.data.find('tokenizers/punkt')\n",
    "#         print(\"âœ” punkt ok\")\n",
    "#     except LookupError:\n",
    "#         print(\"â¬‡ punkt ë‹¤ìš´ë¡œë“œ ì¤‘...\")\n",
    "#         nltk.download('punkt')\n",
    "\n",
    "#     try:\n",
    "#         nltk.data.find('tokenizers/punkt_tab')\n",
    "#         print(\"âœ” punkt_tab ok\")\n",
    "#     except LookupError:\n",
    "#         print(\"â¬‡ punkt_tab ë‹¤ìš´ë¡œë“œ ì¤‘...\")\n",
    "#         nltk.download('punkt_tab')\n",
    "\n",
    "# ensure_punkt()\n",
    "\n",
    "# import spacy\n",
    "\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# --- 0. ì„¤ì • ë° íŒŒì¼ ê²½ë¡œ ---\n",
    "ENG_FILE_PATH = \"eng_testp1.txt\"\n",
    "KOR_FILE_PATH = \"kor_testp1.txt\"\n",
    "OUTPUT_FILE = \"day1_aligned_data.npz\"\n",
    "EMBEDDING_DIM = 768\n",
    "LABSE = \"setu4993/LaBSE\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def save_sentences(sent_list, path):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for s in sent_list:\n",
    "            f.write(s.strip() + \"\\n\")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\n{2,}', '<PARA>', text)\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = text.replace(\"<PARA>\", \"\\n\\n\")\n",
    "    return text\n",
    "# -----------------------------------------------------\n",
    "# 1. í…ìŠ¤íŠ¸ ë¡œë”©\n",
    "# -----------------------------------------------------\n",
    "def load_and_segment_text(file_path):\n",
    "    \"\"\"íŒŒì¼ì„ ì½ê³  í…ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜ (ë¬¸ì¥ ë¶„ë¦¬ëŠ” ì•„ë˜ì—ì„œ ìˆ˜í–‰).\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "        return text\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ì˜¤ë¥˜: íŒŒì¼ ì—†ìŒ â†’ {file_path}\")\n",
    "        return \"\" \n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 2. ë¬¸ì¥ ë¶„ë¦¬\n",
    "# -----------------------------------------------------\n",
    "\n",
    "# def split_paragraphs(raw_text):\n",
    "#     text = re.sub(r'(?<!\\n)\\n(?!\\n)', ' ', raw_text)\n",
    "#     raw_paragraphs = re.split(r'\\n\\s*\\n+', text)\n",
    "#     paragraphs = [p.strip() for p in raw_paragraphs if p.strip()]\n",
    "#     return paragraphs\n",
    "\n",
    "def split_paragraphs(raw_text):\n",
    "    # ë¬¸ë‹¨ êµ¬ë¶„ (\\n\\n ì´ìƒ)\n",
    "    raw_paragraphs = re.split(r'\\n\\s*\\n+', raw_text)\n",
    "\n",
    "    # ë¬¸ë‹¨ ë‚´ë¶€ ì¤„ë°”ê¿ˆì€ ê³µë°±ìœ¼ë¡œ merge\n",
    "    paragraphs = [\n",
    "        re.sub(r'\\n+', ' ', p).strip()\n",
    "        for p in raw_paragraphs if p.strip()\n",
    "    ]\n",
    "    return paragraphs\n",
    "\n",
    "\n",
    "def split_by_punctuation(text):\n",
    "    # ë¬¸ì¥ë¶€í˜¸ ê¸°ë°˜ ë¶„ë¦¬\n",
    "    parts = re.split(r'(?<=[.!?])\\s+(?=[A-Zâ€œ\"â€˜\\'ê°€-í£])', text)\n",
    "    return parts\n",
    "\n",
    "def split_sentences(text):\n",
    "\n",
    "    # 1) Normalize spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    sentences = []\n",
    "\n",
    "    # 2) ë¨¼ì € ë”°ì˜´í‘œ ë¸”ë¡ ë¶„ë¦¬\n",
    "    quote_blocks = re.split(r'(â€œ[^â€]+â€|\"[^\"]+\")', text)\n",
    "\n",
    "    for block in quote_blocks:\n",
    "        if not block.strip():\n",
    "            continue\n",
    "\n",
    "        # 3) blockì´ ë”°ì˜´í‘œë¡œ ë‘˜ëŸ¬ì‹¸ì—¬ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë¬¸ì¥ í›„ë³´ì— ë„£ê³  ë‚´ë¶€ ì²˜ë¦¬\n",
    "        if (block.startswith(\"â€œ\") and block.endswith(\"â€\")) or \\\n",
    "           (block.startswith('\"') and block.endswith('\"')):\n",
    "            sentences.extend(split_by_punctuation(block))\n",
    "            continue\n",
    "\n",
    "        # 4) ê´„í˜¸ ë¸”ë¡ ë¶„ë¦¬\n",
    "        paren_blocks = re.split(r'(\\([^()]+\\))', block)\n",
    "\n",
    "        for pblock in paren_blocks:\n",
    "            if not pblock.strip():\n",
    "                continue\n",
    "\n",
    "            if pblock.startswith(\"(\") and pblock.endswith(\")\"):\n",
    "                sentences.extend(split_by_punctuation(pblock))\n",
    "            else:\n",
    "                sentences.extend(split_by_punctuation(pblock))\n",
    "\n",
    "    return [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "# ë¬¸ì¥ ë¶„ë¦¬ë¥¼ ìœ„í•œ ê¸°ë³¸ íŒ¨í„´\n",
    "SENT_SPLIT_RE = re.compile(\n",
    "    r'(?<=[.!?])\\s+(?=[A-Zâ€œ\"â€˜\\'ê°€-í£])'\n",
    ")\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    \"\"\"ê¸°ë³¸ ë¬¸ì¥ ë‚˜ëˆ„ê¸° (ë„ˆì˜ ê¸°ì¡´ ê·œì¹™ ê¸°ë°˜)\"\"\"\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    parts = SENT_SPLIT_RE.split(text)\n",
    "    return [p.strip() for p in parts if p.strip()]\n",
    "\n",
    "\n",
    "def count_tokens(s):\n",
    "    return len(s.split())\n",
    "\n",
    "\n",
    "def edu_parser(text, max_tokens=50):\n",
    "    \"\"\"\n",
    "    ê°€ì¥ ì •í™•í•œ EDU parser\n",
    "    - ì¸ìš©ë¶€(â€œ â€) ì²˜ë¦¬\n",
    "    - ê´„í˜¸( ) ë¸”ë¡ ë¬¶ê¸°\n",
    "    - ëŒ€í™”ë¬¸ ë’¤ì˜ ì„œìˆ ë¬¸ ë¬¶ê¸°\n",
    "    - EDU token í¬ê¸° ì œí•œ\n",
    "    \"\"\"\n",
    "\n",
    "    # ----------------------------\n",
    "    # 1. ìµœìƒìœ„ ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "    # ----------------------------\n",
    "    sentences = split_into_sentences(text)\n",
    "\n",
    "    edus = []\n",
    "    cur_edu = []\n",
    "    cur_tokens = 0\n",
    "\n",
    "    i = 0\n",
    "    N = len(sentences)\n",
    "\n",
    "    while i < N:\n",
    "        sent = sentences[i]\n",
    "\n",
    "        # ========================================================\n",
    "        # CASE 1: ì¸ìš©ë¶€ ì‹œì‘ (â€œ ë˜ëŠ” \")\n",
    "        # ========================================================\n",
    "        if \"â€œ\" in sent or \"\\\"\" in sent:\n",
    "            quote_block = [sent]\n",
    "            quote_open = True\n",
    "\n",
    "            # ì¸ìš©ë¶€ ë‹«í ë•Œê¹Œì§€ ëª¨ìœ¼ê¸°\n",
    "            while quote_open and i + 1 < N:\n",
    "                if \"â€\" in sentences[i] or \"\\\"\" in sentences[i]:\n",
    "                    quote_open = False\n",
    "                else:\n",
    "                    i += 1\n",
    "                    quote_block.append(sentences[i])\n",
    "\n",
    "                # ë‹«í˜ ê°ì§€\n",
    "                if \"â€\" in sentences[i] or \"\\\"\" in sentences[i]:\n",
    "                    quote_open = False\n",
    "\n",
    "            # ì¸ìš©ë¶€ ë‚´ë¶€ ë¬¸ì¥ ìˆ˜ ê³„ì‚°\n",
    "            inner_sents = []\n",
    "            for q in quote_block:\n",
    "                inner_sents.extend(split_into_sentences(q))\n",
    "\n",
    "            # 3ë¬¸ì¥ ì´ìƒì´ë©´ ë‚´ë¶€ ì„¸ë¶„í™”\n",
    "            if len(inner_sents) >= 3:\n",
    "                tmp = []\n",
    "                for qs in inner_sents:\n",
    "                    tmp.append(qs)\n",
    "                    # ê°íƒ„/ì§ˆë¬¸ ë“±ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ë¶„í• \n",
    "                    if qs.endswith((\"!\", \"?\")):\n",
    "                        edus.append(\" \".join(tmp))\n",
    "                        tmp = []\n",
    "                if tmp:\n",
    "                    edus.append(\" \".join(tmp))\n",
    "            else:\n",
    "                edus.append(\" \".join(inner_sents))\n",
    "\n",
    "            # ì¸ìš©ë¶€ ë’¤ì— speaker ì„œìˆ ë¬¸ì´ ì˜¤ë©´ ë¬¶ê¸°\n",
    "            if i + 1 < N:\n",
    "                nxt = sentences[i+1]\n",
    "                # cried Alice, said Alice, thought Alice ë“±\n",
    "                if re.search(r\"\\b(said|cried|asked|thought)\\b\", nxt, re.I):\n",
    "                    edus[-1] += \" \" + nxt\n",
    "                    i += 1  # speaker line ì†Œë¹„\n",
    "\n",
    "        # ========================================================\n",
    "        # CASE 2: ê´„í˜¸ ë¬¸ì¥ ì²˜ë¦¬\n",
    "        # ========================================================\n",
    "        elif \"(\" in sent and \")\" in sent:\n",
    "            edus.append(sent)\n",
    "\n",
    "        elif \"(\" in sent:\n",
    "            block = [sent]\n",
    "            paren_open = True\n",
    "            while paren_open and i+1 < N:\n",
    "                i += 1\n",
    "                block.append(sentences[i])\n",
    "                if \")\" in sentences[i]:\n",
    "                    paren_open = False\n",
    "            edus.append(\" \".join(block))\n",
    "\n",
    "        # ========================================================\n",
    "        # CASE 3: ì¼ë°˜ ë¬¸ì¥ ì²˜ë¦¬\n",
    "        # ========================================================\n",
    "        else:\n",
    "            # í† í° ê¸¸ì´ ì²´í¬í•˜ë©° EDU ìŒ“ê¸°\n",
    "            t = count_tokens(sent)\n",
    "            if cur_tokens + t <= max_tokens:\n",
    "                cur_edu.append(sent)\n",
    "                cur_tokens += t\n",
    "            else:\n",
    "                # ê¸°ì¡´ EDU flush\n",
    "                if cur_edu:\n",
    "                    edus.append(\" \".join(cur_edu))\n",
    "                # ìƒˆ EDU ì‹œì‘\n",
    "                cur_edu = [sent]\n",
    "                cur_tokens = t\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # ë§ˆì§€ë§‰ EDU ì €ì¥\n",
    "    if cur_edu:\n",
    "        edus.append(\" \".join(cur_edu))\n",
    "\n",
    "    # ìµœì¢… ê¹¨ë—í•˜ê²Œ ì •ë¦¬\n",
    "    return [e.strip() for e in edus if e.strip()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def split_eng(text):\n",
    "#     return sent_tokenize(text)\n",
    "\n",
    "\n",
    "# def split_eng_spacy(text):\n",
    "#     doc = nlp(text)\n",
    "#     return [sent.text.strip() for sent in doc.sents]\n",
    "\n",
    "\n",
    "# def split_kor(text):\n",
    "#     return kss.split_sentences(text)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 3. ëª¨ë¸ ì„ë² ë”© ìƒì„±\n",
    "# -----------------------------------------------------\n",
    "def get_embeddings(sentences, model_name):\n",
    "    \"\"\"\n",
    "    Token-level embedding â†’ mean + var vector (1536-dim)\n",
    "    CLS ëŒ€ì‹  token distribution ê¸°ë°˜ í‘œí˜„ ì‚¬ìš©\n",
    "    \"\"\"\n",
    "    print(f\"  -> ëª¨ë¸ ë¡œë“œ: {model_name}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name).to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    features = []\n",
    "\n",
    "    for sent in tqdm(sentences, desc=f\"  -> ì„ë² ë”© ì¶”ì¶œ ({model_name})\"):\n",
    "        inputs = tokenizer(\n",
    "            sent,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=True\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        token_emb = outputs.last_hidden_state.squeeze(0)   # (seq_len, 768)\n",
    "        token_emb = token_emb.cpu().numpy()\n",
    "\n",
    "        mean_vec = token_emb.mean(axis=0)                 # (768,)\n",
    "        var_vec = token_emb.var(axis=0)                   # (768,)\n",
    "\n",
    "        sent_emb = np.concatenate([mean_vec, var_vec])    # (1536,)\n",
    "\n",
    "        features.append(sent_emb)\n",
    "\n",
    "    return np.vstack(features)\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 4. ë¬¸ì¥ ì •ë ¬ (LaBSE + Hungarian matching)\n",
    "# -----------------------------------------------------\n",
    "def align_sentences(eng_sents, kor_sents):\n",
    "    print(\"  -> LaBSE ì„ë² ë”© ì¶”ì¶œ ì‹œì‘...\")\n",
    "\n",
    "    labse_eng = get_embeddings(eng_sents, LABSE)\n",
    "    labse_kor = get_embeddings(kor_sents, LABSE)\n",
    "\n",
    "    sim_matrix = cosine_similarity(labse_eng, labse_kor)\n",
    "    cost_matrix = -sim_matrix\n",
    "\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "\n",
    "    aligned = []\n",
    "    TH = 0.7\n",
    "\n",
    "    for i, j in zip(row_ind, col_ind):\n",
    "        if sim_matrix[i, j] >= TH:\n",
    "            aligned.append({\n",
    "                \"eng\": eng_sents[i],\n",
    "                \"kor\": kor_sents[j],\n",
    "                \"sim\": sim_matrix[i, j]\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(aligned)\n",
    "\n",
    "def dp_align(eng_emb, kor_emb):\n",
    "    N = len(eng_emb)\n",
    "    M = len(kor_emb)\n",
    "\n",
    "    dp = np.zeros((N+1, M+1))\n",
    "    ptr = np.zeros((N+1, M+1, 2), dtype=int)\n",
    "\n",
    "    sim = cosine_similarity(eng_emb, kor_emb)\n",
    "\n",
    "    for i in range(1, N+1):\n",
    "        for j in range(1, M+1):\n",
    "            # 1:1 match\n",
    "            score1 = dp[i-1][j-1] + sim[i-1][j-1]\n",
    "\n",
    "            # 1:N (skip Korean)\n",
    "            score2 = dp[i][j-1] - 0.3\n",
    "\n",
    "            # N:1 (skip English)\n",
    "            score3 = dp[i-1][j] - 0.3\n",
    "\n",
    "            best = max(score1, score2, score3)\n",
    "\n",
    "            dp[i][j] = best\n",
    "\n",
    "            if best == score1:\n",
    "                ptr[i][j] = (i-1, j-1)\n",
    "            elif best == score2:\n",
    "                ptr[i][j] = (i, j-1)\n",
    "            else:\n",
    "                ptr[i][j] = (i-1, j)\n",
    "\n",
    "    # backtrack\n",
    "    i, j = N, M\n",
    "    alignment = []\n",
    "    unused_eng = set()\n",
    "    unused_kor = set()\n",
    "\n",
    "    while i > 0 or j > 0:\n",
    "        ni, nj = ptr[i][j]\n",
    "        if ni < i and nj < j:\n",
    "            alignment.append((i-1, j-1))\n",
    "        elif ni == i and nj <j:\n",
    "            unused_kor.add(j-1)\n",
    "        elif ni < i and nj == j:  \n",
    "            unused_eng.add(i-1)\n",
    "        i, j = ni, nj\n",
    "    print(f\"ì•ˆ ì“°ì¸ ì˜ì–´ ë¬¸ì¥ ê°¯ìˆ˜: {len(unused_eng)}, ì•ˆ ì“°ì¸ í•œêµ­ì–´ ë¬¸ì¥ ê°¯ìˆ˜: {len(unused_kor)}\")\n",
    "    return alignment[::-1]\n",
    "\n",
    "def dp_align_sentences(eng_sents, kor_sents, th=0.45):\n",
    "    \"\"\"\n",
    "    DP(Vecalign) ë°©ì‹ìœ¼ë¡œ M:N ë¬¸ì¥ ì •ë ¬ í›„ DataFrame ë°˜í™˜\n",
    "    \"\"\"\n",
    "\n",
    "    LABSE = \"setu4993/LaBSE\"\n",
    "\n",
    "    print(\"ğŸ”¥ Extracting LaBSE embeddings...\")\n",
    "    emb_eng = get_embeddings(eng_sents, LABSE)\n",
    "    emb_kor = get_embeddings(kor_sents, LABSE)\n",
    "\n",
    "    print(\"ğŸ”¥ Computing similarity matrix...\")\n",
    "    sim = cosine_similarity(emb_eng, emb_kor)\n",
    "\n",
    "    print(\"ğŸ”¥ Running DP alignment...\")\n",
    "    pairs = dp_align(emb_eng, emb_kor)\n",
    "\n",
    "    print(f\"ğŸ”¥ Raw aligned pairs (DP) = {len(pairs)}\")\n",
    "\n",
    "    aligned_rows = []\n",
    "    for i, j in pairs:\n",
    "        score = sim[i, j]\n",
    "        if score >= th:   # threshold filtering\n",
    "            aligned_rows.append({\n",
    "                \"eng\": eng_sents[i],\n",
    "                \"kor\": kor_sents[j],\n",
    "                \"sim\": float(score)\n",
    "            })\n",
    "\n",
    "    print(f\"ğŸ”¥ Filtered aligned pairs â‰¥ {th} : {len(aligned_rows)}\")\n",
    "\n",
    "    return pd.DataFrame(aligned_rows)\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 5. KoBERT ì„ë² ë”©\n",
    "# -----------------------------------------------------\n",
    "def get_kobert_embeddings(sentences):\n",
    "    from kobert_tokenizer import KoBERTTokenizer\n",
    "    from transformers import BertModel\n",
    "\n",
    "    tokenizer = KoBERTTokenizer.from_pretrained(\"skt/kobert-base-v1\")\n",
    "    model = BertModel.from_pretrained(\"skt/kobert-base-v1\").to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    features = []\n",
    "\n",
    "    for sent in tqdm(sentences, desc=\"  -> KoBERT ì„ë² ë”© ì¶”ì¶œ\"):\n",
    "        inputs = tokenizer(\n",
    "            sent,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=128\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        token_emb = outputs.last_hidden_state.squeeze(0).cpu().numpy()\n",
    "\n",
    "        mean_vec = token_emb.mean(axis=0)\n",
    "        var_vec = token_emb.var(axis=0)\n",
    "\n",
    "        sent_emb = np.concatenate([mean_vec, var_vec])\n",
    "        features.append(sent_emb)\n",
    "\n",
    "    return np.vstack(features)\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 6. ë©”ì¸ ì‹¤í–‰\n",
    "# -----------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"--- Day 1: ë°ì´í„° êµ¬ì¶• ë° ì„ë² ë”© ì¶”ì¶œ ---\")\n",
    "\n",
    "    eng_raw = load_and_segment_text(ENG_FILE_PATH)\n",
    "    eng_paragraph = split_paragraphs(eng_raw)\n",
    "    eng_sentences = split_sentences(\"\\n\".join(eng_paragraph))\n",
    "\n",
    "    kor_raw = load_and_segment_text(KOR_FILE_PATH)\n",
    "    kor_paragraph = split_paragraphs(kor_raw)\n",
    "    kor_sentences = split_sentences(\"\\n\".join(kor_paragraph))\n",
    "\n",
    "    # eng_sents = split_eng(eng_processed)\n",
    "    # eng_sents = split_eng_spacy(eng_processed)\n",
    "    # kor_sents = split_kor(kor_processed)\n",
    "\n",
    "    #---------------------------------------------------------------------------------------#\n",
    "\n",
    "    save_sentences(eng_paragraph, \"eng_paragraph.txt\")\n",
    "    save_sentences(kor_paragraph, \"kor_paragraph.txt\")\n",
    "\n",
    "    print(f\"ë¬¸ë‹¨ ì¶”ì¶œ: ENG={len(eng_paragraph)}, KOR={len(kor_paragraph)}\")\n",
    "\n",
    "    aligned_paragraph = align_sentences(eng_paragraph, kor_paragraph)\n",
    "    print(f\"ì •ë ¬ëœ ë¬¸ë‹¨ ìˆ˜: {len(aligned_paragraph)}\")\n",
    "\n",
    "    print(\"ì˜ì–´ ì„ë² ë”© ìƒì„± ì¤‘...\")\n",
    "    final_par_eng = get_embeddings(aligned_paragraph[\"eng\"].tolist(), \"bert-base-uncased\")\n",
    "\n",
    "    print(\"í•œêµ­ì–´ ì„ë² ë”© ìƒì„± ì¤‘...(KoBERT)\")\n",
    "    final_par_kor = get_kobert_embeddings(aligned_paragraph[\"kor\"].tolist())\n",
    "\n",
    "    np.savez(\n",
    "        \"day1_paragraph_aligned_data.npz\",\n",
    "        eng_embs=final_par_eng,\n",
    "        kor_embs=final_par_kor,\n",
    "        eng_sents=aligned_paragraph[\"eng\"].values,\n",
    "        kor_sents=aligned_paragraph[\"kor\"].values\n",
    "    )\n",
    "    #---------------------------------------------------------------------------------------#\n",
    "\n",
    "    save_sentences(eng_sentences, \"eng_sentences.txt\")\n",
    "    save_sentences(kor_sentences, \"kor_sentences.txt\")\n",
    "\n",
    "    print(\"Normal sentence Alignment\")\n",
    "\n",
    "    print(f\"ë¬¸ì¥ ì¶”ì¶œ: ENG={len(eng_sentences)}, KOR={len(kor_sentences)}\")\n",
    "\n",
    "    aligned = align_sentences(eng_sentences, kor_sentences)\n",
    "    print(f\"ì •ë ¬ëœ ë¬¸ì¥ ìˆ˜: {len(aligned)}\")\n",
    "\n",
    "\n",
    "    print(\"ì˜ì–´ ì„ë² ë”© ìƒì„± ì¤‘...\")\n",
    "    final_normal_eng = get_embeddings(aligned[\"eng\"].tolist(), \"bert-base-uncased\")\n",
    "\n",
    "    print(\"í•œêµ­ì–´ ì„ë² ë”© ìƒì„± ì¤‘...(KoBERT)\")\n",
    "    final_normal_kor = get_kobert_embeddings(aligned[\"kor\"].tolist())\n",
    "\n",
    "    np.savez(\n",
    "        OUTPUT_FILE,\n",
    "        eng_embs=final_normal_eng,\n",
    "        kor_embs=final_normal_kor,\n",
    "        eng_sents=aligned[\"eng\"].values,\n",
    "        kor_sents=aligned[\"kor\"].values\n",
    "    )\n",
    "    #---------------------------------------------------------------------------------------#\n",
    "    print(\"DP sentence Alignment\")\n",
    "    print(f\"ë¬¸ì¥ ì¶”ì¶œ: ENG={len(eng_sentences)}, KOR={len(kor_sentences)}\")\n",
    "\n",
    "    dp_aligned = dp_align_sentences(eng_sentences, kor_sentences)\n",
    "    print(f\"ì •ë ¬ëœ ë¬¸ì¥ ìˆ˜: {len(dp_aligned)}\")\n",
    "\n",
    "    print(\"ì˜ì–´ ì„ë² ë”© ìƒì„± ì¤‘...\")\n",
    "    final_dp_eng = get_embeddings(dp_aligned[\"eng\"].tolist(), \"bert-base-uncased\")\n",
    "\n",
    "    print(\"í•œêµ­ì–´ ì„ë² ë”© ìƒì„± ì¤‘...(KoBERT)\")\n",
    "    final_dp_kor = get_kobert_embeddings(dp_aligned[\"kor\"].tolist())\n",
    "\n",
    "    np.savez(\n",
    "        \"day1_dp_aligned_data.npz\",\n",
    "        eng_embs=final_dp_eng,\n",
    "        kor_embs=final_dp_kor,\n",
    "        eng_sents=dp_aligned[\"eng\"].values,\n",
    "        kor_sents=dp_aligned[\"kor\"].values\n",
    "    )\n",
    "\n",
    "    print(f\"ì €ì¥ ì™„ë£Œ â†’ {OUTPUT_FILE}, day1_paragraph_aligned.npz, day1_dp_aligned_data.npz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d32eb10",
   "metadata": {},
   "source": [
    "# NPZ Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4652240b",
   "metadata": {},
   "source": [
    "## Paragraph Aligned npz Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26096da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Day 1 ë°ì´í„° 'day1_paragraph.npz' ë‚´ìš© í™•ì¸ ---\n",
      "ì €ì¥ëœ ë³€ìˆ˜ ì´ë¦„: ['eng_embs', 'kor_embs', 'eng_sents', 'kor_sents']\n",
      "ì „ì²´ ì •ë ¬ ìŒ ê°œìˆ˜ (N): 25\n",
      "ì„ë² ë”© ì°¨ì› (D): 768\n",
      "\n",
      "âœ… ì •ë ¬ëœ ë¬¸ì¥ ìŒ 5ê°œ í™•ì¸ (ë§¤í•‘ ê²°ê³¼):\n",
      "\n",
      "--- [ìŒ 1] ---\n",
      "  **ENG**: CHAPTER II. The Pool of Tears\n",
      "  **KOR**: ì œ2ì¥ ëˆˆë¬¼ ì›…ë©ì´\n",
      "\n",
      "--- [ìŒ 2] ---\n",
      "  **ENG**: â€œCuriouser and curiouser!â€ cried Alice (she was so much surprised, that for the moment she quite forgot how to speak good English); â€œnow Iâ€™m opening out like the largest telescope that ever was! Good-bye, feet!â€ (for when she looked down at her feet, they seemed to be almost out of sight, they were getting so far off). â€œOh, my poor little feet, I wonder who will put on your shoes and stockings for you now, dears? Iâ€™m sure _I_ shanâ€™t be able! I shall be a great deal too far off to trouble myself about you: you must manage the best way you can;â€”but I must be kind to them,â€ thought Alice, â€œor perhaps they wonâ€™t walk the way I want to go! Let me see: Iâ€™ll give them a new pair of boots every Christmas.â€\n",
      "  **KOR**: â€œìš”ìƒí•˜ê³ ë„ ìš”ìƒí•´!â€ ì•¨ë¦¬ìŠ¤ëŠ” ì†Œë¦¬ì³¤ë‹¤.(ì•¨ë¦¬ìŠ¤ëŠ” ë„ˆë¬´ ë†€ë€ ë‚˜ë¨¸ì§€ ë§ì¡°ì°¨ ë˜‘ë°”ë¡œ í•˜ì§€ ëª»í–ˆë‹¤.) â€œì´ì   ë‚´ê°€ ì„¸ìƒì—ì„œ ê°€ì¥ í° ë§ì›ê²½ì²˜ëŸ¼ í¼ì³ì ¸ ë²„ë ¸ì–´. ì˜ìˆì–´ - ë‚´ ë°œì•„!â€(ì•¨ë¦¬ìŠ¤ê°€ ë°œì„ ì³ë‹¤ ë³´ë‹ˆ ê¹Œë§ˆë“íˆ ë©€ë¦¬ ìˆì–´ì„œ ê²¨ìš° ë³´ì¼ë½ ë§ë½ í•  ì§€ê²½ì´ì—ˆë‹¤.) â€œì•„, ë¶ˆìŒí•œ ë‚´ ì‘ì€ ë°œë“¤. ì´ì œ ëˆ„ê°€ ë‚´ ë°œì— ì–‘ë§ì„ ì‹ ê²¨ ì£¼ê³  ì‹ ë°œì„ ì‹ ê²¨ ì¤€ë‹´. ë‚œ ëª» í• ê±°ì•¼. ë‚´ê°€ ë„ˆí¬ì—ê²Œ í•˜ë ¤ë‹ˆ ë„ˆë¬´ ë©€êµ¬ë‚˜, ê·¸ëŸ¬ë©´ ì •ë§ í° ë¬¸ì œê°€ ìƒê¸¸ê±°ì•¼. ë„ˆí¬ê°€ ìŠ¤ìŠ¤ë¡œ í•˜ëŠ” ê²Œ ê°€ì¥ ì¢‹ì§€ë§Œ, ë‚´ê°€ ë¬´ì–´ë“  í•´ì•¼í•˜ê² ì§€.â€í•˜ê³  ì•¨ë¦¬ìŠ¤ëŠ” ìƒê°í–ˆë‹¤. â€œì•„ë‹ˆë©´ ì•„ë§ˆë„ ë‚´ ë°œë“¤ì´ ë‚´ê°€ ê°€ê³  ì‹¶ì„ ë•Œ ê±·ì§€ ì•Šìœ¼ë ¤ê³  í• ì§€ë„ ëª°ë¼! ì–´ì©Œì§€? ì–˜ë“¤ì•„, í¬ë¦¬ìŠ¤ë§ˆìŠ¤ë§ˆë‹¤ ìƒˆ ì‹ ë°œì„ ì‚¬ì¤„ê»˜.â€\n",
      "\n",
      "--- [ìŒ 3] ---\n",
      "  **ENG**: And she went on planning to herself how she would manage it. â€œThey must go by the carrier,â€ she thought; â€œand how funny itâ€™ll seem, sending presents to oneâ€™s own feet! And how odd the directions will look!\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ëŠ” ì–´ë–»ê²Œ ì„ ë¬¼ì„ ì¤„ ìˆ˜ ìˆì„ ì§€ ìƒê°í•´ ë³´ì•˜ë‹¤. â€œì•„ë¬´ë˜ë„ ìš´ì†¡ íšŒì‚¬ë¥¼ ë¶ˆëŸ¬ì•¼ í•  ê±°ì•¼. ê·¸ëŸ°ë°, ì •ë§ ìš°ìŠµê²Œ ë³´ì´ê² ì§€? ìê¸° ë°œì—ê²Œ ìê¸°ê°€ ì„ ë¬¼ì„ í•˜ë‹¤ë‹ˆ. ì£¼ì†ŒëŠ” ë˜ ì–¼ë§ˆë‚˜ ì´ìƒí• ê¹Œ!\n",
      "\n",
      "--- [ìŒ 4] ---\n",
      "  **ENG**: Just then her head struck against the roof of the hall: in fact she was now more than nine feet high, and she at once took up the little golden key and hurried off to the garden door.\n",
      "  **KOR**: ì´ ë•Œ ì•¨ë¦¬ìŠ¤ì˜ ë¨¸ë¦¬ê°€ ì²œì •ì— ë¶€ë”›í˜”ë‹¤. ì•¨ë¦¬ìŠ¤ëŠ” ì´ë¯¸ í‚¤ê°€ 9 í”¼íŠ¸ê°€ ë„˜ê²Œ ì»¤ì ¸ ìˆì—ˆë‹¤. ì•¨ë¦¬ìŠ¤ëŠ” ì¬ë¹¨ë¦¬ íƒì ìœ„ì— ë†“ì¸ ê¸ˆì—´ì‡ ë¥¼ ì§‘ì–´ ë¬¸ì„ ì—´ì—ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 5] ---\n",
      "  **ENG**: Poor Alice! It was as much as she could do, lying down on one side, to look through into the garden with one eye; but to get through was more hopeless than ever: she sat down and began to cry again.\n",
      "  **KOR**: ë¶ˆìŒí•œ ì•¨ë¦¬ìŠ¤! ì•¨ë¦¬ìŠ¤ê°€ ìµœëŒ€í•œ í•  ìˆ˜ ìˆëŠ” ì¼ì´ë¼ê³¤ í•œìª½ìœ¼ë¡œ ëˆ„ì›Œ í•œ ëˆˆìœ¼ë¡œ ë¬¸ ì•ˆì„ ë“¤ì—¬ë‹¤ ë³´ëŠ” ê²ƒì´ ê³ ì‘ì´ì—ˆë‹¤. ê·¸ë˜ì„œ ê·¸ ê³³ì„ ì§€ë‚˜ê°€ëŠ” ì¼ì€ ì—„ë‘ë„ ë‚´ì§€ ëª»í•˜ê²Œ ë˜ì—ˆë‹¤. ì•¨ë¦¬ìŠ¤ëŠ” ì£¼ì € ì•‰ì•„ ë‹¤ì‹œ ìš¸ê¸° ì‹œì‘í•˜ì˜€ë‹¤.\n",
      "\n",
      "--- [ìŒ 6] ---\n",
      "  **ENG**: â€œYou ought to be ashamed of yourself,â€ said Alice, â€œa great girl like you,â€ (she might well say this), â€œto go on crying in this way! Stop this moment, I tell you!â€ But she went on all the same, shedding gallons of tears, until there was a large pool all round her, about four inches deep and reaching half down the hall.\n",
      "  **KOR**: â€œë¶€ë„ëŸ¬ìš´ ì¤„ ì•Œì•„ì•¼ì§€. ë‹¤ í° ì†Œë…€ê°€ ìš¸ë‹¤ë‹ˆ.â€í•˜ê³  ì•¨ë¦¬ìŠ¤ëŠ” ë§í–ˆë‹¤.(ì´ë²ˆì—” í›Œë¥­í•˜ê²Œ ë§í–ˆë‹¤.) â€œì´ë ‡ê²Œ ìš¸ë‹¤ë‹ˆ. ëš! ê·¸ì¹˜ë¼ê³  ë§í–ˆë‹¤!â€ í•˜ì§€ë§Œ ê·¸ ë• ì´ë¯¸ ì•¨ë¦¬ìŠ¤ê°€ í˜ë¦° ëˆˆë¬¼ì´ ë°©ì•ˆì— ê°€ë“ ì°¨ì„œ í° ì›…ë©ì´ê°€ ë˜ì–´ ë²„ë ¸ë‹¤. ì›…ë©ì´ ê¹Šì´ëŠ” 4 í”¼íŠ¸ë‚˜ ë˜ì–´ ë°© ë†’ì´ì˜ ì ˆë°˜ì´ë‚˜ ë˜ì—ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 7] ---\n",
      "  **ENG**: After a time she heard a little pattering of feet in the distance, and she hastily dried her eyes to see what was coming. It was the White Rabbit returning, splendidly dressed, with a pair of white kid gloves in one hand and a large fan in the other: he came trotting along in a great hurry, muttering to himself as he came, â€œOh! the Duchess, the Duchess! Oh! wonâ€™t she be savage if Iâ€™ve kept her waiting!â€ Alice felt so desperate that she was ready to ask help of any one; so, when the Rabbit came near her, she began, in a low, timid voice, â€œIf you please, sirâ€”â€ The Rabbit started violently, dropped the white kid gloves and the fan, and skurried away into the darkness as hard as he could go.\n",
      "  **KOR**: ì´ ë•Œ ì–´ë””ì„ ê°€ ë°œìêµ­ ì†Œë¦¬ê°€ ë“¤ë ¸ë‹¤. ì•¨ë¦¬ìŠ¤ëŠ” ëˆˆë¬¼ì„ í›”ì¹˜ê³  ì–´ë–¤ ê²ƒì´ ë‹¤ê°€ì˜¤ë‚˜ ì‚´í´ë³´ì•˜ë‹¤. ì•„ê¹Œ ê·¸ í° í† ë¼ê°€ ëŒì•„ì˜¤ê³  ìˆì—ˆë‹¤. í† ë¼ëŠ” ê·¼ì‚¬í•œ ì˜·ì„ ì…ê³  í•œ ì†ì—” í° ì¥ê°‘ í•œ ìŒì„ ë“¤ê³  ë‹¤ë¥¸ ì†ì—” í° ë¶€ì±„ë¥¼ ë“¤ê³  ìˆì—ˆë‹¤. í† ë¼ëŠ” ê¹¡ì´ê±°ë¦¬ë©° ë§¤ìš° ê¸‰í•˜ê²Œ ë‹¤ê°€ì˜¤ë©° ì¤‘ì–¼ê±°ë ¸ë‹¤. â€œì•„, ê³µì‘ ë¶€ì¸, ê³µì‘ ë¶€ì¸. ë‚´ê°€ ê·¸ë…€ë¥¼ ê¸°ë‹¤ë¦¬ê²Œ í–ˆë‹¤ê°„ ê°€ë§Œ ë‘ì§€ ì•Šê² ì§€.â€\n",
      "\n",
      "--- [ìŒ 8] ---\n",
      "  **ENG**: Alice took up the fan and gloves, and, as the hall was very hot, she kept fanning herself all the time she went on talking: â€œDear, dear! How queer everything is to-day! And yesterday things went on just as usual. I wonder if Iâ€™ve been changed in the night? Let me think: was I the same when I got up this morning? I almost think I can remember feeling a little different. But if Iâ€™m not the same, the next question is, Who in the world am I? Ah, _thatâ€™s_ the great puzzle!â€ And she began thinking over all the children she knew that were of the same age as herself, to see if she could have been changed for any of them.\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ëŠ” ë¶€ì±„ì™€ ì¥ê°‘ì„ ì§‘ì–´ ë“¤ì—ˆë‹¤. ë°©ì´ ë„ˆë¬´ ë”ì›Œì„œ ì•¨ë¦¬ìŠ¤ëŠ” ë¶€ì±„ë¥¼ ë¶€ì¹˜ë©° ìŠ¤ìŠ¤ë¡œì—ê²Œ ë§í–ˆë‹¤. â€œì´ëŸ°, ì´ëŸ°. ì˜¤ëŠ˜ì€ ì°¸ ë³„ë‚œ ë‚ ì´ë‹¤! ì–´ì œëŠ” ëª¨ë“  ê²Œ ë‹¤ í‰ë²”í–ˆëŠ”ë°. ë°¤ë™ì•ˆ ë‚´ê°€ ë³€í•œê±¸ê¹Œ? ìƒê°í•´ ë³´ì. ë‚˜ëŠ” ì˜¤ëŠ˜ ì•„ì¹¨ ì¼ì–´ë‚¬ì„ ë•Œë‘ ë˜‘ê°™ì€ ë‚œê°€? ë‚œ ë­”ê°€ ì¡°ê¸ˆì€ ë‹¬ë¼ì§„ ê²ƒ ê°™ë‹¤ê³  ëŠê¼ˆë˜ ê±¸ ê¸°ì–µí•  ìˆ˜ ìˆë‹¤ê³  ìƒê°í•˜ëŠ”ë°. í•˜ì§€ë§Œ ë‚´ê°€ ì•„ì¹¨ì˜ ë‚˜ì™€ ê°™ì§€ ì•Šë‹¤ë©´, ë‹¤ìŒ ì§ˆë¬¸ì€, ê·¸ëŸ¼ ë‚˜ëŠ” ëˆ„êµ¬ì§€? ì•„! ì—„ì²­ ë³µì¡í•œ ìˆ˜ìˆ˜ê»˜ë¼ë‹¤.â€ ê·¸ëŸ¬ë©´ì„œ ì•¨ë¦¬ìŠ¤ëŠ” ìê¸°ì™€ ë¹„ìŠ·í•œ ë‚˜ì´ì˜ ì•„ì´ë“¤ì„ ë– ì˜¬ë¦¬ë©° í˜¹ì‹œ ê·¸ ì•„ì´ë“¤ ì¤‘ í•˜ë‚˜ë¡œ ë°”ë€ ê²ƒì€ ì•„ë‹Œì§€ ìƒê°í•´ë³´ì•˜ë‹¤.\n",
      "\n",
      "--- [ìŒ 9] ---\n",
      "  **ENG**: â€œIâ€™m sure Iâ€™m not Ada,â€ she said, â€œfor her hair goes in such long ringlets, and mine doesnâ€™t go in ringlets at all; and Iâ€™m sure I canâ€™t be Mabel, for I know all sorts of things, and she, oh! she knows such a very little! Besides, _sheâ€™s_ she, and _Iâ€™m_ I, andâ€”oh dear, how puzzling it all is! Iâ€™ll try if I know all the things I used to know. Let me see: four times five is twelve, and four times six is thirteen, and four times seven isâ€”oh dear! I shall never get to twenty at that rate! However, the Multiplication Table doesnâ€™t signify: letâ€™s try Geography. London is the capital of Paris, and Paris is the capital of Rome, and Romeâ€”no, _thatâ€™s_ all wrong, Iâ€™m certain! I must have been changed for Mabel! Iâ€™ll try and say â€˜_How doth the little_â€”â€™â€ and she crossed her hands on her lap as if she were saying lessons, and began to repeat it, but her voice sounded hoarse and strange, and the words did not come the same as they used to do:â€”\n",
      "  **KOR**: â€œë‚œ í™•ì‹¤íˆ ì—ì´ë”ëŠ” ì•„ëƒ.â€ ì•¨ë¦¬ìŠ¤ê°€ ë§í–ˆë‹¤. â€œê·¸ ì•  ë¨¸ë¦¬ì¹´ë½ì€ ë„ˆë¬´ ê¸´ ê³±ìŠ¬ë¨¸ë¦¬ì•¼. ë‚´ê»€ ê³±ìŠ¬ê±°ë¦¬ì§€ ì•Šì•„. ê·¸ë¦¬ê³ , ë‚´ê°€ ì•„ëŠ” í•œ, ë‚œ í™•ì‹¤íˆ ë©”ì´ë¸”ì´ ë  ìˆ˜ë„ ì—†ì–´. ê·¸ ì•¤ ë„ˆë¬´ ì•„ëŠ” ê²Œ ì—†ì–´. ê²Œë‹¤ê°€ ê·¸ ì•  ëŠ” ê·¸ ì• ê³  ë‚˜ ëŠ” ë‚˜ì–ì•„, ê·¸ë¦¬ê³ , ì–´â€¦ ì•„ì´ì¿ , ë­ë“  ì™œ ì´ë¦¬ ë³µì¡í•œ ìˆ˜ìˆ˜ê»˜ë¼ê°€ ë˜ëŠ” ê±°ì§€! ë‚´ê°€ ì•Œë˜ ê²ƒë“¤ì„ ì œëŒ€ë¡œ ë‹¤ ê¸°ì–µí•˜ê³  ìˆëŠ”ì§€ ë´ì•¼ê² ë‹¤. ì–´ë””ë³´ì, 4 ê³±í•˜ê¸° 5ëŠ” 12, ê·¸ë¦¬ê³  4 ê³±í•˜ê¸° 6ì€ 13, 4 ê³±í•˜ê¸° 7ì€â€¦, ì•„ì´ì¿  ì´ëŸ° ì‹ìœ¼ë¡œëŠ” 20ê¹Œì§€ëŠ” ì ˆëŒ€ ëª» ê°€ê² ëŠ”ë°! í•˜ì§€ë§Œ, êµ¬êµ¬ë‹¨ì€ ê·¸ë¦¬ ì¤‘ìš”í•œ ê²Œ ì•„ë‹ˆë‹ˆê¹Œ, ì§€ë¦¬ë¥¼ ìƒê°í•´ ë³¼ê¹Œ? ëŸ°ë˜ì€ íŒŒë¦¬ì˜ ìˆ˜ë„, íŒŒë¦¬ëŠ” ë¡œë§ˆì˜ ìˆ˜ë„ â€¦â€¦, ì•„ë‹ˆì•¼. ëª½ë•… í‹€ë ¸ì–´. í™•ì‹¤í•´! ë‚œ ì•„ë¬´ë˜ë„ ë©”ì´ë¸”ì´ ëœ ê²ƒ ê°™ì•„!\n",
      "\n",
      "--- [ìŒ 10] ---\n",
      "  **ENG**: â€œHow doth the little crocodile     Improve his shining tail, And pour the waters of the Nile     On every golden scale!\n",
      "  **KOR**: ì–´ì©œ ì´ë¦¬ ì‘ì€ ì•…ì–´ê°€    ì´ë ‡ê²Œ ë°˜ì§ì´ëŠ” ê¼¬ë¦¬ë¥¼ ì˜¬ë ¤ ë‚˜ì¼ê°•ì˜ ëª¨ë“  ê°•ë¬¼ì„   í™©ê¸ˆ ë¹„ëŠ˜ì— ê³³ê³³ì— í©ë¿Œë¦¬ëŠ”ì§€\n",
      "\n",
      "--- [ìŒ 11] ---\n",
      "  **ENG**: â€œHow cheerfully he seems to grin,     How neatly spread his claws, And welcome little fishes in     With gently smiling jaws!â€\n",
      "  **KOR**: ì–´ì©œ ì €ë¦¬ ë°©ë— ì›ƒëŠ”ì§€   ë‚ ì¹´ë¡œìš´ ë°œí†±ì„ ê°€ì§€ëŸ°íˆ í´ê³ ì„œ ë¬¼ê³ ê¸°ë“¤ì„ ë°˜ê¸°ì§€   ì¹œì ˆí•˜ê²Œ ì›ƒìŒ ì§“ëŠ” ì… ì†ìœ¼ë¡œ\n",
      "\n",
      "--- [ìŒ 12] ---\n",
      "  **ENG**: â€œIâ€™m sure those are not the right words,â€ said poor Alice, and her eyes filled with tears again as she went on, â€œI must be Mabel after all, and I shall have to go and live in that poky little house, and have next to no toys to play with, and oh! ever so many lessons to learn! No, Iâ€™ve made up my mind about it; if Iâ€™m Mabel, Iâ€™ll stay down here! Itâ€™ll be no use their putting their heads down and saying â€˜Come up again, dear!â€™ I shall only look up and say â€˜Who am I then? Tell me that first, and then, if I like being that person, Iâ€™ll come up: if not, Iâ€™ll stay down here till Iâ€™m somebody elseâ€™â€”but, oh dear!â€ cried Alice, with a sudden burst of tears, â€œI do wish they _would_ put their heads down! I am so _very_ tired of being all alone here!â€\n",
      "  **KOR**: â€œì´ê±´ í™•ì‹¤íˆ ì œëŒ€ë¡œ ëœ ë‚´ìš©ì´ ì•„ë‹ˆì•¼.â€ ê°€ì—¬ìš´ ì•¨ë¦¬ìŠ¤ëŠ” ë‹¤ì‹œ ìš¸ê¸° ì‹œì‘í–ˆë‹¤. â€œ ë©”ì´ë¸”ì´ ëœ ê²Œ í‹€ë¦¼ì—†ì–´. ê·¸ë¦¬ê³  ê·¸ í—ˆë¦„í•œ ì§‘ì— ë“¤ì–´ê°€ ì‚´ê²Œ ë˜ê² ì§€. ì¥ë‚œê°ë„ ì—†ê³  ë†€ì§€ë„ ëª»í•  ê±°ì•¼. ì•„! ê·¸ë¦¬ê³  ì—„ì²­ë‚˜ê²Œ ê³µë¶€ë§Œ ë°°ìš°ê²Œ ë ê±°ì•¼. ì•„ëƒ, ë‚œ ë§ˆìŒì„ ì •í–ˆì–´. ë‚´ê°€ ë©”ì´ë¸”ì´ë¼ë©´ ê·¸ëƒ¥ ì—¬ê¸°ì— ìˆì„ ê±°ì•¼! ì‚¬ëŒë“¤ì´ êµ¬ë©ì— ê³ ê°œë¥¼ ë„£ê³  â€˜ì–˜ì•¼ ì–´ì„œ ë‹¤ì‹œ ì˜¬ë¼ì˜¤ë ´â€™ í•´ë„ ë‚˜ëŠ” â€˜ê·¸ëŸ¼ ì œê°€ ëˆ„êµ¬ì£ ? ë¨¼ì € ë§í•´ì£¼ì„¸ìš”.â€™ ë¼ê³  í• êº¼ì•¼. â€˜ë§Œì•½ ê·¸ ì‚¬ëŒì´ ë˜ëŠ”ê²Œ ë‚´ ë§ˆìŒì— ë“¤ë©´ ì˜¬ë¼ê°ˆ ê±°ì§€ë§Œ, ì•„ë‹ˆë©´ ê·¸ëƒ¥ ì—¬ê¸° ìˆì„ë˜. ë‹¤ì‹œ ë‹¤ë¥¸ ì‚¬ëŒì´ ë  ë•Œê¹Œì§€.â€™ í•´ì•¼ì§€. í•˜ì§€ë§Œ, ì´ëŸ°!â€ ì•¨ë¦¬ìŠ¤ëŠ” ê°‘ìê¸° ìš¸ìŒì„ í„°ëœ¨ë ¸ë‹¤. â€œê·¸ëƒ¥ ì‚¬ëŒë“¤ì´ êµ¬ë©ì— ë¨¸ë¦¬ë‚˜ ë””ë°€ì–´ ì¤¬ìœ¼ë©´! ì—¬ê¸° í˜¼ì ìˆì–´ì„œ ë„ˆë¬´ ë„ˆë¬´ ì§€ì³¤ì–´.â€\n",
      "\n",
      "--- [ìŒ 13] ---\n",
      "  **ENG**: As she said this she looked down at her hands, and was surprised to see that she had put on one of the Rabbitâ€™s little white kid gloves while she was talking. â€œHow _can_ I have done that?â€ she thought. â€œI must be growing small again.â€ She got up and went to the table to measure herself by it, and found that, as nearly as she could guess, she was now about two feet high, and was going on shrinking rapidly: she soon found out that the cause of this was the fan she was holding, and she dropped it hastily, just in time to avoid shrinking away altogether.\n",
      "  **KOR**: ì´ë ‡ê²Œ ë§í•˜ë©° ì•¨ë¦¬ìŠ¤ëŠ” ìê¸° ì†ì„ ë‚´ë ¤ë‹¤ ë³´ì•˜ë‹¤. ê·¸ë¦¬ê³ ëŠ” í† ë¼ì˜ ì‘ì€ í° ì¥ê°‘ ì¤‘ í•˜ë‚˜ê°€ ì†ì— ë¼ì›Œì ¸ ìˆëŠ” ê²ƒì„ ë°œê²¬í•˜ê³  ë†€ëë‹¤. â€œë‚´ê°€ ì´ê±¸ ì–´ë–»ê²Œ í•œê±°ì§€?â€ ì•¨ë¦¬ìŠ¤ëŠ” ìƒê°í–ˆë‹¤. â€œë‹¤ì‹œ ì‘ì•„ì§„ ê²Œ í‹€ë¦¼ì—†ì–´.â€ ì•¨ë¦¬ìŠ¤ëŠ” ì¼ì–´ë‚˜ ìê¸° í‚¤ë¥¼ íƒìì™€ ê²¬ì£¼ì–´ ë³´ì•˜ë‹¤. ì•¨ë¦¬ìŠ¤ê°€ ìƒê°í–ˆë˜ëŒ€ë¡œ ì•¨ë¦¬ìŠ¤ì˜ í‚¤ëŠ” ì•½ 2 í”¼íŠ¸ ì •ë„ ë˜ì—ˆê³  ê·¸ëŸ¬ëŠ” ì‚¬ì´ì—ë„ í‚¤ëŠ” ë¹ ë¥´ê²Œ ì¤„ì–´ë“¤ê³  ìˆì—ˆë‹¤. ì•¨ë¦¬ìŠ¤ëŠ” ê¸ˆìƒˆ ê°€ì§€ê³  ìˆë˜ ë¶€ì±„ê°€ í‚¤ë¥¼ ì¤„ì–´ë“¤ê²Œ í•œ ê²ƒì„ ì•Œì•„ì±„ê³ ëŠ” ì™„ì „íˆ ìª¼ê·¸ë¼ë“¤ê¸° ì§ì „ì— ì¬ë¹¨ë¦¬ ë¶€ì±„ë¥¼ ë–¨ì–´ëœ¨ë ¸ë‹¤.\n",
      "\n",
      "--- [ìŒ 14] ---\n",
      "  **ENG**: â€œThat _was_ a narrow escape!â€ said Alice, a good deal frightened at the sudden change, but very glad to find herself still in existence; â€œand now for the garden!â€ and she ran with all speed back to the little door: but, alas! the little door was shut again, and the little golden key was lying on the glass table as before, â€œand things are worse than ever,â€ thought the poor child, â€œfor I never was so small as this before, never! And I declare itâ€™s too bad, that it is!â€\n",
      "  **KOR**: â€œì•„ìŠ¬ì•„ìŠ¬ í–ˆì–´!â€ í•˜ê³  ì•¨ë¦¬ìŠ¤ê°€ ë§í–ˆë‹¤. ê°‘ì‘ìŠ¤ëŸ¬ìš´ ë³€í™”ì— ê²ì„ ë¨¹ê¸°ëŠ” í–ˆì§€ë§Œ ì™„ì „íˆ ì‚¬ë¼ì§€ì§€ ì•Šì•˜ë‹¤ëŠ” ê²ƒì´ ê¸°ë»¤ë‹¤. â€œê·¸ëŸ¼, ì´ì œ ì •ì›ìœ¼ë¡œ!â€ ì•¨ë¦¬ìŠ¤ëŠ” ì „ì†ë ¥ìœ¼ë¡œ ì‘ì€ ë¬¸ì„ í–¥í•´ ë‹¬ë ¸ë‹¤. ì•„ë¿”ì‹¸! ì‘ì€ ë¬¸ì€ ê·¸ ìƒˆ ë‹«í˜€ ìˆì—ˆê³ , ì‘ì€ í™©ê¸ˆ ì—´ì‡ ëŠ” ì—¬ì „íˆ íƒì ìœ„ì— ë†“ì—¬ ìˆì—ˆë‹¤. â€œë” ë‚˜ë¹ ì§€ê¸°ë§Œ í–ˆì–ì•„!â€ ì•¨ë¦¬ìŠ¤ëŠ” ìƒê°í–ˆë‹¤. â€œë‚œ ì´ë ‡ê²Œ ì‘ì•˜ë˜ ì ì´ ì—†ì–´. í•œ ë²ˆë„! ì´ê±´ ì •ë§ ë‚˜ë¹ , ë‚˜ì˜ë‹¤êµ¬!â€\n",
      "\n",
      "--- [ìŒ 15] ---\n",
      "  **ENG**: As she said these words her foot slipped, and in another moment, splash! she was up to her chin in salt water. Her first idea was that she had somehow fallen into the sea, â€œand in that case I can go back by railway,â€ she said to herself. (Alice had been to the seaside once in her life, and had come to the general conclusion, that wherever you go to on the English coast you find a number of bathing machines in the sea, some children digging in the sand with wooden spades, then a row of lodging houses, and behind them a railway station.) However, she soon made out that she was in the pool of tears which she had wept when she was nine feet high.\n",
      "  **KOR**: â€œê·¸ëŸ¬ë©´ ë‚œ ê¸°ì°¨ë¥¼ íƒ€ê³  ëŒì•„ê°€ì•¼ì§€.â€ ì•¨ë¦¬ìŠ¤ëŠ” ìƒê°í–ˆë‹¤.(ì•¨ë¦¬ìŠ¤ëŠ” ë”± í•œ ë²ˆ ë°”ë‹·ê°€ì— ê°„ ì ì´ ìˆì—ˆë‹¤. ê±°ê¸°ì„œ ì˜êµ­ í•´ì•ˆì´ë¼ë©´ ì–´ë””ë‚˜ ì—¬ëŸ¬ ê°œì˜ ì˜·ì„ ê°ˆì•„ì…ëŠ” ê³µê°„ì´ ë°”ë‹¤ ìœ„ì— ë– ìˆê³ , ì•„ì´ë“¤ì´ ë‚˜ë¬´ ì‚½ìœ¼ë¡œ ëª¨ë˜ ë†€ì´ë¥¼ í•˜ë©°, ê·¸ ë’¤ì— ì¤„ì¤„ì´ ìˆ™ì†Œê°€ ìˆê³ , ê·¸ ë’¤ë¡œ ê¸°ì°¨ì—­ì´ ìˆë‹¤ê³  ìƒê°í•˜ê²Œ ë˜ì—ˆë‹¤.) ì•¨ë¦¬ìŠ¤ëŠ” ì–¼ë§ˆ ì§€ë‚˜ì§€ ì•Šì•„ ì´ê²Œ ì‚¬ì‹¤ì€ ìê¸° í‚¤ê°€ 9í”¼íŠ¸ì¼ ë•Œ í˜ë ¸ë˜ ëˆˆë¬¼ì´ ë§Œë“  ì›…ë©ì´ë¼ëŠ” ê²ƒì„ ê¹¨ë‹¬ì•˜ë‹¤.\n",
      "\n",
      "--- [ìŒ 16] ---\n",
      "  **ENG**: â€œI wish I hadnâ€™t cried so much!â€ said Alice, as she swam about, trying to find her way out. â€œI shall be punished for it now, I suppose, by being drowned in my own tears! That _will_ be a queer thing, to be sure! However, everything is queer to-day.â€\n",
      "  **KOR**: ì›…ë©ì´ë¥¼ í—¤ì—„ì¹˜ë©° ë¹ ì ¸ ë‚˜ê°ˆ ê³³ì„ ì°¾ìœ¼ë©° ì•¨ë¦¬ìŠ¤ëŠ” â€œê·¸ë ‡ê²Œ ë§ì´ ìš¸ì§€ ë§ê»„!â€í•˜ê³  ë§í–ˆë‹¤. â€œë‚´ê°€ ê·¸ë ‡ê²Œ ë§ì€ ëˆˆë¬¼ì„ í˜ë ¤ì„œ ë‚´ ëˆˆë¬¼ì— ë¹ ì ¸ ì£½ê²Œ ë˜ëŠ” ë²Œì„ ë°›ëŠ” ê±¸ ê±°ì•¼. ì§„ì§œ ì´ìƒí•œ ì¼ì´ë‹¤. í•˜ì§€ë§Œ ì˜¤ëŠ˜ì€ ëª¨ë“  ê²Œ ë‹¤ ì´ìƒí•œ ë‚ ì¸ê±¸.â€\n",
      "\n",
      "--- [ìŒ 17] ---\n",
      "  **ENG**: Just then she heard something splashing about in the pool a little way off, and she swam nearer to make out what it was: at first she thought it must be a walrus or hippopotamus, but then she remembered how small she was now, and she soon made out that it was only a mouse that had slipped in like herself.\n",
      "  **KOR**: ê·¸ ë•Œ ì–´ë””ì„ ê°€ ì²¨ë²™ê±°ë¦¬ëŠ” ì†Œë¦¬ê°€ ë“¤ë ¸ë‹¤. ì•¨ë¦¬ìŠ¤ëŠ” ê·¸ê²Œ ë¬´ì—‡ì¸ì§€ ì•Œì•„ë³´ë ¤ í—¤ì—„ì³ ë‹¤ê°€ê°”ë‹¤. ì•¨ë¦¬ìŠ¤ëŠ” ì²˜ìŒì— ê·¸ê²ƒì´ ë°”ë‹¤ì½”ë¼ë¦¬ ì´ê±°ë‚˜ í•˜ë§ˆì¼ ê²ƒì´ë¼ê³  ìƒê°í–ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì•¨ë¦¬ìŠ¤ëŠ” ìì‹ ì´ ì‘ì•„ì§„ ê²ƒì„ ë– ì˜¬ë¦¬ê³ ëŠ” í—¤ì—„ì³ ì˜¤ëŠ” ë™ë¬¼ì´ ì•¨ë¦¬ìŠ¤ì²˜ëŸ¼ ì›…ë©ì´ì— ë¯¸ë„ëŸ¬ì§„ ìƒì¥ë¼ëŠ” ê²ƒì„ ì•Œì•˜ë‹¤.\n",
      "\n",
      "--- [ìŒ 18] ---\n",
      "  **ENG**: â€œWould it be of any use, now,â€ thought Alice, â€œto speak to this mouse? Everything is so out-of-the-way down here, that I should think very likely it can talk: at any rate, thereâ€™s no harm in trying.â€ So she began: â€œO Mouse, do you know the way out of this pool? I am very tired of swimming about here, O Mouse!â€ (Alice thought this must be the right way of speaking to a mouse: she had never done such a thing before, but she remembered having seen in her brotherâ€™s Latin Grammar, â€œA mouseâ€”of a mouseâ€”to a mouseâ€”a mouseâ€”O mouse!â€) The Mouse looked at her rather inquisitively, and seemed to her to wink with one of its little eyes, but it said nothing.\n",
      "  **KOR**: â€œì´ ìƒì¥ë‘ ì´ì•¼ê¸°í•˜ëŠ” ê²Œ ë„ì›€ì´ ë ê¹Œ?â€ì•¨ë¦¬ìŠ¤ëŠ” ìƒê°í–ˆë‹¤. â€œì—¬ê¸´ ëª¨ë“  ê²Œ ë‹¤ ì´ìƒí•˜ë‹ˆê¹Œ, ìƒì¥ë„ ë§í•  ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„. ì–´ì¨Œë“ , ì‹œë„ í•´ ë³´ëŠ” ê²Œ ë‚˜ì  ê²ƒë„ ì—†ì§€.â€ ê·¸ë¦¬ê³ ëŠ” ì•¨ë¦¬ìŠ¤ê°€ ìƒì¥ì—ê²Œ ë§ì„ ê±¸ì—ˆë‹¤. â€œì˜¤, ìƒì¥ì•¼. ì´ ì›…ë©ì´ë¥¼ ë¹ ì ¸ë‚˜ê°ˆ ê¸¸ì„ ì•„ë‹ˆ? ìˆ˜ì˜í•˜ëŠë¼ ë„ˆë¬´ í˜ë“¤ì–´. ì˜¤, ìƒì¥ì•¼.â€ (ì•¨ë¦¬ìŠ¤ëŠ” ì´ê²Œ ìƒì¥ì—ê²Œ ë§ì„ ê±°ëŠ” ì•Œë§ì€ ë°©ë²•ì´ë¼ê³  ìƒê°í–ˆë‹¤. ì•¨ë¦¬ìŠ¤ëŠ” ì˜ˆì „ì— í•œ ë²ˆë„ ìƒì¥ë‘ ë§ì„ í•´ ë³´ì§€ëŠ” ì•Šì•˜ì§€ë§Œ, ì˜ˆì „ì— ì˜¤ë¹ ê°€ ë¼í‹´ì–´ ë¬¸ë²•ì„ ë°°ìš°ë©° â€œì•„ ì–´ ë§ˆìš°ìŠ¤ - íˆ¬ ë§ˆìš°ìŠ¤, ì•„ ë§ˆìš°ìŠ¤ - ì˜¤ ë§ˆìš°ìŠ¤â€í•˜ê³  ë§í–ˆë˜ ê²ƒì´ ê¸°ì–µë‚¬ê¸° ë•Œë¬¸ì´ì—ˆë‹¤.) ìƒì¥ëŠ” ëª¹ì‹œ ê¶ê¸ˆí•´í•˜ëŠ” í‘œì •ìœ¼ë¡œ ì•¨ë¦¬ìŠ¤ë¥¼ ë°”ë¼ë³´ê³ ëŠ” í•œ ìª½ ëˆˆì„ ì°¡ë— í•œë“¯ í–ˆì§€ë§Œ, ì•„ë¬´ëŸ° ë§ë„ í•˜ì§€ ì•Šì•˜ë‹¤.\n",
      "\n",
      "--- [ìŒ 19] ---\n",
      "  **ENG**: â€œPerhaps it doesnâ€™t understand English,â€ thought Alice; â€œI daresay itâ€™s a French mouse, come over with William the Conqueror.â€ (For, with all her knowledge of history, Alice had no very clear notion how long ago anything had happened.) So she began again: â€œOÃ¹ est ma chatte?â€ which was the first sentence in her French lesson-book. The Mouse gave a sudden leap out of the water, and seemed to quiver all over with fright. â€œOh, I beg your pardon!â€ cried Alice hastily, afraid that she had hurt the poor animalâ€™s feelings. â€œI quite forgot you didnâ€™t like cats.â€\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ëŠ” â€œì•„ë§ˆë„ ì˜ì–´ë¥¼ ëª» ì•Œì•„ ë“£ë‚˜ë´. ì •ë³µì ìœŒë¦¬ì—„ì´ë‘ í•¨ê»˜ ê±´ë„ˆì˜¨ í”„ë‘ìŠ¤ ì¥ì¸ê°€?â€í•˜ê³  ìƒê°í–ˆë‹¤.(ì•¨ë¦¬ìŠ¤ëŠ” ì—­ì‚¬ì— ì“°ì¸ ì¼ë“¤ì´ ì •í™•íˆ ì–¸ì œ ìˆì—ˆê³  ì–¼ë§ˆë‚˜ ì˜¤ë˜ ëœ ì¼ì¸ì§€ ì˜ ì•Œì§€ ëª»í–ˆë‹¤.) ê·¸ë˜ì„œ ì•¨ë¦¬ìŠ¤ëŠ” í”„ë‘ìŠ¤ì–´ë¡œ ë§í–ˆë‹¤. â€œìš° ì— ë§ˆ ìƒ¤íŠ¸(ë‚´ ê³ ì–‘ì´ëŠ” ì–´ë””ì— ìˆì§€?)?â€ ì•¨ë¦¬ìŠ¤ì˜ í”„ë‘ìŠ¤ì–´ êµê³¼ì„œ ì²˜ìŒì— ì íŒ ë¬¸ì¥ì´ì—ˆë‹¤. ìˆœê°„ ìƒì¥ëŠ” í„ì© ë›°ì–´ ì˜¬ëê³  ë‘ë ¤ì›Œì„œ ë²Œë²Œ ë– ëŠ” ê²ƒ ì²˜ëŸ¼ ë³´ì˜€ë‹¤. ì•¨ë¦¬ìŠ¤ëŠ” ìì‹ ì´ ê°€ì—¬ìš´ ë™ë¬¼ì˜ ë§ˆìŒì„ ìƒí•˜ê²Œ í•œ ê²ƒ ê°™ì•„ ë‹¤ê¸‰íˆ ì™¸ì³¤ë‹¤. â€œìš©ì„œí•´ì¤˜! ë„Œ ê³ ì–‘ì´ë¥¼ ì¢‹ì•„í•˜ì§€ ì•ŠëŠ” ë‹¤ëŠ” ê±¸ ìŠì—ˆì–´.â€\n",
      "\n",
      "--- [ìŒ 20] ---\n",
      "  **ENG**: â€œNot like cats!â€ cried the Mouse, in a shrill, passionate voice. â€œWould _you_ like cats if you were me?â€\n",
      "  **KOR**: ìƒì¥ê°€ ë‚ ì¹´ë¡­ê³  í° ì†Œë¦¬ë¡œ ëŒ€ë‹µí–ˆë‹¤. â€œê³ ì–‘ì´ ì‹«ë‹¤! ë„¤ê°€ ë‚˜ë¼ë©´ ê³ ì–‘ì´ê°€ ì¢‹ê² ë‹ˆ?â€\n",
      "\n",
      "--- [ìŒ 21] ---\n",
      "  **ENG**: â€œWell, perhaps not,â€ said Alice in a soothing tone: â€œdonâ€™t be angry about it. And yet I wish I could show you our cat Dinah: I think youâ€™d take a fancy to cats if you could only see her. She is such a dear quiet thing,â€ Alice went on, half to herself, as she swam lazily about in the pool, â€œand she sits purring so nicely by the fire, licking her paws and washing her faceâ€”and she is such a nice soft thing to nurseâ€”and sheâ€™s such a capital one for catching miceâ€”oh, I beg your pardon!â€ cried Alice again, for this time the Mouse was bristling all over, and she felt certain it must be really offended. â€œWe wonâ€™t talk about her any more if youâ€™d rather not.â€\n",
      "  **KOR**: â€œìŒ, ì•„ë§ˆ ì•ˆ ì¢‹ì•„í•  ê±°ì•¼.â€í•˜ê³  ì•¨ë¦¬ìŠ¤ëŠ” ìƒì¥ë¥¼ ë‹¬ë¬ë‹¤. â€œí™”ë‚´ì§€ ë§ˆ. ë‚œ ìš°ë¦¬ ê³ ì–‘ì´ ë””ë‚˜ê°€ ë³´ê³  ì‹¶ì–´. ë„ˆë„ ë””ë‚˜ë¥¼ ë³´ë©´ ì¢‹ì•„í•˜ê²Œ ë  êº¼ì•¼. ì •ë§ ì‚¬ë‘ìŠ¤ëŸ½ê±°ë“ .â€ì•¨ë¦¬ìŠ¤ëŠ” ë°˜ì¯¤ì€ ìŠ¤ìŠ¤ë¡œì—ê²Œ ë§í•˜ë©° ì²œì²œíˆ í—¤ì—„ì³¤ë‹¤.\n",
      "\n",
      "--- [ìŒ 22] ---\n",
      "  **ENG**: â€œWe indeed!â€ cried the Mouse, who was trembling down to the end of his tail. â€œAs if _I_ would talk on such a subject! Our family always _hated_ cats: nasty, low, vulgar things! Donâ€™t let me hear the name again!â€\n",
      "  **KOR**: â€œë‹¹ì—°íˆ!â€í•˜ê³  ìƒì¥ê°€ ëŠ˜ì–´ëœ¨ë¦° ê¼¬ë¦¬ ëì„ ë–¨ë©´ì„œ í° ì†Œë¦¬ë¡œ ë§í–ˆë‹¤. â€œê·¸ëŸ° ì–˜ê¸°ëŠ” ê´€ë‘ì! ìš°ë¦¬ ê°€ë¬¸ì€ ê³ ì–‘ì´ ê°™ì€ ë”ëŸ½ê³  ì²œí•œ ë¬´ì‹í•œ ê²ƒë“¤ì€ ì‹«ì–´í•´! ë‹¤ì‹  ê·¸ ì–˜ê¸°í•˜ì§€ ë§ˆ!â€\n",
      "\n",
      "--- [ìŒ 23] ---\n",
      "  **ENG**: â€œI wonâ€™t indeed!â€ said Alice, in a great hurry to change the subject of conversation. â€œAre youâ€”are you fondâ€”ofâ€”of dogs?â€ The Mouse did not answer, so Alice went on eagerly: â€œThere is such a nice little dog near our house I should like to show you! A little bright-eyed terrier, you know, with oh, such long curly brown hair! And itâ€™ll fetch things when you throw them, and itâ€™ll sit up and beg for its dinner, and all sorts of thingsâ€”I canâ€™t remember half of themâ€”and it belongs to a farmer, you know, and he says itâ€™s so useful, itâ€™s worth a hundred pounds! He says it kills all the rats andâ€”oh dear!â€ cried Alice in a sorrowful tone, â€œIâ€™m afraid Iâ€™ve offended it again!â€ For the Mouse was swimming away from her as hard as it could go, and making quite a commotion in the pool as it went.\n",
      "  **KOR**: â€œì•Œì•˜ì–´.â€ ì•¨ë¦¬ìŠ¤ëŠ” ì¬ë¹¨ë¦¬ í™”ì œë¥¼ ëŒë ¸ë‹¤. â€œë„ˆ -- ë„ˆëŠ” ê°œ -- ê°œëŠ” ì¢‹ì•„í•˜ë‹ˆ?â€ ìƒì¥ê°€ ì•„ë¬´ ë§ë„ í•˜ì§€ ì•Šì ì•¨ë¦¬ìŠ¤ëŠ” ì—´ì‹¬íˆ ë§í–ˆë‹¤. â€œì§„ì§œ ë©‹ì§„ ê°œê°€ ìš°ë¦¬ ì˜† ì§‘ì— ì‚¬ëŠ”ë°. ë‚œ ê·¸ ê°œë¥¼ ë³´ëŠ” ê²Œ ì •ë§ ì¢‹ì•„. ìˆì–ì•„, ê±˜ ëˆˆì´ ë°˜ì§ê±°ë¦¬ëŠ” í…Œë¦¬ì–´ì•¼. ì•„, ê³±ìŠ¬ê±°ë¦¬ëŠ” ê°ˆìƒ‰ í„¸! ë¬´ì–¼ ë˜ì§€ë©´ ë‹¬ë ¤ê°€ì„œ ë‹¤ì‹œ ì£¼ì›Œì™€. ê·¸ë¦¬ê³¤ ì•‰ì•„ì„œ ë¨¹ì„ ê±¸ ë‹¬ë¼ê³  í•´. ê·¸ë¦¬ê³  ë©‹ì§„ ì ì´ ì•„ì£¼ ë§ì•„ -- ë°˜ë„ ê¸°ì–µì´ ì•ˆë‚œì§€ë§Œ. ìˆì–ì•„, ê·¸ë¦¬ê³  ê·¸ ê°œëŠ” ë†ë¶€ ì•„ì €ì”¨ê°€ ê¸¸ëŸ¬. ë†ë¶€ ì•„ì €ì”¨ëŠ” ê·¸ ê°œê°€ ì •ë§ ì“¸ëª¨ ìˆê³ , ê°’ë„ ëª‡ ë°± íŒŒìš´ë“œë‚˜ ë˜ëŠ” ì¢‹ì€ ê°œë¬ì–´! ë†ë¶€ ì•„ì €ì”¨ëŠ” ê·¸ ê°œê°€ ì¥ë„ ì˜ ì¡ê³  ë˜ -- ì•„ì´ì¿ !â€ ì•¨ë¦¬ìŠ¤ëŠ” ë¯¸ì•ˆí•œ ëª©ì†Œë¦¬ë¡œ ë§í–ˆë‹¤. â€œë‚´ê°€ ë˜ ë„¤ ë§ˆìŒì„ ìƒí•˜ê²Œ í–ˆë‚˜ë´!â€ ìƒì¥ëŠ” ì²¨ë²™ê±°ë¦¬ë©° ë¬¼ì‚´ì„ ë§Œë“¤ë©´ì„œ ì˜¨ í˜ì„ ë‹¤í•´ ë©€ë¦¬ í—¤ì—„ì³ ê°€ê³  ìˆì—ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 24] ---\n",
      "  **ENG**: So she called softly after it, â€œMouse dear! Do come back again, and we wonâ€™t talk about cats or dogs either, if you donâ€™t like them!â€ When the Mouse heard this, it turned round and swam slowly back to her: its face was quite pale (with passion, Alice thought), and it said in a low trembling voice, â€œLet us get to the shore, and then Iâ€™ll tell you my history, and youâ€™ll understand why it is I hate cats and dogs.â€\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ëŠ” ë¶€ë“œëŸ¬ìš´ ëª©ì†Œë¦¬ë¡œ â€œìƒì¥ì•¼! ëŒì•„ì™€. ì‹«ì–´í•˜ë©´ ê³ ì–‘ì´ë‚˜ ê°œ ì–˜ê¸´ ì•ˆí• ê»˜.â€í•˜ê³  ë§í–ˆë‹¤. ìƒì¥ëŠ” ê·¸ ì†Œë¦¬ë¥¼ ë“£ê³  ì²œì²œíˆ í—¤ì—„ì³ ëŒì•„ì™”ë‹¤. ìƒì¥ì˜ ì–¼êµ´ì€ ì°½ë°±í–ˆë‹¤.(ì•¨ë¦¬ìŠ¤ëŠ” í™”ë‚œ ê²ƒ ê°™ì•„ ë³´ì¸ë‹¤ê³  ìƒê°í–ˆë‹¤.) ìƒì¥ëŠ” ë–¨ë¦¬ëŠ” ëª©ì†Œë¦¬ë¡œ ë§í–ˆë‹¤. â€œì¼ë‹¨ ì›…ë©ì´ë¥¼ ë²—ì–´ë‚˜ì. ê·¸ëŸ¼ ë‚´ ì´ì•¼ê¸°ë¥¼ í•´ ì¤„ê»˜. ê·¸ëŸ¬ë©´ ë„ˆë„ ë‚´ê°€ ì™œ ê³ ì–‘ì´ë‘ ê°œë¥¼ ì‹«ì–´í•˜ëŠ” ì§€ ì•Œê²Œ ë êº¼ì•¼.â€\n",
      "\n",
      "--- [ìŒ 25] ---\n",
      "  **ENG**: It was high time to go, for the pool was getting quite crowded with the birds and animals that had fallen into it: there were a Duck and a Dodo, a Lory and an Eaglet, and several other curious creatures. Alice led the way, and the whole party swam to the shore.\n",
      "  **KOR**: í•œ ì°¸ì„ ê°€ë‹¤ë³´ë‹ˆ, ì›…ë©ì´ì—” ë‹¤ë¥¸ ë™ë¬¼ê³¼ ìƒˆë“¤ë„ ë¹ ì ¸ ìˆì—ˆë‹¤. ì˜¤ë¦¬ í•œ ë§ˆë¦¬, ë„ë„ìƒˆ í•œ ë§ˆë¦¬, ì‰ê¼¬ í•œ ë§ˆë¦¬, ì–´ë¦° ë…ìˆ˜ë¦¬ í•œ ë§ˆë¦¬, ê·¸ë¦¬ê³  ì‹ ê¸°í•œ ë™ë¬¼ë“¤ ëª‡ ë§ˆë¦¬ê°€ ìˆì—ˆë‹¤. ì•¨ë¦¬ìŠ¤ëŠ” ì•ì¥ì„œì„œ ì´ ë™ë¬¼ë“¤ê³¼ í—¤ì—„ì³ ì›…ë©ì´ë¥¼ ë¹ ì ¸ ë‚˜ì™”ë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- 0. ì„¤ì • ---\n",
    "FILE_NAME = 'day1_paragraph_aligned_data.npz'\n",
    "NUM_SAMPLES_TO_SHOW = 5 # í™•ì¸í•  ë¬¸ì¥ ìŒì˜ ê°œìˆ˜\n",
    "\n",
    "try:\n",
    "    # Day 1 ê²°ê³¼ íŒŒì¼ ë¡œë“œ\n",
    "    day1_data = np.load(FILE_NAME, allow_pickle=True)\n",
    "    \n",
    "    print(f\"--- Day 1 ë°ì´í„° '{FILE_NAME}' ë‚´ìš© í™•ì¸ ---\")\n",
    "    \n",
    "    # 1. íŒŒì¼ì— ì €ì¥ëœ ë³€ìˆ˜(í‚¤) ëª©ë¡ í™•ì¸\n",
    "    print(\"ì €ì¥ëœ ë³€ìˆ˜ ì´ë¦„:\", day1_data.files)\n",
    "\n",
    "    # 2. ì„ë² ë”© í¬ê¸° í™•ì¸\n",
    "    eng_embs_shape = day1_data['eng_embs'].shape\n",
    "    print(f\"ì „ì²´ ì •ë ¬ ìŒ ê°œìˆ˜ (N): {eng_embs_shape[0]}\")\n",
    "    print(f\"ì„ë² ë”© ì°¨ì› (D): {eng_embs_shape[1]}\")\n",
    "    \n",
    "    # 3. ì •ë ¬ëœ ë¬¸ì¥ ìŒ ë¡œë“œ\n",
    "    eng_sents = day1_data['eng_sents']\n",
    "    kor_sents = day1_data['kor_sents']\n",
    "    \n",
    "    # 4. ì •ë ¬ëœ ë¬¸ì¥ ìŒ ì¶œë ¥ (ë§¤í•‘ í™•ì¸)\n",
    "    print(f\"\\nâœ… ì •ë ¬ëœ ë¬¸ì¥ ìŒ {NUM_SAMPLES_TO_SHOW}ê°œ í™•ì¸ (ë§¤í•‘ ê²°ê³¼):\")\n",
    "    \n",
    "    for i in range(len(eng_sents)):\n",
    "        print(f\"\\n--- [ìŒ {i+1}] ---\")\n",
    "        print(f\"  **ENG**: {eng_sents[i]}\")\n",
    "        print(f\"  **KOR**: {kor_sents[i]}\")\n",
    "        \n",
    "    # 5. ë©”ëª¨ë¦¬ í•´ì œ\n",
    "    day1_data.close()\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"ì˜¤ë¥˜: '{FILE_NAME}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Day 1 ì½”ë“œë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ íŒŒì¼ì„ ìƒì„±í•˜ì‹­ì‹œì˜¤.\")\n",
    "except KeyError as e:\n",
    "    print(f\"ì˜¤ë¥˜: í•„ìš”í•œ ë³€ìˆ˜({e})ê°€ íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤. Day 1 ì½”ë“œê°€ ì •ìƒì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì‹­ì‹œì˜¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc08d8e8",
   "metadata": {},
   "source": [
    "## Sentence Normal Aligned npz Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c38fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Day 1 ë°ì´í„° 'day1_paragraph.npz' ë‚´ìš© í™•ì¸ ---\n",
      "ì €ì¥ëœ ë³€ìˆ˜ ì´ë¦„: ['eng_sents', 'kor_sents']\n",
      "\n",
      "âœ… ì •ë ¬ëœ ë¬¸ì¥ ìŒ 5ê°œ í™•ì¸ (ë§¤í•‘ ê²°ê³¼):\n",
      "\n",
      "--- [ìŒ 1] ---\n",
      "  **ENG**: The Pool of Tears\n",
      "  **KOR**: ì œ2ì¥ ëˆˆë¬¼ ì›…ë©ì´\n",
      "\n",
      "--- [ìŒ 2] ---\n",
      "  **ENG**: â€œCuriouser and curiouser!â€\n",
      "  **KOR**: â€œìš”ìƒí•˜ê³ ë„ ìš”ìƒí•´!â€\n",
      "\n",
      "--- [ìŒ 3] ---\n",
      "  **ENG**: cried Alice\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ëŠ” ì†Œë¦¬ì³¤ë‹¤.\n",
      "\n",
      "--- [ìŒ 4] ---\n",
      "  **ENG**: (she was so much surprised, that for the moment she quite forgot how to speak good English)\n",
      "  **KOR**: (ì•¨ë¦¬ìŠ¤ëŠ” ë„ˆë¬´ ë†€ë€ ë‚˜ë¨¸ì§€ ë§ì¡°ì°¨ ë˜‘ë°”ë¡œ í•˜ì§€ ëª»í–ˆë‹¤.)\n",
      "\n",
      "--- [ìŒ 5] ---\n",
      "  **ENG**: â€œnow Iâ€™m opening out like the largest telescope that ever was!\n",
      "  **KOR**: â€œì´ì   ë‚´ê°€ ì„¸ìƒì—ì„œ ê°€ì¥ í° ë§ì›ê²½ì²˜ëŸ¼ í¼ì³ì ¸ ë²„ë ¸ì–´.\n",
      "\n",
      "--- [ìŒ 6] ---\n",
      "  **ENG**: Good-bye, feet!â€\n",
      "  **KOR**: ì˜ìˆì–´ - ë‚´ ë°œì•„!â€\n",
      "\n",
      "--- [ìŒ 7] ---\n",
      "  **ENG**: (for when she looked down at her feet, they seemed to be almost out of sight, they were getting so far off)\n",
      "  **KOR**: (ì•¨ë¦¬ìŠ¤ê°€ ë°œì„ ì³ë‹¤ ë³´ë‹ˆ ê¹Œë§ˆë“íˆ ë©€ë¦¬ ìˆì–´ì„œ ê²¨ìš° ë³´ì¼ë½ ë§ë½ í•  ì§€ê²½ì´ì—ˆë‹¤.)\n",
      "\n",
      "--- [ìŒ 8] ---\n",
      "  **ENG**: â€œOh, my poor little feet, I wonder who will put on your shoes and stockings for you now, dears?\n",
      "  **KOR**: â€œì•„, ë¶ˆìŒí•œ ë‚´ ì‘ì€ ë°œë“¤.\n",
      "\n",
      "--- [ìŒ 9] ---\n",
      "  **ENG**: I shall be a great deal too far off to trouble myself about you: you must manage the best way you can;â€”but I must be kind to them,â€\n",
      "  **KOR**: ë„ˆí¬ê°€ ìŠ¤ìŠ¤ë¡œ í•˜ëŠ” ê²Œ ê°€ì¥ ì¢‹ì§€ë§Œ, ë‚´ê°€ ë¬´ì–´ë“  í•´ì•¼í•˜ê² ì§€.â€\n",
      "\n",
      "--- [ìŒ 10] ---\n",
      "  **ENG**: thought Alice,\n",
      "  **KOR**: í•˜ê³  ì•¨ë¦¬ìŠ¤ëŠ” ìƒê°í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 11] ---\n",
      "  **ENG**: â€œor perhaps they wonâ€™t walk the way I want to go!\n",
      "  **KOR**: â€œì•„ë‹ˆë©´ ì•„ë§ˆë„ ë‚´ ë°œë“¤ì´ ë‚´ê°€ ê°€ê³  ì‹¶ì„ ë•Œ ê±·ì§€ ì•Šìœ¼ë ¤ê³  í• ì§€ë„ ëª°ë¼!\n",
      "\n",
      "--- [ìŒ 12] ---\n",
      "  **ENG**: Let me see: Iâ€™ll give them a new pair of boots every Christmas.â€\n",
      "  **KOR**: ì–˜ë“¤ì•„, í¬ë¦¬ìŠ¤ë§ˆìŠ¤ë§ˆë‹¤ ìƒˆ ì‹ ë°œì„ ì‚¬ì¤„ê»˜.â€\n",
      "\n",
      "--- [ìŒ 13] ---\n",
      "  **ENG**: â€œThey must go by the carrier,â€\n",
      "  **KOR**: â€œì•„ë¬´ë˜ë„ ìš´ì†¡ íšŒì‚¬ë¥¼ ë¶ˆëŸ¬ì•¼ í•  ê±°ì•¼.\n",
      "\n",
      "--- [ìŒ 14] ---\n",
      "  **ENG**: she thought;\n",
      "  **KOR**: í•˜ê³  ìƒê°í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 15] ---\n",
      "  **ENG**: And how odd the directions will look! _Aliceâ€™s Right Foot, Esq., Hearthrug, near the Fender,_ (_with Aliceâ€™s love_).\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ì˜ ì˜¤ë¥¸ë°œ ê·€í•˜ ë²½ë‚œë¡œ ê¹”ê°œ ë‚œë¡œ ì² ë§ ì˜† (ì‚¬ë‘ì„ ë‹´ì•„ ì•¨ë¦¬ìŠ¤ê°€) ë§™ì†Œì‚¬ ë‚´ê°€ ë¬´ìŠ¨ ì—‰ëš±í•œ ë§ì„ í•˜ê³  ìˆëŠ” ê±°ì•¼.â€\n",
      "\n",
      "--- [ìŒ 16] ---\n",
      "  **ENG**: Oh dear, what nonsense Iâ€™m talking!â€\n",
      "  **KOR**: ì˜¤, ìƒì¥ì•¼.â€\n",
      "\n",
      "--- [ìŒ 17] ---\n",
      "  **ENG**: Poor Alice!\n",
      "  **KOR**: ë¶ˆìŒí•œ ì•¨ë¦¬ìŠ¤!\n",
      "\n",
      "--- [ìŒ 18] ---\n",
      "  **ENG**: It was as much as she could do, lying down on one side, to look through into the garden with one eye; but to get through was more hopeless than ever: she sat down and began to cry again.\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ê°€ ìµœëŒ€í•œ í•  ìˆ˜ ìˆëŠ” ì¼ì´ë¼ê³¤ í•œìª½ìœ¼ë¡œ ëˆ„ì›Œ í•œ ëˆˆìœ¼ë¡œ ë¬¸ ì•ˆì„ ë“¤ì—¬ë‹¤ ë³´ëŠ” ê²ƒì´ ê³ ì‘ì´ì—ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 19] ---\n",
      "  **ENG**: â€œYou ought to be ashamed of yourself,â€\n",
      "  **KOR**: â€œë¶€ë„ëŸ¬ìš´ ì¤„ ì•Œì•„ì•¼ì§€.\n",
      "\n",
      "--- [ìŒ 20] ---\n",
      "  **ENG**: said Alice,\n",
      "  **KOR**: í•˜ê³  ì•¨ë¦¬ìŠ¤ê°€ ë§í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 21] ---\n",
      "  **ENG**: (she might well say this)\n",
      "  **KOR**: (ì´ë²ˆì—” í›Œë¥­í•˜ê²Œ ë§í–ˆë‹¤.)\n",
      "\n",
      "--- [ìŒ 22] ---\n",
      "  **ENG**: â€œto go on crying in this way!\n",
      "  **KOR**: â€œì´ë ‡ê²Œ ìš¸ë‹¤ë‹ˆ.\n",
      "\n",
      "--- [ìŒ 23] ---\n",
      "  **ENG**: Stop this moment, I tell you!â€\n",
      "  **KOR**: ê·¸ì¹˜ë¼ê³  ë§í–ˆë‹¤!â€\n",
      "\n",
      "--- [ìŒ 24] ---\n",
      "  **ENG**: It was the White Rabbit returning, splendidly dressed, with a pair of white kid gloves in one hand and a large fan in the other: he came trotting along in a great hurry, muttering to himself as he came,\n",
      "  **KOR**: í† ë¼ëŠ” ê·¼ì‚¬í•œ ì˜·ì„ ì…ê³  í•œ ì†ì—” í° ì¥ê°‘ í•œ ìŒì„ ë“¤ê³  ë‹¤ë¥¸ ì†ì—” í° ë¶€ì±„ë¥¼ ë“¤ê³  ìˆì—ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 25] ---\n",
      "  **ENG**: â€œOh! the Duchess, the Duchess!\n",
      "  **KOR**: â€œì•„, ê³µì‘ ë¶€ì¸, ê³µì‘ ë¶€ì¸.\n",
      "\n",
      "--- [ìŒ 26] ---\n",
      "  **ENG**: Oh! wonâ€™t she be savage if Iâ€™ve kept her waiting!â€\n",
      "  **KOR**: ë‚´ê°€ ê·¸ë…€ë¥¼ ê¸°ë‹¤ë¦¬ê²Œ í–ˆë‹¤ê°„ ê°€ë§Œ ë‘ì§€ ì•Šê² ì§€.â€\n",
      "\n",
      "--- [ìŒ 27] ---\n",
      "  **ENG**: Alice felt so desperate that she was ready to ask help of any one; so, when the Rabbit came near her, she began, in a low, timid voice,\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ëŠ” ëˆ„ê°€ ì§€ë‚˜ê°€ë“  ì œë°œ ë„ì™€ë‹¬ë¼ê³  í•´ì•¼ í•  ë•Œì—¬ì„œ, í† ë¼ê°€ ë‹¤ê°€ì˜¤ì ì‘ê³  ë‚®ì€ ëª©ì†Œë¦¬ë¡œ ì…ì„ ì—´ì—ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 28] ---\n",
      "  **ENG**: â€œIf you please, sirâ€”â€\n",
      "  **KOR**: â€œì €, ê´œì°®ìœ¼ì‹œë©´ â€¦â€¦â€\n",
      "\n",
      "--- [ìŒ 29] ---\n",
      "  **ENG**: The Rabbit started violently, dropped the white kid gloves and the fan, and skurried away into the darkness as hard as he could go.\n",
      "  **KOR**: í† ë¼ëŠ” ê¹œì§ ë†€ë¼ë”ë‹ˆ ì¥ê°‘ê³¼ ë¶€ì±„ë¥¼ ë–¨ì–´ëœ¨ë¦¬ê³ ëŠ” í—ˆë‘¥ê±°ë¦¬ë©° í•  ìˆ˜ ìˆëŠ” í•œ ì¬ë¹¨ë¦¬ ì–´ë‘  ì†ìœ¼ë¡œ ë‹¬ë ¤ê°€ ë²„ë ¸ë‹¤.\n",
      "\n",
      "--- [ìŒ 30] ---\n",
      "  **ENG**: Alice took up the fan and gloves, and, as the hall was very hot, she kept fanning herself all the time she went on talking:\n",
      "  **KOR**: ë°©ì´ ë„ˆë¬´ ë”ì›Œì„œ ì•¨ë¦¬ìŠ¤ëŠ” ë¶€ì±„ë¥¼ ë¶€ì¹˜ë©° ìŠ¤ìŠ¤ë¡œì—ê²Œ ë§í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 31] ---\n",
      "  **ENG**: â€œDear, dear!\n",
      "  **KOR**: â€œì˜¤, ìƒì¥ì•¼.\n",
      "\n",
      "--- [ìŒ 32] ---\n",
      "  **ENG**: How queer everything is to-day!\n",
      "  **KOR**: ì£¼ì†ŒëŠ” ë˜ ì–¼ë§ˆë‚˜ ì´ìƒí• ê¹Œ!\n",
      "\n",
      "--- [ìŒ 33] ---\n",
      "  **ENG**: And yesterday things went on just as usual.\n",
      "  **KOR**: ì–´ì œëŠ” ëª¨ë“  ê²Œ ë‹¤ í‰ë²”í–ˆëŠ”ë°.\n",
      "\n",
      "--- [ìŒ 34] ---\n",
      "  **ENG**: I wonder if Iâ€™ve been changed in the night?\n",
      "  **KOR**: ë°¤ë™ì•ˆ ë‚´ê°€ ë³€í•œê±¸ê¹Œ?\n",
      "\n",
      "--- [ìŒ 35] ---\n",
      "  **ENG**: Let me think: was I the same when I got up this morning?\n",
      "  **KOR**: ë‚˜ëŠ” ì˜¤ëŠ˜ ì•„ì¹¨ ì¼ì–´ë‚¬ì„ ë•Œë‘ ë˜‘ê°™ì€ ë‚œê°€?\n",
      "\n",
      "--- [ìŒ 36] ---\n",
      "  **ENG**: I almost think I can remember feeling a little different.\n",
      "  **KOR**: ë‚œ ë­”ê°€ ì¡°ê¸ˆì€ ë‹¬ë¼ì§„ ê²ƒ ê°™ë‹¤ê³  ëŠê¼ˆë˜ ê±¸ ê¸°ì–µí•  ìˆ˜ ìˆë‹¤ê³  ìƒê°í•˜ëŠ”ë°.\n",
      "\n",
      "--- [ìŒ 37] ---\n",
      "  **ENG**: But if Iâ€™m not the same, the next question is, Who in the world am I?\n",
      "  **KOR**: í•˜ì§€ë§Œ ë‚´ê°€ ì•„ì¹¨ì˜ ë‚˜ì™€ ê°™ì§€ ì•Šë‹¤ë©´, ë‹¤ìŒ ì§ˆë¬¸ì€, ê·¸ëŸ¼ ë‚˜ëŠ” ëˆ„êµ¬ì§€?\n",
      "\n",
      "--- [ìŒ 38] ---\n",
      "  **ENG**: Ah, _thatâ€™s_ the great puzzle!â€\n",
      "  **KOR**: ì—„ì²­ ë³µì¡í•œ ìˆ˜ìˆ˜ê»˜ë¼ë‹¤.â€\n",
      "\n",
      "--- [ìŒ 39] ---\n",
      "  **ENG**: And she began thinking over all the children she knew that were of the same age as herself, to see if she could have been changed for any of them.\n",
      "  **KOR**: ê·¸ëŸ¬ë©´ì„œ ì•¨ë¦¬ìŠ¤ëŠ” ìê¸°ì™€ ë¹„ìŠ·í•œ ë‚˜ì´ì˜ ì•„ì´ë“¤ì„ ë– ì˜¬ë¦¬ë©° í˜¹ì‹œ ê·¸ ì•„ì´ë“¤ ì¤‘ í•˜ë‚˜ë¡œ ë°”ë€ ê²ƒì€ ì•„ë‹Œì§€ ìƒê°í•´ë³´ì•˜ë‹¤.\n",
      "\n",
      "--- [ìŒ 40] ---\n",
      "  **ENG**: â€œIâ€™m sure Iâ€™m not Ada,â€\n",
      "  **KOR**: â€œë‚œ í™•ì‹¤íˆ ì—ì´ë”ëŠ” ì•„ëƒ.â€\n",
      "\n",
      "--- [ìŒ 41] ---\n",
      "  **ENG**: she said,\n",
      "  **KOR**: í•˜ê³  ë§í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 42] ---\n",
      "  **ENG**: Besides, _sheâ€™s_ she, and _Iâ€™m_ I, andâ€”oh dear, how puzzling it all is!\n",
      "  **KOR**: ê²Œë‹¤ê°€ ê·¸ ì•  ëŠ” ê·¸ ì• ê³  ë‚˜ ëŠ” ë‚˜ì–ì•„, ê·¸ë¦¬ê³ , ì–´â€¦ ì•„ì´ì¿ , ë­ë“  ì™œ ì´ë¦¬ ë³µì¡í•œ ìˆ˜ìˆ˜ê»˜ë¼ê°€ ë˜ëŠ” ê±°ì§€!\n",
      "\n",
      "--- [ìŒ 43] ---\n",
      "  **ENG**: Iâ€™ll try if I know all the things I used to know.\n",
      "  **KOR**: ë‚´ê°€ ì•Œë˜ ê²ƒë“¤ì„ ì œëŒ€ë¡œ ë‹¤ ê¸°ì–µí•˜ê³  ìˆëŠ”ì§€ ë´ì•¼ê² ë‹¤.\n",
      "\n",
      "--- [ìŒ 44] ---\n",
      "  **ENG**: Let me see: four times five is twelve, and four times six is thirteen, and four times seven isâ€”oh dear!\n",
      "  **KOR**: ì–´ë””ë³´ì, 4 ê³±í•˜ê¸° 5ëŠ” 12, ê·¸ë¦¬ê³  4 ê³±í•˜ê¸° 6ì€ 13, 4 ê³±í•˜ê¸° 7ì€â€¦, ì•„ì´ì¿  ì´ëŸ° ì‹ìœ¼ë¡œëŠ” 20ê¹Œì§€ëŠ” ì ˆëŒ€ ëª» ê°€ê² ëŠ”ë°!\n",
      "\n",
      "--- [ìŒ 45] ---\n",
      "  **ENG**: London is the capital of Paris, and Paris is the capital of Rome, and Romeâ€”no, _thatâ€™s_ all wrong, Iâ€™m certain!\n",
      "  **KOR**: ëŸ°ë˜ì€ íŒŒë¦¬ì˜ ìˆ˜ë„, íŒŒë¦¬ëŠ” ë¡œë§ˆì˜ ìˆ˜ë„ â€¦â€¦, ì•„ë‹ˆì•¼.\n",
      "\n",
      "--- [ìŒ 46] ---\n",
      "  **ENG**: I must have been changed for Mabel!\n",
      "  **KOR**: ë‚œ ì•„ë¬´ë˜ë„ ë©”ì´ë¸”ì´ ëœ ê²ƒ ê°™ì•„!\n",
      "\n",
      "--- [ìŒ 47] ---\n",
      "  **ENG**: Iâ€™ll try and say â€˜_How doth the little_â€”â€™â€\n",
      "  **KOR**: â€˜ì–´ì©œ ì´ë¦¬ ì‘ì€â€™ì„ ë‚­ì†¡í•´ ë´ì•¼ê² ë‹¤.\n",
      "\n",
      "--- [ìŒ 48] ---\n",
      "  **ENG**: and she crossed her hands on her lap as if she were saying lessons, and began to repeat it, but her voice sounded hoarse and strange, and the words did not come the same as they used to do:â€”\n",
      "  **KOR**: í•˜ì§€ë§Œ ê·¸ ì•¤ ì´ìƒí•œ ì‰° ëª©ì†Œë¦¬ë¥¼ ë‚´ëŠ” ë°ë‹¤ ë§ë„ ë‹¤ë¥¸ ì‚¬ëŒì´ í•˜ëŠ” ê²ƒì²˜ëŸ¼ í•˜ì§€ ì•ŠëŠ”ë°â€¦â€¦ 'ì–´ì©œ ì´ë¦¬ ì‘ì„ê¹Œâ€™ë¡œ ì‹œì‘í•˜ëŠ” ì‹œë¥¼ ë‚­ì†¡í•´ ë´ì•¼ê² ë‹¤.\n",
      "\n",
      "--- [ìŒ 49] ---\n",
      "  **ENG**: said poor Alice, and her eyes filled with tears again as she went on,\n",
      "  **KOR**: ê°€ì—¬ìš´ ì•¨ë¦¬ìŠ¤ëŠ” ë‹¤ì‹œ ìš¸ê¸° ì‹œì‘í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 50] ---\n",
      "  **ENG**: No, Iâ€™ve made up my mind about it; if Iâ€™m Mabel, Iâ€™ll stay down here!\n",
      "  **KOR**: ë‚´ê°€ ë©”ì´ë¸”ì´ë¼ë©´ ê·¸ëƒ¥ ì—¬ê¸°ì— ìˆì„ ê±°ì•¼!\n",
      "\n",
      "--- [ìŒ 51] ---\n",
      "  **ENG**: Itâ€™ll be no use their putting their heads down and saying â€˜Come up again, dear!â€™ I shall only look up and say â€˜Who am I then?\n",
      "  **KOR**: ì‚¬ëŒë“¤ì´ êµ¬ë©ì— ê³ ê°œë¥¼ ë„£ê³  â€˜ì–˜ì•¼ ì–´ì„œ ë‹¤ì‹œ ì˜¬ë¼ì˜¤ë ´â€™ í•´ë„ ë‚˜ëŠ” â€˜ê·¸ëŸ¼ ì œê°€ ëˆ„êµ¬ì£ ?\n",
      "\n",
      "--- [ìŒ 52] ---\n",
      "  **ENG**: cried Alice, with a sudden burst of tears,\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ëŠ” ê°‘ìê¸° ìš¸ìŒì„ í„°ëœ¨ë ¸ë‹¤.\n",
      "\n",
      "--- [ìŒ 53] ---\n",
      "  **ENG**: â€œI do wish they _would_ put their heads down!\n",
      "  **KOR**: â€œê·¸ëƒ¥ ì‚¬ëŒë“¤ì´ êµ¬ë©ì— ë¨¸ë¦¬ë‚˜ ë””ë°€ì–´ ì¤¬ìœ¼ë©´!\n",
      "\n",
      "--- [ìŒ 54] ---\n",
      "  **ENG**: I am so _very_ tired of being all alone here!â€\n",
      "  **KOR**: ì—¬ê¸° í˜¼ì ìˆì–´ì„œ ë„ˆë¬´ ë„ˆë¬´ ì§€ì³¤ì–´.â€\n",
      "\n",
      "--- [ìŒ 55] ---\n",
      "  **ENG**: As she said this she looked down at her hands, and was surprised to see that she had put on one of the Rabbitâ€™s little white kid gloves while she was talking.\n",
      "  **KOR**: ê·¸ë¦¬ê³ ëŠ” í† ë¼ì˜ ì‘ì€ í° ì¥ê°‘ ì¤‘ í•˜ë‚˜ê°€ ì†ì— ë¼ì›Œì ¸ ìˆëŠ” ê²ƒì„ ë°œê²¬í•˜ê³  ë†€ëë‹¤.\n",
      "\n",
      "--- [ìŒ 56] ---\n",
      "  **ENG**: â€œHow _can_ I have done that?â€\n",
      "  **KOR**: â€œë‚´ê°€ ì´ê±¸ ì–´ë–»ê²Œ í•œê±°ì§€?â€\n",
      "\n",
      "--- [ìŒ 57] ---\n",
      "  **ENG**: â€œI must be growing small again.â€\n",
      "  **KOR**: â€œë‹¤ì‹œ ì‘ì•„ì§„ ê²Œ í‹€ë¦¼ì—†ì–´.â€\n",
      "\n",
      "--- [ìŒ 58] ---\n",
      "  **ENG**: â€œThat _was_ a narrow escape!â€\n",
      "  **KOR**: â€œë” ë‚˜ë¹ ì§€ê¸°ë§Œ í–ˆì–ì•„!â€\n",
      "\n",
      "--- [ìŒ 59] ---\n",
      "  **ENG**: said Alice, a good deal frightened at the sudden change, but very glad to find herself still in existence;\n",
      "  **KOR**: ê°‘ì‘ìŠ¤ëŸ¬ìš´ ë³€í™”ì— ê²ì„ ë¨¹ê¸°ëŠ” í–ˆì§€ë§Œ ì™„ì „íˆ ì‚¬ë¼ì§€ì§€ ì•Šì•˜ë‹¤ëŠ” ê²ƒì´ ê¸°ë»¤ë‹¤.\n",
      "\n",
      "--- [ìŒ 60] ---\n",
      "  **ENG**: â€œand now for the garden!â€\n",
      "  **KOR**: â€œê·¸ëŸ¼, ì´ì œ ì •ì›ìœ¼ë¡œ!â€\n",
      "\n",
      "--- [ìŒ 61] ---\n",
      "  **ENG**: and she ran with all speed back to the little door: but, alas! the little door was shut again, and the little golden key was lying on the glass table as before,\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ëŠ” ì „ì†ë ¥ìœ¼ë¡œ ì‘ì€ ë¬¸ì„ í–¥í•´ ë‹¬ë ¸ë‹¤.\n",
      "\n",
      "--- [ìŒ 62] ---\n",
      "  **ENG**: â€œfor I never was so small as this before, never!\n",
      "  **KOR**: â€œë‚œ ì´ë ‡ê²Œ ì‘ì•˜ë˜ ì ì´ ì—†ì–´.\n",
      "\n",
      "--- [ìŒ 63] ---\n",
      "  **ENG**: And I declare itâ€™s too bad, that it is!â€\n",
      "  **KOR**: ì´ê±´ ì •ë§ ë‚˜ë¹ , ë‚˜ì˜ë‹¤êµ¬!â€\n",
      "\n",
      "--- [ìŒ 64] ---\n",
      "  **ENG**: Her first idea was that she had somehow fallen into the sea,\n",
      "  **KOR**: ì²˜ìŒì— ì•¨ë¦¬ìŠ¤ëŠ” ë°”ë‹¤ì— ë¹ ì¡Œë‹¤ê³  ìƒê°í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 65] ---\n",
      "  **ENG**: â€œand in that case I can go back by railway,â€\n",
      "  **KOR**: â€œê·¸ëŸ¬ë©´ ë‚œ ê¸°ì°¨ë¥¼ íƒ€ê³  ëŒì•„ê°€ì•¼ì§€.â€\n",
      "\n",
      "--- [ìŒ 66] ---\n",
      "  **ENG**: she said to herself.\n",
      "  **KOR**: í•˜ê³  ë§í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 67] ---\n",
      "  **ENG**: (Alice had been to the seaside once in her life, and had come to the general conclusion, that wherever you go to on the English coast you find a number of bathing machines in the sea, some children digging in the sand with wooden spades, then a row of lodging houses, and behind them a railway station.)\n",
      "  **KOR**: ê±°ê¸°ì„œ ì˜êµ­ í•´ì•ˆì´ë¼ë©´ ì–´ë””ë‚˜ ì—¬ëŸ¬ ê°œì˜ ì˜·ì„ ê°ˆì•„ì…ëŠ” ê³µê°„ì´ ë°”ë‹¤ ìœ„ì— ë– ìˆê³ , ì•„ì´ë“¤ì´ ë‚˜ë¬´ ì‚½ìœ¼ë¡œ ëª¨ë˜ ë†€ì´ë¥¼ í•˜ë©°, ê·¸ ë’¤ì— ì¤„ì¤„ì´ ìˆ™ì†Œê°€ ìˆê³ , ê·¸ ë’¤ë¡œ ê¸°ì°¨ì—­ì´ ìˆë‹¤ê³  ìƒê°í•˜ê²Œ ë˜ì—ˆë‹¤.)\n",
      "\n",
      "--- [ìŒ 68] ---\n",
      "  **ENG**: However, she soon made out that she was in the pool of tears which she had wept when she was nine feet high.\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ëŠ” ì–¼ë§ˆ ì§€ë‚˜ì§€ ì•Šì•„ ì´ê²Œ ì‚¬ì‹¤ì€ ìê¸° í‚¤ê°€ 9í”¼íŠ¸ì¼ ë•Œ í˜ë ¸ë˜ ëˆˆë¬¼ì´ ë§Œë“  ì›…ë©ì´ë¼ëŠ” ê²ƒì„ ê¹¨ë‹¬ì•˜ë‹¤.\n",
      "\n",
      "--- [ìŒ 69] ---\n",
      "  **ENG**: â€œI wish I hadnâ€™t cried so much!â€\n",
      "  **KOR**: â€œê·¸ë ‡ê²Œ ë§ì´ ìš¸ì§€ ë§ê»„!â€\n",
      "\n",
      "--- [ìŒ 70] ---\n",
      "  **ENG**: said Alice, as she swam about, trying to find her way out.\n",
      "  **KOR**: ì›…ë©ì´ë¥¼ í—¤ì—„ì¹˜ë©° ë¹ ì ¸ ë‚˜ê°ˆ ê³³ì„ ì°¾ìœ¼ë©° ì•¨ë¦¬ìŠ¤ëŠ”\n",
      "\n",
      "--- [ìŒ 71] ---\n",
      "  **ENG**: â€œI shall be punished for it now, I suppose, by being drowned in my own tears!\n",
      "  **KOR**: â€œë‚´ê°€ ê·¸ë ‡ê²Œ ë§ì€ ëˆˆë¬¼ì„ í˜ë ¤ì„œ ë‚´ ëˆˆë¬¼ì— ë¹ ì ¸ ì£½ê²Œ ë˜ëŠ” ë²Œì„ ë°›ëŠ” ê±¸ ê±°ì•¼.\n",
      "\n",
      "--- [ìŒ 72] ---\n",
      "  **ENG**: However, everything is queer to-day.â€\n",
      "  **KOR**: í•˜ì§€ë§Œ ì˜¤ëŠ˜ì€ ëª¨ë“  ê²Œ ë‹¤ ì´ìƒí•œ ë‚ ì¸ê±¸.â€\n",
      "\n",
      "--- [ìŒ 73] ---\n",
      "  **ENG**: thought Alice,\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ëŠ” ìƒê°í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 74] ---\n",
      "  **ENG**: â€œto speak to this mouse?\n",
      "  **KOR**: â€œì´ ìƒì¥ë‘ ì´ì•¼ê¸°í•˜ëŠ” ê²Œ ë„ì›€ì´ ë ê¹Œ?â€\n",
      "\n",
      "--- [ìŒ 75] ---\n",
      "  **ENG**: Everything is so out-of-the-way down here, that I should think very likely it can talk: at any rate, thereâ€™s no harm in trying.â€\n",
      "  **KOR**: ì–´ì¨Œë“ , ì‹œë„ í•´ ë³´ëŠ” ê²Œ ë‚˜ì  ê²ƒë„ ì—†ì§€.â€\n",
      "\n",
      "--- [ìŒ 76] ---\n",
      "  **ENG**: â€œO Mouse, do you know the way out of this pool?\n",
      "  **KOR**: ì´ ì›…ë©ì´ë¥¼ ë¹ ì ¸ë‚˜ê°ˆ ê¸¸ì„ ì•„ë‹ˆ?\n",
      "\n",
      "--- [ìŒ 77] ---\n",
      "  **ENG**: I am very tired of swimming about here, O Mouse!â€\n",
      "  **KOR**: ê·¸ë¦¬ê³ , ì¥ë¥¼ ì •ë§ ì˜ ì¡ì•„ -- ì•„, ë¯¸ì•ˆí•´!â€\n",
      "\n",
      "--- [ìŒ 78] ---\n",
      "  **ENG**: (Alice thought this must be the right way of speaking to a mouse: she had never done such a thing before, but she remembered having seen in her brotherâ€™s Latin Grammar,\n",
      "  **KOR**: (ì•¨ë¦¬ìŠ¤ëŠ” ì´ê²Œ ìƒì¥ì—ê²Œ ë§ì„ ê±°ëŠ” ì•Œë§ì€ ë°©ë²•ì´ë¼ê³  ìƒê°í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 79] ---\n",
      "  **ENG**: â€œA mouseâ€”of a mouseâ€”to a mouseâ€”a mouseâ€”O mouse!â€\n",
      "  **KOR**: â€œì•„ ì–´ ë§ˆìš°ìŠ¤ - íˆ¬ ë§ˆìš°ìŠ¤, ì•„ ë§ˆìš°ìŠ¤ - ì˜¤ ë§ˆìš°ìŠ¤â€\n",
      "\n",
      "--- [ìŒ 80] ---\n",
      "  **ENG**: ) The Mouse looked at her rather inquisitively, and seemed to her to wink with one of its little eyes, but it said nothing.\n",
      "  **KOR**: í•˜ê³  ë§í–ˆë˜ ê²ƒì´ ê¸°ì–µë‚¬ê¸° ë•Œë¬¸ì´ì—ˆë‹¤.) ìƒì¥ëŠ” ëª¹ì‹œ ê¶ê¸ˆí•´í•˜ëŠ” í‘œì •ìœ¼ë¡œ ì•¨ë¦¬ìŠ¤ë¥¼ ë°”ë¼ë³´ê³ ëŠ” í•œ ìª½ ëˆˆì„ ì°¡ë— í•œë“¯ í–ˆì§€ë§Œ, ì•„ë¬´ëŸ° ë§ë„ í•˜ì§€ ì•Šì•˜ë‹¤.\n",
      "\n",
      "--- [ìŒ 81] ---\n",
      "  **ENG**: â€œPerhaps it doesnâ€™t understand English,â€\n",
      "  **KOR**: â€œì•„ë§ˆë„ ì˜ì–´ë¥¼ ëª» ì•Œì•„ ë“£ë‚˜ë´.\n",
      "\n",
      "--- [ìŒ 82] ---\n",
      "  **ENG**: thought Alice;\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ëŠ” ìƒê°í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 83] ---\n",
      "  **ENG**: â€œI daresay itâ€™s a French mouse, come over with William the Conqueror.â€\n",
      "  **KOR**: ì •ë³µì ìœŒë¦¬ì—„ì´ë‘ í•¨ê»˜ ê±´ë„ˆì˜¨ í”„ë‘ìŠ¤ ì¥ì¸ê°€?â€\n",
      "\n",
      "--- [ìŒ 84] ---\n",
      "  **ENG**: (For, with all her knowledge of history, Alice had no very clear notion how long ago anything had happened.)\n",
      "  **KOR**: (ì•¨ë¦¬ìŠ¤ëŠ” ì—­ì‚¬ì— ì“°ì¸ ì¼ë“¤ì´ ì •í™•íˆ ì–¸ì œ ìˆì—ˆê³  ì–¼ë§ˆë‚˜ ì˜¤ë˜ ëœ ì¼ì¸ì§€ ì˜ ì•Œì§€ ëª»í–ˆë‹¤.)\n",
      "\n",
      "--- [ìŒ 85] ---\n",
      "  **ENG**: â€œOÃ¹ est ma chatte?â€\n",
      "  **KOR**: â€œìš° ì— ë§ˆ ìƒ¤íŠ¸(ë‚´ ê³ ì–‘ì´ëŠ” ì–´ë””ì— ìˆì§€?)?â€\n",
      "\n",
      "--- [ìŒ 86] ---\n",
      "  **ENG**: which was the first sentence in her French lesson-book.\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ì˜ í”„ë‘ìŠ¤ì–´ êµê³¼ì„œ ì²˜ìŒì— ì íŒ ë¬¸ì¥ì´ì—ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 87] ---\n",
      "  **ENG**: The Mouse gave a sudden leap out of the water, and seemed to quiver all over with fright.\n",
      "  **KOR**: ìˆœê°„ ìƒì¥ëŠ” í„ì© ë›°ì–´ ì˜¬ëê³  ë‘ë ¤ì›Œì„œ ë²Œë²Œ ë– ëŠ” ê²ƒ ì²˜ëŸ¼ ë³´ì˜€ë‹¤.\n",
      "\n",
      "--- [ìŒ 88] ---\n",
      "  **ENG**: â€œOh, I beg your pardon!â€\n",
      "  **KOR**: â€œìš©ì„œí•´ì¤˜!\n",
      "\n",
      "--- [ìŒ 89] ---\n",
      "  **ENG**: cried Alice hastily, afraid that she had hurt the poor animalâ€™s feelings.\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ëŠ” ìì‹ ì´ ê°€ì—¬ìš´ ë™ë¬¼ì˜ ë§ˆìŒì„ ìƒí•˜ê²Œ í•œ ê²ƒ ê°™ì•„ ë‹¤ê¸‰íˆ ì™¸ì³¤ë‹¤.\n",
      "\n",
      "--- [ìŒ 90] ---\n",
      "  **ENG**: â€œI quite forgot you didnâ€™t like cats.â€\n",
      "  **KOR**: ë„Œ ê³ ì–‘ì´ë¥¼ ì¢‹ì•„í•˜ì§€ ì•ŠëŠ” ë‹¤ëŠ” ê±¸ ìŠì—ˆì–´.â€\n",
      "\n",
      "--- [ìŒ 91] ---\n",
      "  **ENG**: â€œNot like cats!â€\n",
      "  **KOR**: â€œê³ ì–‘ì´ ì‹«ë‹¤!\n",
      "\n",
      "--- [ìŒ 92] ---\n",
      "  **ENG**: cried the Mouse, in a shrill, passionate voice.\n",
      "  **KOR**: ìƒì¥ê°€ ë‚ ì¹´ë¡­ê³  í° ì†Œë¦¬ë¡œ ëŒ€ë‹µí–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 93] ---\n",
      "  **ENG**: â€œWould _you_ like cats if you were me?â€\n",
      "  **KOR**: ë„¤ê°€ ë‚˜ë¼ë©´ ê³ ì–‘ì´ê°€ ì¢‹ê² ë‹ˆ?â€\n",
      "\n",
      "--- [ìŒ 94] ---\n",
      "  **ENG**: â€œWell, perhaps not,â€\n",
      "  **KOR**: â€œìŒ, ì•„ë§ˆ ì•ˆ ì¢‹ì•„í•  ê±°ì•¼.â€\n",
      "\n",
      "--- [ìŒ 95] ---\n",
      "  **ENG**: said Alice in a soothing tone:\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ëŠ” ë¶€ë“œëŸ¬ìš´ ëª©ì†Œë¦¬ë¡œ\n",
      "\n",
      "--- [ìŒ 96] ---\n",
      "  **ENG**: â€œdonâ€™t be angry about it.\n",
      "  **KOR**: â€œí™”ë‚´ì§€ ë§ˆ.\n",
      "\n",
      "--- [ìŒ 97] ---\n",
      "  **ENG**: She is such a dear quiet thing,â€\n",
      "  **KOR**: ì •ë§ ì‚¬ë‘ìŠ¤ëŸ½ê±°ë“ .â€\n",
      "\n",
      "--- [ìŒ 98] ---\n",
      "  **ENG**: Alice went on, half to herself, as she swam lazily about in the pool,\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ëŠ” ë°˜ì¯¤ì€ ìŠ¤ìŠ¤ë¡œì—ê²Œ ë§í•˜ë©° ì²œì²œíˆ í—¤ì—„ì³¤ë‹¤.\n",
      "\n",
      "--- [ìŒ 99] ---\n",
      "  **ENG**: cried Alice again, for this time the Mouse was bristling all over, and she felt certain it must be really offended.\n",
      "  **KOR**: ìƒì¥ëŠ” ì´ ë²ˆì—” í™”ê°€ ë‚œ ê²ƒ ê°™ì•˜ë‹¤.\n",
      "\n",
      "--- [ìŒ 100] ---\n",
      "  **ENG**: â€œWe indeed!â€\n",
      "  **KOR**: â€œë‹¹ì—°íˆ!â€\n",
      "\n",
      "--- [ìŒ 101] ---\n",
      "  **ENG**: cried the Mouse, who was trembling down to the end of his tail.\n",
      "  **KOR**: í•˜ê³  ìƒì¥ê°€ ëŠ˜ì–´ëœ¨ë¦° ê¼¬ë¦¬ ëì„ ë–¨ë©´ì„œ í° ì†Œë¦¬ë¡œ ë§í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 102] ---\n",
      "  **ENG**: â€œAs if _I_ would talk on such a subject!\n",
      "  **KOR**: â€œê·¸ëŸ° ì–˜ê¸°ëŠ” ê´€ë‘ì!\n",
      "\n",
      "--- [ìŒ 103] ---\n",
      "  **ENG**: Our family always _hated_ cats: nasty, low, vulgar things!\n",
      "  **KOR**: ìš°ë¦¬ ê°€ë¬¸ì€ ê³ ì–‘ì´ ê°™ì€ ë”ëŸ½ê³  ì²œí•œ ë¬´ì‹í•œ ê²ƒë“¤ì€ ì‹«ì–´í•´!\n",
      "\n",
      "--- [ìŒ 104] ---\n",
      "  **ENG**: Donâ€™t let me hear the name again!â€\n",
      "  **KOR**: ë‹¤ì‹  ê·¸ ì–˜ê¸°í•˜ì§€ ë§ˆ!â€\n",
      "\n",
      "--- [ìŒ 105] ---\n",
      "  **ENG**: â€œI wonâ€™t indeed!â€\n",
      "  **KOR**: â€œì•„ìŠ¬ì•„ìŠ¬ í–ˆì–´!â€\n",
      "\n",
      "--- [ìŒ 106] ---\n",
      "  **ENG**: said Alice, in a great hurry to change the subject of conversation.\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ëŠ” ì¬ë¹¨ë¦¬ í™”ì œë¥¼ ëŒë ¸ë‹¤.\n",
      "\n",
      "--- [ìŒ 107] ---\n",
      "  **ENG**: â€œAre youâ€”are you fondâ€”ofâ€”of dogs?â€\n",
      "  **KOR**: â€œë„ˆ -- ë„ˆëŠ” ê°œ -- ê°œëŠ” ì¢‹ì•„í•˜ë‹ˆ?â€\n",
      "\n",
      "--- [ìŒ 108] ---\n",
      "  **ENG**: The Mouse did not answer, so Alice went on eagerly:\n",
      "  **KOR**: ìƒì¥ê°€ ì•„ë¬´ ë§ë„ í•˜ì§€ ì•Šì ì•¨ë¦¬ìŠ¤ëŠ” ì—´ì‹¬íˆ ë§í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 109] ---\n",
      "  **ENG**: â€œThere is such a nice little dog near our house I should like to show you!\n",
      "  **KOR**: â€œì§„ì§œ ë©‹ì§„ ê°œê°€ ìš°ë¦¬ ì˜† ì§‘ì— ì‚¬ëŠ”ë°.\n",
      "\n",
      "--- [ìŒ 110] ---\n",
      "  **ENG**: A little bright-eyed terrier, you know, with oh, such long curly brown hair!\n",
      "  **KOR**: ì•„, ê³±ìŠ¬ê±°ë¦¬ëŠ” ê°ˆìƒ‰ í„¸!\n",
      "\n",
      "--- [ìŒ 111] ---\n",
      "  **ENG**: He says it kills all the rats andâ€”oh dear!â€\n",
      "  **KOR**: ë†ë¶€ ì•„ì €ì”¨ëŠ” ê·¸ ê°œê°€ ì¥ë„ ì˜ ì¡ê³  ë˜ -- ì•„ì´ì¿ !â€\n",
      "\n",
      "--- [ìŒ 112] ---\n",
      "  **ENG**: cried Alice in a sorrowful tone,\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ëŠ” ë¯¸ì•ˆí•œ ëª©ì†Œë¦¬ë¡œ ë§í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 113] ---\n",
      "  **ENG**: â€œIâ€™m afraid Iâ€™ve offended it again!â€\n",
      "  **KOR**: â€œë‚´ê°€ ë˜ ë„¤ ë§ˆìŒì„ ìƒí•˜ê²Œ í–ˆë‚˜ë´!â€\n",
      "\n",
      "--- [ìŒ 114] ---\n",
      "  **ENG**: For the Mouse was swimming away from her as hard as it could go, and making quite a commotion in the pool as it went.\n",
      "  **KOR**: ìƒì¥ëŠ” ì²¨ë²™ê±°ë¦¬ë©° ë¬¼ì‚´ì„ ë§Œë“¤ë©´ì„œ ì˜¨ í˜ì„ ë‹¤í•´ ë©€ë¦¬ í—¤ì—„ì³ ê°€ê³  ìˆì—ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 115] ---\n",
      "  **ENG**: â€œMouse dear!\n",
      "  **KOR**: â€œìƒì¥ì•¼!\n",
      "\n",
      "--- [ìŒ 116] ---\n",
      "  **ENG**: Do come back again, and we wonâ€™t talk about cats or dogs either, if you donâ€™t like them!â€\n",
      "  **KOR**: ì‹«ì–´í•˜ë©´ ê³ ì–‘ì´ë‚˜ ê°œ ì–˜ê¸´ ì•ˆí• ê»˜.â€\n",
      "\n",
      "--- [ìŒ 117] ---\n",
      "  **ENG**: When the Mouse heard this, it turned round and swam slowly back to her: its face was quite pale\n",
      "  **KOR**: ìƒì¥ëŠ” ê·¸ ì†Œë¦¬ë¥¼ ë“£ê³  ì²œì²œíˆ í—¤ì—„ì³ ëŒì•„ì™”ë‹¤.\n",
      "\n",
      "--- [ìŒ 118] ---\n",
      "  **ENG**: (with passion, Alice thought)\n",
      "  **KOR**: (ì•¨ë¦¬ìŠ¤ëŠ” í™”ë‚œ ê²ƒ ê°™ì•„ ë³´ì¸ë‹¤ê³  ìƒê°í–ˆë‹¤.)\n",
      "\n",
      "--- [ìŒ 119] ---\n",
      "  **ENG**: , and it said in a low trembling voice,\n",
      "  **KOR**: ìƒì¥ëŠ” ë–¨ë¦¬ëŠ” ëª©ì†Œë¦¬ë¡œ ë§í–ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- 0. ì„¤ì • ---\n",
    "FILE_NAME = 'day1_aligned_data.npz'\n",
    "NUM_SAMPLES_TO_SHOW = 5 # í™•ì¸í•  ë¬¸ì¥ ìŒì˜ ê°œìˆ˜\n",
    "\n",
    "try:\n",
    "    # Day 1 ê²°ê³¼ íŒŒì¼ ë¡œë“œ\n",
    "    day1_data = np.load(FILE_NAME, allow_pickle=True)\n",
    "    \n",
    "    print(f\"--- Day 1 ë°ì´í„° '{FILE_NAME}' ë‚´ìš© í™•ì¸ ---\")\n",
    "    \n",
    "    # 1. íŒŒì¼ì— ì €ì¥ëœ ë³€ìˆ˜(í‚¤) ëª©ë¡ í™•ì¸\n",
    "    print(\"ì €ì¥ëœ ë³€ìˆ˜ ì´ë¦„:\", day1_data.files)\n",
    "\n",
    "    # 2. ì„ë² ë”© í¬ê¸° í™•ì¸\n",
    "    eng_embs_shape = day1_data['eng_embs'].shape\n",
    "    print(f\"ì „ì²´ ì •ë ¬ ìŒ ê°œìˆ˜ (N): {eng_embs_shape[0]}\")\n",
    "    print(f\"ì„ë² ë”© ì°¨ì› (D): {eng_embs_shape[1]}\")\n",
    "    \n",
    "    # 3. ì •ë ¬ëœ ë¬¸ì¥ ìŒ ë¡œë“œ\n",
    "    eng_sents = day1_data['eng_sents']\n",
    "    kor_sents = day1_data['kor_sents']\n",
    "    \n",
    "    # 4. ì •ë ¬ëœ ë¬¸ì¥ ìŒ ì¶œë ¥ (ë§¤í•‘ í™•ì¸)\n",
    "    print(f\"\\nâœ… ì •ë ¬ëœ ë¬¸ì¥ ìŒ {NUM_SAMPLES_TO_SHOW}ê°œ í™•ì¸ (ë§¤í•‘ ê²°ê³¼):\")\n",
    "    \n",
    "    for i in range(len(eng_sents)):\n",
    "        print(f\"\\n--- [ìŒ {i+1}] ---\")\n",
    "        print(f\"  **ENG**: {eng_sents[i]}\")\n",
    "        print(f\"  **KOR**: {kor_sents[i]}\")\n",
    "        \n",
    "    # 5. ë©”ëª¨ë¦¬ í•´ì œ\n",
    "    day1_data.close()\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"ì˜¤ë¥˜: '{FILE_NAME}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Day 1 ì½”ë“œë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ íŒŒì¼ì„ ìƒì„±í•˜ì‹­ì‹œì˜¤.\")\n",
    "except KeyError as e:\n",
    "    print(f\"ì˜¤ë¥˜: í•„ìš”í•œ ë³€ìˆ˜({e})ê°€ íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤. Day 1 ì½”ë“œê°€ ì •ìƒì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì‹­ì‹œì˜¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653d816c",
   "metadata": {},
   "source": [
    "## Sentence DP Aligned npz Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "e2447c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Day 1 ë°ì´í„° 'day1_dp_aligned_data.npz' ë‚´ìš© í™•ì¸ ---\n",
      "ì €ì¥ëœ ë³€ìˆ˜ ì´ë¦„: ['eng_embs', 'kor_embs', 'eng_sents', 'kor_sents']\n",
      "ì „ì²´ ì •ë ¬ ìŒ ê°œìˆ˜ (N): 104\n",
      "ì„ë² ë”© ì°¨ì› (D): 768\n",
      "\n",
      "âœ… ì •ë ¬ëœ ë¬¸ì¥ ìŒ 5ê°œ í™•ì¸ (ë§¤í•‘ ê²°ê³¼):\n",
      "\n",
      "--- [ìŒ 1] ---\n",
      "  **ENG**: The Pool of Tears\n",
      "  **KOR**: ì œ2ì¥ ëˆˆë¬¼ ì›…ë©ì´\n",
      "\n",
      "--- [ìŒ 2] ---\n",
      "  **ENG**: â€œCuriouser and curiouser!â€ cried Alice\n",
      "  **KOR**: â€œìš”ìƒí•˜ê³ ë„ ìš”ìƒí•´!â€ ì•¨ë¦¬ìŠ¤ëŠ” ì†Œë¦¬ì³¤ë‹¤.\n",
      "\n",
      "--- [ìŒ 3] ---\n",
      "  **ENG**: (she was so much surprised, that for the moment she quite forgot how to speak good English);\n",
      "  **KOR**: (ì•¨ë¦¬ìŠ¤ëŠ” ë„ˆë¬´ ë†€ë€ ë‚˜ë¨¸ì§€ ë§ì¡°ì°¨ ë˜‘ë°”ë¡œ í•˜ì§€ ëª»í–ˆë‹¤.)\n",
      "\n",
      "--- [ìŒ 4] ---\n",
      "  **ENG**: â€œnow Iâ€™m opening out like the largest telescope that ever was!\n",
      "  **KOR**: â€œì´ì   ë‚´ê°€ ì„¸ìƒì—ì„œ ê°€ì¥ í° ë§ì›ê²½ì²˜ëŸ¼ í¼ì³ì ¸ ë²„ë ¸ì–´. ì˜ìˆì–´ - ë‚´ ë°œì•„!â€\n",
      "\n",
      "--- [ìŒ 5] ---\n",
      "  **ENG**: (for when she looked down at her feet, they seemed to be almost out of sight, they were getting so far off).\n",
      "  **KOR**: (ì•¨ë¦¬ìŠ¤ê°€ ë°œì„ ì³ë‹¤ ë³´ë‹ˆ ê¹Œë§ˆë“íˆ ë©€ë¦¬ ìˆì–´ì„œ ê²¨ìš° ë³´ì¼ë½ ë§ë½ í•  ì§€ê²½ì´ì—ˆë‹¤.)\n",
      "\n",
      "--- [ìŒ 6] ---\n",
      "  **ENG**: â€œOh, my poor little feet, I wonder who will put on your shoes and stockings for you now, dears?\n",
      "  **KOR**: â€œì•„, ë¶ˆìŒí•œ ë‚´ ì‘ì€ ë°œë“¤. ì´ì œ ëˆ„ê°€ ë‚´ ë°œì— ì–‘ë§ì„ ì‹ ê²¨ ì£¼ê³  ì‹ ë°œì„ ì‹ ê²¨ ì¤€ë‹´. ë‚œ ëª» í• ê±°ì•¼.\n",
      "\n",
      "--- [ìŒ 7] ---\n",
      "  **ENG**: Let me see: Iâ€™ll give them a new pair of boots every Christmas.â€ And she went on planning to herself how she would manage it.\n",
      "  **KOR**: ì–˜ë“¤ì•„, í¬ë¦¬ìŠ¤ë§ˆìŠ¤ë§ˆë‹¤ ìƒˆ ì‹ ë°œì„ ì‚¬ì¤„ê»˜.â€ ì•¨ë¦¬ìŠ¤ëŠ” ì–´ë–»ê²Œ ì„ ë¬¼ì„ ì¤„ ìˆ˜ ìˆì„ ì§€ ìƒê°í•´ ë³´ì•˜ë‹¤.\n",
      "\n",
      "--- [ìŒ 8] ---\n",
      "  **ENG**: â€œThey must go by the carrier,â€ she thought;\n",
      "  **KOR**: â€œì•„ë¬´ë˜ë„ ìš´ì†¡ íšŒì‚¬ë¥¼ ë¶ˆëŸ¬ì•¼ í•  ê±°ì•¼. ê·¸ëŸ°ë°, ì •ë§ ìš°ìŠµê²Œ ë³´ì´ê² ì§€?\n",
      "\n",
      "--- [ìŒ 9] ---\n",
      "  **ENG**: â€œand how funny itâ€™ll seem, sending presents to oneâ€™s own feet!\n",
      "  **KOR**: ìê¸° ë°œì—ê²Œ ìê¸°ê°€ ì„ ë¬¼ì„ í•˜ë‹¤ë‹ˆ.\n",
      "\n",
      "--- [ìŒ 10] ---\n",
      "  **ENG**: And how odd the directions will look!\n",
      "  **KOR**: ì£¼ì†ŒëŠ” ë˜ ì–¼ë§ˆë‚˜ ì´ìƒí• ê¹Œ!\n",
      "\n",
      "--- [ìŒ 11] ---\n",
      "  **ENG**: _Aliceâ€™s Right Foot, Esq., Hearthrug, near the Fender,_ (_with Aliceâ€™s love_). Oh dear, what nonsense Iâ€™m talking!â€ Just then her head struck against the roof of the hall: in fact she was now more than nine feet high, and she at once took up the little golden key and hurried off to the garden door.\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ì˜ ì˜¤ë¥¸ë°œ ê·€í•˜ ë²½ë‚œë¡œ ê¹”ê°œ ë‚œë¡œ ì² ë§ ì˜† (ì‚¬ë‘ì„ ë‹´ì•„ ì•¨ë¦¬ìŠ¤ê°€) ë§™ì†Œì‚¬ ë‚´ê°€ ë¬´ìŠ¨ ì—‰ëš±í•œ ë§ì„ í•˜ê³  ìˆëŠ” ê±°ì•¼.â€ ì´ ë•Œ ì•¨ë¦¬ìŠ¤ì˜ ë¨¸ë¦¬ê°€ ì²œì •ì— ë¶€ë”›í˜”ë‹¤.\n",
      "\n",
      "--- [ìŒ 12] ---\n",
      "  **ENG**: Poor Alice!\n",
      "  **KOR**: ë¶ˆìŒí•œ ì•¨ë¦¬ìŠ¤!\n",
      "\n",
      "--- [ìŒ 13] ---\n",
      "  **ENG**: It was as much as she could do, lying down on one side, to look through into the garden with one eye; but to get through was more hopeless than ever: she sat down and began to cry again.\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ê°€ ìµœëŒ€í•œ í•  ìˆ˜ ìˆëŠ” ì¼ì´ë¼ê³¤ í•œìª½ìœ¼ë¡œ ëˆ„ì›Œ í•œ ëˆˆìœ¼ë¡œ ë¬¸ ì•ˆì„ ë“¤ì—¬ë‹¤ ë³´ëŠ” ê²ƒì´ ê³ ì‘ì´ì—ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 14] ---\n",
      "  **ENG**: â€œYou ought to be ashamed of yourself,â€ said Alice,\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ëŠ” ì£¼ì € ì•‰ì•„ ë‹¤ì‹œ ìš¸ê¸° ì‹œì‘í•˜ì˜€ë‹¤.\n",
      "\n",
      "--- [ìŒ 15] ---\n",
      "  **ENG**: â€œa great girl like you,â€\n",
      "  **KOR**: â€œë¶€ë„ëŸ¬ìš´ ì¤„ ì•Œì•„ì•¼ì§€. ë‹¤ í° ì†Œë…€ê°€ ìš¸ë‹¤ë‹ˆ.â€ í•˜ê³  ì•¨ë¦¬ìŠ¤ëŠ” ë§í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 16] ---\n",
      "  **ENG**: (she might well say this),\n",
      "  **KOR**: (ì´ë²ˆì—” í›Œë¥­í•˜ê²Œ ë§í–ˆë‹¤.)\n",
      "\n",
      "--- [ìŒ 17] ---\n",
      "  **ENG**: â€œto go on crying in this way!\n",
      "  **KOR**: â€œì´ë ‡ê²Œ ìš¸ë‹¤ë‹ˆ. ëš!\n",
      "\n",
      "--- [ìŒ 18] ---\n",
      "  **ENG**: Stop this moment, I tell you!â€ But she went on all the same, shedding gallons of tears, until there was a large pool all round her, about four inches deep and reaching half down the hall.\n",
      "  **KOR**: ê·¸ì¹˜ë¼ê³  ë§í–ˆë‹¤!â€ í•˜ì§€ë§Œ ê·¸ ë• ì´ë¯¸ ì•¨ë¦¬ìŠ¤ê°€ í˜ë¦° ëˆˆë¬¼ì´ ë°©ì•ˆì— ê°€ë“ ì°¨ì„œ í° ì›…ë©ì´ê°€ ë˜ì–´ ë²„ë ¸ë‹¤.\n",
      "\n",
      "--- [ìŒ 19] ---\n",
      "  **ENG**: After a time she heard a little pattering of feet in the distance, and she hastily dried her eyes to see what was coming.\n",
      "  **KOR**: ì´ ë•Œ ì–´ë””ì„ ê°€ ë°œìêµ­ ì†Œë¦¬ê°€ ë“¤ë ¸ë‹¤.\n",
      "\n",
      "--- [ìŒ 20] ---\n",
      "  **ENG**: It was the White Rabbit returning, splendidly dressed, with a pair of white kid gloves in one hand and a large fan in the other: he came trotting along in a great hurry, muttering to himself as he came,\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ëŠ” ëˆˆë¬¼ì„ í›”ì¹˜ê³  ì–´ë–¤ ê²ƒì´ ë‹¤ê°€ì˜¤ë‚˜ ì‚´í´ë³´ì•˜ë‹¤.\n",
      "\n",
      "--- [ìŒ 21] ---\n",
      "  **ENG**: wonâ€™t she be savage if Iâ€™ve kept her waiting!â€ Alice felt so desperate that she was ready to ask help of any one; so, when the Rabbit came near her, she began, in a low, timid voice,\n",
      "  **KOR**: â€œì•„, ê³µì‘ ë¶€ì¸, ê³µì‘ ë¶€ì¸. ë‚´ê°€ ê·¸ë…€ë¥¼ ê¸°ë‹¤ë¦¬ê²Œ í–ˆë‹¤ê°„ ê°€ë§Œ ë‘ì§€ ì•Šê² ì§€.â€ ì•¨ë¦¬ìŠ¤ëŠ” ëˆ„ê°€ ì§€ë‚˜ê°€ë“  ì œë°œ ë„ì™€ë‹¬ë¼ê³  í•´ì•¼ í•  ë•Œì—¬ì„œ, í† ë¼ê°€ ë‹¤ê°€ì˜¤ì ì‘ê³  ë‚®ì€ ëª©ì†Œë¦¬ë¡œ ì…ì„ ì—´ì—ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 22] ---\n",
      "  **ENG**: â€œIf you please, sirâ€”â€ The Rabbit started violently, dropped the white kid gloves and the fan, and skurried away into the darkness as hard as he could go.\n",
      "  **KOR**: â€œì €, ê´œì°®ìœ¼ì‹œë©´ â€¦â€¦â€ í† ë¼ëŠ” ê¹œì§ ë†€ë¼ë”ë‹ˆ ì¥ê°‘ê³¼ ë¶€ì±„ë¥¼ ë–¨ì–´ëœ¨ë¦¬ê³ ëŠ” í—ˆë‘¥ê±°ë¦¬ë©° í•  ìˆ˜ ìˆëŠ” í•œ ì¬ë¹¨ë¦¬ ì–´ë‘  ì†ìœ¼ë¡œ ë‹¬ë ¤ê°€ ë²„ë ¸ë‹¤.\n",
      "\n",
      "--- [ìŒ 23] ---\n",
      "  **ENG**: Alice took up the fan and gloves, and, as the hall was very hot, she kept fanning herself all the time she went on talking:\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ëŠ” ë¶€ì±„ì™€ ì¥ê°‘ì„ ì§‘ì–´ ë“¤ì—ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 24] ---\n",
      "  **ENG**: How queer everything is to-day!\n",
      "  **KOR**: â€œì´ëŸ°, ì´ëŸ°. ì˜¤ëŠ˜ì€ ì°¸ ë³„ë‚œ ë‚ ì´ë‹¤!\n",
      "\n",
      "--- [ìŒ 25] ---\n",
      "  **ENG**: And yesterday things went on just as usual.\n",
      "  **KOR**: ì–´ì œëŠ” ëª¨ë“  ê²Œ ë‹¤ í‰ë²”í–ˆëŠ”ë°.\n",
      "\n",
      "--- [ìŒ 26] ---\n",
      "  **ENG**: I wonder if Iâ€™ve been changed in the night?\n",
      "  **KOR**: ë°¤ë™ì•ˆ ë‚´ê°€ ë³€í•œê±¸ê¹Œ?\n",
      "\n",
      "--- [ìŒ 27] ---\n",
      "  **ENG**: Let me think: was I the same when I got up this morning?\n",
      "  **KOR**: ìƒê°í•´ ë³´ì. ë‚˜ëŠ” ì˜¤ëŠ˜ ì•„ì¹¨ ì¼ì–´ë‚¬ì„ ë•Œë‘ ë˜‘ê°™ì€ ë‚œê°€?\n",
      "\n",
      "--- [ìŒ 28] ---\n",
      "  **ENG**: I almost think I can remember feeling a little different.\n",
      "  **KOR**: ë‚œ ë­”ê°€ ì¡°ê¸ˆì€ ë‹¬ë¼ì§„ ê²ƒ ê°™ë‹¤ê³  ëŠê¼ˆë˜ ê±¸ ê¸°ì–µí•  ìˆ˜ ìˆë‹¤ê³  ìƒê°í•˜ëŠ”ë°. í•˜ì§€ë§Œ ë‚´ê°€ ì•„ì¹¨ì˜ ë‚˜ì™€ ê°™ì§€ ì•Šë‹¤ë©´, ë‹¤ìŒ ì§ˆë¬¸ì€, ê·¸ëŸ¼ ë‚˜ëŠ” ëˆ„êµ¬ì§€?\n",
      "\n",
      "--- [ìŒ 29] ---\n",
      "  **ENG**: Ah, _thatâ€™s_ the great puzzle!â€ And she began thinking over all the children she knew that were of the same age as herself, to see if she could have been changed for any of them.\n",
      "  **KOR**: ì—„ì²­ ë³µì¡í•œ ìˆ˜ìˆ˜ê»˜ë¼ë‹¤.â€ ê·¸ëŸ¬ë©´ì„œ ì•¨ë¦¬ìŠ¤ëŠ” ìê¸°ì™€ ë¹„ìŠ·í•œ ë‚˜ì´ì˜ ì•„ì´ë“¤ì„ ë– ì˜¬ë¦¬ë©° í˜¹ì‹œ ê·¸ ì•„ì´ë“¤ ì¤‘ í•˜ë‚˜ë¡œ ë°”ë€ ê²ƒì€ ì•„ë‹Œì§€ ìƒê°í•´ë³´ì•˜ë‹¤.\n",
      "\n",
      "--- [ìŒ 30] ---\n",
      "  **ENG**: â€œIâ€™m sure Iâ€™m not Ada,â€ she said,\n",
      "  **KOR**: â€œë‚œ í™•ì‹¤íˆ ì—ì´ë”ëŠ” ì•„ëƒ.â€ ì•¨ë¦¬ìŠ¤ê°€ ë§í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 31] ---\n",
      "  **ENG**: â€œfor her hair goes in such long ringlets, and mine doesnâ€™t go in ringlets at all; and Iâ€™m sure I canâ€™t be Mabel, for I know all sorts of things, and she, oh!\n",
      "  **KOR**: â€œê·¸ ì•  ë¨¸ë¦¬ì¹´ë½ì€ ë„ˆë¬´ ê¸´ ê³±ìŠ¬ë¨¸ë¦¬ì•¼. ë‚´ê»€ ê³±ìŠ¬ê±°ë¦¬ì§€ ì•Šì•„. ê·¸ë¦¬ê³ , ë‚´ê°€ ì•„ëŠ” í•œ, ë‚œ í™•ì‹¤íˆ ë©”ì´ë¸”ì´ ë  ìˆ˜ë„ ì—†ì–´.\n",
      "\n",
      "--- [ìŒ 32] ---\n",
      "  **ENG**: she knows such a very little!\n",
      "  **KOR**: ê·¸ ì•¤ ë„ˆë¬´ ì•„ëŠ” ê²Œ ì—†ì–´. ê²Œë‹¤ê°€ ê·¸ ì•  ëŠ” ê·¸ ì• ê³  ë‚˜ ëŠ” ë‚˜ì–ì•„, ê·¸ë¦¬ê³ , ì–´â€¦ ì•„ì´ì¿ , ë­ë“  ì™œ ì´ë¦¬ ë³µì¡í•œ ìˆ˜ìˆ˜ê»˜ë¼ê°€ ë˜ëŠ” ê±°ì§€!\n",
      "\n",
      "--- [ìŒ 33] ---\n",
      "  **ENG**: Besides, _sheâ€™s_ she, and _Iâ€™m_ I, andâ€”oh dear, how puzzling it all is!\n",
      "  **KOR**: ë‚´ê°€ ì•Œë˜ ê²ƒë“¤ì„ ì œëŒ€ë¡œ ë‹¤ ê¸°ì–µí•˜ê³  ìˆëŠ”ì§€ ë´ì•¼ê² ë‹¤.\n",
      "\n",
      "--- [ìŒ 34] ---\n",
      "  **ENG**: Iâ€™ll try if I know all the things I used to know. Let me see: four times five is twelve, and four times six is thirteen, and four times seven isâ€”oh dear!\n",
      "  **KOR**: ì–´ë””ë³´ì, 4 ê³±í•˜ê¸° 5ëŠ” 12, ê·¸ë¦¬ê³  4 ê³±í•˜ê¸° 6ì€ 13, 4 ê³±í•˜ê¸° 7ì€â€¦, ì•„ì´ì¿  ì´ëŸ° ì‹ìœ¼ë¡œëŠ” 20ê¹Œì§€ëŠ” ì ˆëŒ€ ëª» ê°€ê² ëŠ”ë°!\n",
      "\n",
      "--- [ìŒ 35] ---\n",
      "  **ENG**: I shall never get to twenty at that rate!\n",
      "  **KOR**: í•˜ì§€ë§Œ, êµ¬êµ¬ë‹¨ì€ ê·¸ë¦¬ ì¤‘ìš”í•œ ê²Œ ì•„ë‹ˆë‹ˆê¹Œ, ì§€ë¦¬ë¥¼ ìƒê°í•´ ë³¼ê¹Œ?\n",
      "\n",
      "--- [ìŒ 36] ---\n",
      "  **ENG**: However, the Multiplication Table doesnâ€™t signify: letâ€™s try Geography. London is the capital of Paris, and Paris is the capital of Rome, and Romeâ€”no, _thatâ€™s_ all wrong, Iâ€™m certain!\n",
      "  **KOR**: ëŸ°ë˜ì€ íŒŒë¦¬ì˜ ìˆ˜ë„, íŒŒë¦¬ëŠ” ë¡œë§ˆì˜ ìˆ˜ë„ â€¦â€¦, ì•„ë‹ˆì•¼.\n",
      "\n",
      "--- [ìŒ 37] ---\n",
      "  **ENG**: I must have been changed for Mabel!\n",
      "  **KOR**: ëª½ë•… í‹€ë ¸ì–´. í™•ì‹¤í•´!\n",
      "\n",
      "--- [ìŒ 38] ---\n",
      "  **ENG**: Iâ€™ll try and say â€˜_How doth the little_â€”â€™â€ and she crossed her hands on her lap as if she were saying lessons, and began to repeat it, but her voice sounded hoarse and strange, and the words did not come the same as they used to do:â€”\n",
      "  **KOR**: ë‚œ ì•„ë¬´ë˜ë„ ë©”ì´ë¸”ì´ ëœ ê²ƒ ê°™ì•„!\n",
      "\n",
      "--- [ìŒ 39] ---\n",
      "  **ENG**: â€œHow doth the little crocodile Improve his shining tail, And pour the waters of the Nile On every golden scale!\n",
      "  **KOR**: â€˜ì–´ì©œ ì´ë¦¬ ì‘ì€â€™ì„ ë‚­ì†¡í•´ ë´ì•¼ê² ë‹¤. ê·¸ëŸ¬ë©´ ê·¸ ì• ëŠ” ìˆ˜ì—…ì‹œê°„ì— ê·¸ëŸ° ê²ƒ ì²˜ëŸ¼ ë‘ ì†ì„ ì—Šê°ˆë ¤ ë¬´ë¦ì— ì–¹ê³  ë”°ë¼í–ˆì—ˆì§€. í•˜ì§€ë§Œ ê·¸ ì•¤ ì´ìƒí•œ ì‰° ëª©ì†Œë¦¬ë¥¼ ë‚´ëŠ” ë°ë‹¤ ë§ë„ ë‹¤ë¥¸ ì‚¬ëŒì´ í•˜ëŠ” ê²ƒì²˜ëŸ¼ í•˜ì§€ ì•ŠëŠ”ë°â€¦â€¦ 'ì–´ì©œ ì´ë¦¬ ì‘ì„ê¹Œâ€™ë¡œ ì‹œì‘í•˜ëŠ” ì‹œë¥¼ ë‚­ì†¡í•´ ë´ì•¼ê² ë‹¤.\n",
      "\n",
      "--- [ìŒ 40] ---\n",
      "  **ENG**: â€œHow cheerfully he seems to grin, How neatly spread his claws, And welcome little fishes in With gently smiling jaws!â€\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ëŠ” ìˆ˜ì—… ì‹œê°„ ë•Œ ì²˜ëŸ¼ ë‘ì†ì„ ì—‡ê°ˆë ¤ ë¬´ë¦ì— ë†“ê³  ì‹œë¥¼ ì™¸ìš°ê¸° ì‹œì‘í–ˆë‹¤. í•˜ì§€ë§Œ ì•¨ë¦¬ìŠ¤ì˜ ëª©ì†Œë¦¬ëŠ” ê±°ì¹ ê³  ì´ìƒí•˜ê²Œ ë‚˜ì™”ìœ¼ë©° ë‚´ìš©ë„ ì›ë˜ì™€ ë‹¤ë¥´ê²Œ ë‚˜ì™”ë‹¤ ì–´ì©œ ì´ë¦¬ ì‘ì€ ì•…ì–´ê°€ ì´ë ‡ê²Œ ë°˜ì§ì´ëŠ” ê¼¬ë¦¬ë¥¼ ì˜¬ë ¤ ë‚˜ì¼ê°•ì˜ ëª¨ë“  ê°•ë¬¼ì„ í™©ê¸ˆ ë¹„ëŠ˜ì— ê³³ê³³ì— í©ë¿Œë¦¬ëŠ”ì§€ ì–´ì©œ ì €ë¦¬ ë°©ë— ì›ƒëŠ”ì§€ ë‚ ì¹´ë¡œìš´ ë°œí†±ì„ ê°€ì§€ëŸ°íˆ í´ê³ ì„œ ë¬¼ê³ ê¸°ë“¤ì„ ë°˜ê¸°ì§€ ì¹œì ˆí•˜ê²Œ ì›ƒìŒ ì§“ëŠ” ì… ì†ìœ¼ë¡œ â€œì´ê±´ í™•ì‹¤íˆ ì œëŒ€ë¡œ ëœ ë‚´ìš©ì´ ì•„ë‹ˆì•¼.â€ ê°€ì—¬ìš´ ì•¨ë¦¬ìŠ¤ëŠ” ë‹¤ì‹œ ìš¸ê¸° ì‹œì‘í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 41] ---\n",
      "  **ENG**: â€œIâ€™m sure those are not the right words,â€ said poor Alice, and her eyes filled with tears again as she went on,\n",
      "  **KOR**: â€œ ë©”ì´ë¸”ì´ ëœ ê²Œ í‹€ë¦¼ì—†ì–´. ê·¸ë¦¬ê³  ê·¸ í—ˆë¦„í•œ ì§‘ì— ë“¤ì–´ê°€ ì‚´ê²Œ ë˜ê² ì§€. ì¥ë‚œê°ë„ ì—†ê³  ë†€ì§€ë„ ëª»í•  ê±°ì•¼.\n",
      "\n",
      "--- [ìŒ 42] ---\n",
      "  **ENG**: ever so many lessons to learn!\n",
      "  **KOR**: ê·¸ë¦¬ê³  ì—„ì²­ë‚˜ê²Œ ê³µë¶€ë§Œ ë°°ìš°ê²Œ ë ê±°ì•¼. ì•„ëƒ, ë‚œ ë§ˆìŒì„ ì •í–ˆì–´.\n",
      "\n",
      "--- [ìŒ 43] ---\n",
      "  **ENG**: No, Iâ€™ve made up my mind about it; if Iâ€™m Mabel, Iâ€™ll stay down here!\n",
      "  **KOR**: ë‚´ê°€ ë©”ì´ë¸”ì´ë¼ë©´ ê·¸ëƒ¥ ì—¬ê¸°ì— ìˆì„ ê±°ì•¼!\n",
      "\n",
      "--- [ìŒ 44] ---\n",
      "  **ENG**: Itâ€™ll be no use their putting their heads down and saying â€˜Come up again, dear!\n",
      "  **KOR**: ì‚¬ëŒë“¤ì´ êµ¬ë©ì— ê³ ê°œë¥¼ ë„£ê³  â€˜ì–˜ì•¼ ì–´ì„œ ë‹¤ì‹œ ì˜¬ë¼ì˜¤ë ´â€™ í•´ë„ ë‚˜ëŠ” â€˜ê·¸ëŸ¼ ì œê°€ ëˆ„êµ¬ì£ ?\n",
      "\n",
      "--- [ìŒ 45] ---\n",
      "  **ENG**: â€™ I shall only look up and say â€˜Who am I then?\n",
      "  **KOR**: ë¨¼ì € ë§í•´ì£¼ì„¸ìš”.â€™ ë¼ê³  í• êº¼ì•¼.\n",
      "\n",
      "--- [ìŒ 46] ---\n",
      "  **ENG**: Tell me that first, and then, if I like being that person, Iâ€™ll come up: if not, Iâ€™ll stay down here till Iâ€™m somebody elseâ€™â€”but, oh dear!â€ cried Alice, with a sudden burst of tears,\n",
      "  **KOR**: â€˜ë§Œì•½ ê·¸ ì‚¬ëŒì´ ë˜ëŠ”ê²Œ ë‚´ ë§ˆìŒì— ë“¤ë©´ ì˜¬ë¼ê°ˆ ê±°ì§€ë§Œ, ì•„ë‹ˆë©´ ê·¸ëƒ¥ ì—¬ê¸° ìˆì„ë˜. ë‹¤ì‹œ ë‹¤ë¥¸ ì‚¬ëŒì´ ë  ë•Œê¹Œì§€.â€™ í•´ì•¼ì§€. í•˜ì§€ë§Œ, ì´ëŸ°!â€ ì•¨ë¦¬ìŠ¤ëŠ” ê°‘ìê¸° ìš¸ìŒì„ í„°ëœ¨ë ¸ë‹¤.\n",
      "\n",
      "--- [ìŒ 47] ---\n",
      "  **ENG**: â€œI do wish they _would_ put their heads down!\n",
      "  **KOR**: â€œê·¸ëƒ¥ ì‚¬ëŒë“¤ì´ êµ¬ë©ì— ë¨¸ë¦¬ë‚˜ ë””ë°€ì–´ ì¤¬ìœ¼ë©´!\n",
      "\n",
      "--- [ìŒ 48] ---\n",
      "  **ENG**: I am so _very_ tired of being all alone here!â€ As she said this she looked down at her hands, and was surprised to see that she had put on one of the Rabbitâ€™s little white kid gloves while she was talking.\n",
      "  **KOR**: ì—¬ê¸° í˜¼ì ìˆì–´ì„œ ë„ˆë¬´ ë„ˆë¬´ ì§€ì³¤ì–´.â€ ì´ë ‡ê²Œ ë§í•˜ë©° ì•¨ë¦¬ìŠ¤ëŠ” ìê¸° ì†ì„ ë‚´ë ¤ë‹¤ ë³´ì•˜ë‹¤.\n",
      "\n",
      "--- [ìŒ 49] ---\n",
      "  **ENG**: â€œHow _can_ I have done that?â€ she thought.\n",
      "  **KOR**: â€œë‚´ê°€ ì´ê±¸ ì–´ë–»ê²Œ í•œê±°ì§€?â€ ì•¨ë¦¬ìŠ¤ëŠ” ìƒê°í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 50] ---\n",
      "  **ENG**: â€œI must be growing small again.â€ She got up and went to the table to measure herself by it, and found that, as nearly as she could guess, she was now about two feet high, and was going on shrinking rapidly: she soon found out that the cause of this was the fan she was holding, and she dropped it hastily, just in time to avoid shrinking away altogether.\n",
      "  **KOR**: â€œë‹¤ì‹œ ì‘ì•„ì§„ ê²Œ í‹€ë¦¼ì—†ì–´.â€ ì•¨ë¦¬ìŠ¤ëŠ” ì¼ì–´ë‚˜ ìê¸° í‚¤ë¥¼ íƒìì™€ ê²¬ì£¼ì–´ ë³´ì•˜ë‹¤.\n",
      "\n",
      "--- [ìŒ 51] ---\n",
      "  **ENG**: â€œThat _was_ a narrow escape!â€ said Alice, a good deal frightened at the sudden change, but very glad to find herself still in existence;\n",
      "  **KOR**: ê°‘ì‘ìŠ¤ëŸ¬ìš´ ë³€í™”ì— ê²ì„ ë¨¹ê¸°ëŠ” í–ˆì§€ë§Œ ì™„ì „íˆ ì‚¬ë¼ì§€ì§€ ì•Šì•˜ë‹¤ëŠ” ê²ƒì´ ê¸°ë»¤ë‹¤.\n",
      "\n",
      "--- [ìŒ 52] ---\n",
      "  **ENG**: â€œand now for the garden!â€ and she ran with all speed back to the little door: but, alas!\n",
      "  **KOR**: â€œê·¸ëŸ¼, ì´ì œ ì •ì›ìœ¼ë¡œ!â€ ì•¨ë¦¬ìŠ¤ëŠ” ì „ì†ë ¥ìœ¼ë¡œ ì‘ì€ ë¬¸ì„ í–¥í•´ ë‹¬ë ¸ë‹¤.\n",
      "\n",
      "--- [ìŒ 53] ---\n",
      "  **ENG**: the little door was shut again, and the little golden key was lying on the glass table as before,\n",
      "  **KOR**: ì‘ì€ ë¬¸ì€ ê·¸ ìƒˆ ë‹«í˜€ ìˆì—ˆê³ , ì‘ì€ í™©ê¸ˆ ì—´ì‡ ëŠ” ì—¬ì „íˆ íƒì ìœ„ì— ë†“ì—¬ ìˆì—ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 54] ---\n",
      "  **ENG**: â€œand things are worse than ever,â€ thought the poor child,\n",
      "  **KOR**: â€œë” ë‚˜ë¹ ì§€ê¸°ë§Œ í–ˆì–ì•„!â€ ì•¨ë¦¬ìŠ¤ëŠ” ìƒê°í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 55] ---\n",
      "  **ENG**: â€œfor I never was so small as this before, never!\n",
      "  **KOR**: â€œë‚œ ì´ë ‡ê²Œ ì‘ì•˜ë˜ ì ì´ ì—†ì–´. í•œ ë²ˆë„!\n",
      "\n",
      "--- [ìŒ 56] ---\n",
      "  **ENG**: And I declare itâ€™s too bad, that it is!â€ As she said these words her foot slipped, and in another moment, splash!\n",
      "  **KOR**: ì´ê±´ ì •ë§ ë‚˜ë¹ , ë‚˜ì˜ë‹¤êµ¬!â€ ê·¸ ìˆœê°„, ì•¨ë¦¬ìŠ¤ì˜ ë°œì´ ë¯¸ë„ëŸ¬ì¡Œë‹¤.\n",
      "\n",
      "--- [ìŒ 57] ---\n",
      "  **ENG**: she was up to her chin in salt water.\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ì˜ ëº¨ì— ì§ ë¬¼ì´ ë‹¿ì•˜ë‹¤.\n",
      "\n",
      "--- [ìŒ 58] ---\n",
      "  **ENG**: Her first idea was that she had somehow fallen into the sea,\n",
      "  **KOR**: ì²˜ìŒì— ì•¨ë¦¬ìŠ¤ëŠ” ë°”ë‹¤ì— ë¹ ì¡Œë‹¤ê³  ìƒê°í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 59] ---\n",
      "  **ENG**: â€œand in that case I can go back by railway,â€ she said to herself.\n",
      "  **KOR**: â€œê·¸ëŸ¬ë©´ ë‚œ ê¸°ì°¨ë¥¼ íƒ€ê³  ëŒì•„ê°€ì•¼ì§€.â€ ì•¨ë¦¬ìŠ¤ëŠ” ìƒê°í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 60] ---\n",
      "  **ENG**: (Alice had been to the seaside once in her life, and had come to the general conclusion, that wherever you go to on the English coast you find a number of bathing machines in the sea, some children digging in the sand with wooden spades, then a row of lodging houses, and behind them a railway station.)\n",
      "  **KOR**: ê±°ê¸°ì„œ ì˜êµ­ í•´ì•ˆì´ë¼ë©´ ì–´ë””ë‚˜ ì—¬ëŸ¬ ê°œì˜ ì˜·ì„ ê°ˆì•„ì…ëŠ” ê³µê°„ì´ ë°”ë‹¤ ìœ„ì— ë– ìˆê³ , ì•„ì´ë“¤ì´ ë‚˜ë¬´ ì‚½ìœ¼ë¡œ ëª¨ë˜ ë†€ì´ë¥¼ í•˜ë©°, ê·¸ ë’¤ì— ì¤„ì¤„ì´ ìˆ™ì†Œê°€ ìˆê³ , ê·¸ ë’¤ë¡œ ê¸°ì°¨ì—­ì´ ìˆë‹¤ê³  ìƒê°í•˜ê²Œ ë˜ì—ˆë‹¤.)\n",
      "\n",
      "--- [ìŒ 61] ---\n",
      "  **ENG**: However, she soon made out that she was in the pool of tears which she had wept when she was nine feet high.\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ëŠ” ì–¼ë§ˆ ì§€ë‚˜ì§€ ì•Šì•„ ì´ê²Œ ì‚¬ì‹¤ì€ ìê¸° í‚¤ê°€ 9í”¼íŠ¸ì¼ ë•Œ í˜ë ¸ë˜ ëˆˆë¬¼ì´ ë§Œë“  ì›…ë©ì´ë¼ëŠ” ê²ƒì„ ê¹¨ë‹¬ì•˜ë‹¤.\n",
      "\n",
      "--- [ìŒ 62] ---\n",
      "  **ENG**: â€œI wish I hadnâ€™t cried so much!â€ said Alice, as she swam about, trying to find her way out.\n",
      "  **KOR**: â€œê·¸ë ‡ê²Œ ë§ì´ ìš¸ì§€ ë§ê»„!â€ í•˜ê³  ë§í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 63] ---\n",
      "  **ENG**: â€œI shall be punished for it now, I suppose, by being drowned in my own tears!\n",
      "  **KOR**: â€œë‚´ê°€ ê·¸ë ‡ê²Œ ë§ì€ ëˆˆë¬¼ì„ í˜ë ¤ì„œ ë‚´ ëˆˆë¬¼ì— ë¹ ì ¸ ì£½ê²Œ ë˜ëŠ” ë²Œì„ ë°›ëŠ” ê±¸ ê±°ì•¼. ì§„ì§œ ì´ìƒí•œ ì¼ì´ë‹¤. í•˜ì§€ë§Œ ì˜¤ëŠ˜ì€ ëª¨ë“  ê²Œ ë‹¤ ì´ìƒí•œ ë‚ ì¸ê±¸.â€ ê·¸ ë•Œ ì–´ë””ì„ ê°€ ì²¨ë²™ê±°ë¦¬ëŠ” ì†Œë¦¬ê°€ ë“¤ë ¸ë‹¤.\n",
      "\n",
      "--- [ìŒ 64] ---\n",
      "  **ENG**: That _will_ be a queer thing, to be sure!\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ëŠ” ê·¸ê²Œ ë¬´ì—‡ì¸ì§€ ì•Œì•„ë³´ë ¤ í—¤ì—„ì³ ë‹¤ê°€ê°”ë‹¤.\n",
      "\n",
      "--- [ìŒ 65] ---\n",
      "  **ENG**: However, everything is queer to-day.â€ Just then she heard something splashing about in the pool a little way off, and she swam nearer to make out what it was: at first she thought it must be a walrus or hippopotamus, but then she remembered how small she was now, and she soon made out that it was only a mouse that had slipped in like herself.\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ëŠ” ì²˜ìŒì— ê·¸ê²ƒì´ ë°”ë‹¤ì½”ë¼ë¦¬ ì´ê±°ë‚˜ í•˜ë§ˆì¼ ê²ƒì´ë¼ê³  ìƒê°í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 66] ---\n",
      "  **ENG**: â€œWould it be of any use, now,â€ thought Alice,\n",
      "  **KOR**: ê·¸ëŸ¬ë‚˜ ì•¨ë¦¬ìŠ¤ëŠ” ìì‹ ì´ ì‘ì•„ì§„ ê²ƒì„ ë– ì˜¬ë¦¬ê³ ëŠ” í—¤ì—„ì³ ì˜¤ëŠ” ë™ë¬¼ì´ ì•¨ë¦¬ìŠ¤ì²˜ëŸ¼ ì›…ë©ì´ì— ë¯¸ë„ëŸ¬ì§„ ìƒì¥ë¼ëŠ” ê²ƒì„ ì•Œì•˜ë‹¤.\n",
      "\n",
      "--- [ìŒ 67] ---\n",
      "  **ENG**: â€œto speak to this mouse?\n",
      "  **KOR**: â€œì´ ìƒì¥ë‘ ì´ì•¼ê¸°í•˜ëŠ” ê²Œ ë„ì›€ì´ ë ê¹Œ?â€ ì•¨ë¦¬ìŠ¤ëŠ” ìƒê°í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 68] ---\n",
      "  **ENG**: Everything is so out-of-the-way down here, that I should think very likely it can talk: at any rate, thereâ€™s no harm in trying.â€ So she began:\n",
      "  **KOR**: â€œì—¬ê¸´ ëª¨ë“  ê²Œ ë‹¤ ì´ìƒí•˜ë‹ˆê¹Œ, ìƒì¥ë„ ë§í•  ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„. ì–´ì¨Œë“ , ì‹œë„ í•´ ë³´ëŠ” ê²Œ ë‚˜ì  ê²ƒë„ ì—†ì§€.â€ ê·¸ë¦¬ê³ ëŠ” ì•¨ë¦¬ìŠ¤ê°€ ìƒì¥ì—ê²Œ ë§ì„ ê±¸ì—ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 69] ---\n",
      "  **ENG**: â€œO Mouse, do you know the way out of this pool?\n",
      "  **KOR**: â€œì˜¤, ìƒì¥ì•¼. ì´ ì›…ë©ì´ë¥¼ ë¹ ì ¸ë‚˜ê°ˆ ê¸¸ì„ ì•„ë‹ˆ?\n",
      "\n",
      "--- [ìŒ 70] ---\n",
      "  **ENG**: I am very tired of swimming about here, O Mouse!â€\n",
      "  **KOR**: ì˜¤, ìƒì¥ì•¼.â€\n",
      "\n",
      "--- [ìŒ 71] ---\n",
      "  **ENG**: (Alice thought this must be the right way of speaking to a mouse: she had never done such a thing before, but she remembered having seen in her brotherâ€™s Latin Grammar,\n",
      "  **KOR**: (ì•¨ë¦¬ìŠ¤ëŠ” ì´ê²Œ ìƒì¥ì—ê²Œ ë§ì„ ê±°ëŠ” ì•Œë§ì€ ë°©ë²•ì´ë¼ê³  ìƒê°í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 72] ---\n",
      "  **ENG**: â€œA mouseâ€”of a mouseâ€”to a mouseâ€”a mouseâ€”O mouse!â€ ) The Mouse looked at her rather inquisitively, and seemed to her to wink with one of its little eyes, but it said nothing.\n",
      "  **KOR**: â€œì•„ ì–´ ë§ˆìš°ìŠ¤ - íˆ¬ ë§ˆìš°ìŠ¤, ì•„ ë§ˆìš°ìŠ¤ - ì˜¤ ë§ˆìš°ìŠ¤â€ í•˜ê³  ë§í–ˆë˜ ê²ƒì´ ê¸°ì–µë‚¬ê¸° ë•Œë¬¸ì´ì—ˆë‹¤.) ìƒì¥ëŠ” ëª¹ì‹œ ê¶ê¸ˆí•´í•˜ëŠ” í‘œì •ìœ¼ë¡œ ì•¨ë¦¬ìŠ¤ë¥¼ ë°”ë¼ë³´ê³ ëŠ” í•œ ìª½ ëˆˆì„ ì°¡ë— í•œë“¯ í–ˆì§€ë§Œ, ì•„ë¬´ëŸ° ë§ë„ í•˜ì§€ ì•Šì•˜ë‹¤.\n",
      "\n",
      "--- [ìŒ 73] ---\n",
      "  **ENG**: â€œPerhaps it doesnâ€™t understand English,â€ thought Alice;\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ëŠ”\n",
      "\n",
      "--- [ìŒ 74] ---\n",
      "  **ENG**: â€œI daresay itâ€™s a French mouse, come over with William the Conqueror.â€\n",
      "  **KOR**: â€œì•„ë§ˆë„ ì˜ì–´ë¥¼ ëª» ì•Œì•„ ë“£ë‚˜ë´. ì •ë³µì ìœŒë¦¬ì—„ì´ë‘ í•¨ê»˜ ê±´ë„ˆì˜¨ í”„ë‘ìŠ¤ ì¥ì¸ê°€?â€ í•˜ê³  ìƒê°í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 75] ---\n",
      "  **ENG**: (For, with all her knowledge of history, Alice had no very clear notion how long ago anything had happened.)\n",
      "  **KOR**: (ì•¨ë¦¬ìŠ¤ëŠ” ì—­ì‚¬ì— ì“°ì¸ ì¼ë“¤ì´ ì •í™•íˆ ì–¸ì œ ìˆì—ˆê³  ì–¼ë§ˆë‚˜ ì˜¤ë˜ ëœ ì¼ì¸ì§€ ì˜ ì•Œì§€ ëª»í–ˆë‹¤.)\n",
      "\n",
      "--- [ìŒ 76] ---\n",
      "  **ENG**: So she began again:\n",
      "  **KOR**: ê·¸ë˜ì„œ ì•¨ë¦¬ìŠ¤ëŠ” í”„ë‘ìŠ¤ì–´ë¡œ ë§í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 77] ---\n",
      "  **ENG**: â€œOÃ¹ est ma chatte?â€ which was the first sentence in her French lesson-book.\n",
      "  **KOR**: â€œìš° ì— ë§ˆ ìƒ¤íŠ¸(ë‚´ ê³ ì–‘ì´ëŠ” ì–´ë””ì— ìˆì§€?)?â€ ì•¨ë¦¬ìŠ¤ì˜ í”„ë‘ìŠ¤ì–´ êµê³¼ì„œ ì²˜ìŒì— ì íŒ ë¬¸ì¥ì´ì—ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 78] ---\n",
      "  **ENG**: The Mouse gave a sudden leap out of the water, and seemed to quiver all over with fright.\n",
      "  **KOR**: ìˆœê°„ ìƒì¥ëŠ” í„ì© ë›°ì–´ ì˜¬ëê³  ë‘ë ¤ì›Œì„œ ë²Œë²Œ ë– ëŠ” ê²ƒ ì²˜ëŸ¼ ë³´ì˜€ë‹¤.\n",
      "\n",
      "--- [ìŒ 79] ---\n",
      "  **ENG**: â€œOh, I beg your pardon!â€ cried Alice hastily, afraid that she had hurt the poor animalâ€™s feelings.\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ëŠ” ìì‹ ì´ ê°€ì—¬ìš´ ë™ë¬¼ì˜ ë§ˆìŒì„ ìƒí•˜ê²Œ í•œ ê²ƒ ê°™ì•„ ë‹¤ê¸‰íˆ ì™¸ì³¤ë‹¤.\n",
      "\n",
      "--- [ìŒ 80] ---\n",
      "  **ENG**: â€œI quite forgot you didnâ€™t like cats.â€\n",
      "  **KOR**: ë„Œ ê³ ì–‘ì´ë¥¼ ì¢‹ì•„í•˜ì§€ ì•ŠëŠ” ë‹¤ëŠ” ê±¸ ìŠì—ˆì–´.â€ ìƒì¥ê°€ ë‚ ì¹´ë¡­ê³  í° ì†Œë¦¬ë¡œ ëŒ€ë‹µí–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 81] ---\n",
      "  **ENG**: â€œNot like cats!â€ cried the Mouse, in a shrill, passionate voice.\n",
      "  **KOR**: â€œê³ ì–‘ì´ ì‹«ë‹¤!\n",
      "\n",
      "--- [ìŒ 82] ---\n",
      "  **ENG**: â€œWould _you_ like cats if you were me?â€\n",
      "  **KOR**: ë„¤ê°€ ë‚˜ë¼ë©´ ê³ ì–‘ì´ê°€ ì¢‹ê² ë‹ˆ?â€\n",
      "\n",
      "--- [ìŒ 83] ---\n",
      "  **ENG**: â€œWell, perhaps not,â€ said Alice in a soothing tone:\n",
      "  **KOR**: â€œìŒ, ì•„ë§ˆ ì•ˆ ì¢‹ì•„í•  ê±°ì•¼.â€ í•˜ê³  ì•¨ë¦¬ìŠ¤ëŠ” ìƒì¥ë¥¼ ë‹¬ë¬ë‹¤.\n",
      "\n",
      "--- [ìŒ 84] ---\n",
      "  **ENG**: â€œdonâ€™t be angry about it. And yet I wish I could show you our cat Dinah: I think youâ€™d take a fancy to cats if you could only see her. She is such a dear quiet thing,â€ Alice went on, half to herself, as she swam lazily about in the pool,\n",
      "  **KOR**: â€œí™”ë‚´ì§€ ë§ˆ. ë‚œ ìš°ë¦¬ ê³ ì–‘ì´ ë””ë‚˜ê°€ ë³´ê³  ì‹¶ì–´. ë„ˆë„ ë””ë‚˜ë¥¼ ë³´ë©´ ì¢‹ì•„í•˜ê²Œ ë  êº¼ì•¼.\n",
      "\n",
      "--- [ìŒ 85] ---\n",
      "  **ENG**: â€œand she sits purring so nicely by the fire, licking her paws and washing her faceâ€”and she is such a nice soft thing to nurseâ€”and sheâ€™s such a capital one for catching miceâ€”oh, I beg your pardon!â€ cried Alice again, for this time the Mouse was bristling all over, and she felt certain it must be really offended.\n",
      "  **KOR**: ê·¸ë¦¬ê³ , ì¥ë¥¼ ì •ë§ ì˜ ì¡ì•„ -- ì•„, ë¯¸ì•ˆí•´!â€ ì•¨ë¦¬ìŠ¤ëŠ” ë‹¤ì‹œ í° ì†Œë¦¬ë¡œ ë§í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 86] ---\n",
      "  **ENG**: â€œWe wonâ€™t talk about her any more if youâ€™d rather not.â€\n",
      "  **KOR**: â€œë„¤ê°€ ì‹«ë‹¤ë©´ ë””ë‚˜ ì• ê¸°ëŠ” ê·¸ë§Œ í•´ì•¼ í•˜ê² ë‹¤.â€\n",
      "\n",
      "--- [ìŒ 87] ---\n",
      "  **ENG**: â€œWe indeed!â€ cried the Mouse, who was trembling down to the end of his tail.\n",
      "  **KOR**: â€œë‹¹ì—°íˆ!â€ í•˜ê³  ìƒì¥ê°€ ëŠ˜ì–´ëœ¨ë¦° ê¼¬ë¦¬ ëì„ ë–¨ë©´ì„œ í° ì†Œë¦¬ë¡œ ë§í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 88] ---\n",
      "  **ENG**: â€œAs if _I_ would talk on such a subject!\n",
      "  **KOR**: â€œê·¸ëŸ° ì–˜ê¸°ëŠ” ê´€ë‘ì!\n",
      "\n",
      "--- [ìŒ 89] ---\n",
      "  **ENG**: Our family always _hated_ cats: nasty, low, vulgar things!\n",
      "  **KOR**: ìš°ë¦¬ ê°€ë¬¸ì€ ê³ ì–‘ì´ ê°™ì€ ë”ëŸ½ê³  ì²œí•œ ë¬´ì‹í•œ ê²ƒë“¤ì€ ì‹«ì–´í•´!\n",
      "\n",
      "--- [ìŒ 90] ---\n",
      "  **ENG**: Donâ€™t let me hear the name again!â€\n",
      "  **KOR**: ë‹¤ì‹  ê·¸ ì–˜ê¸°í•˜ì§€ ë§ˆ!â€\n",
      "\n",
      "--- [ìŒ 91] ---\n",
      "  **ENG**: â€œI wonâ€™t indeed!â€ said Alice, in a great hurry to change the subject of conversation.\n",
      "  **KOR**: â€œì•Œì•˜ì–´.â€ ì•¨ë¦¬ìŠ¤ëŠ” ì¬ë¹¨ë¦¬ í™”ì œë¥¼ ëŒë ¸ë‹¤.\n",
      "\n",
      "--- [ìŒ 92] ---\n",
      "  **ENG**: â€œAre youâ€”are you fondâ€”ofâ€”of dogs?â€ The Mouse did not answer, so Alice went on eagerly:\n",
      "  **KOR**: â€œë„ˆ -- ë„ˆëŠ” ê°œ -- ê°œëŠ” ì¢‹ì•„í•˜ë‹ˆ?â€ ìƒì¥ê°€ ì•„ë¬´ ë§ë„ í•˜ì§€ ì•Šì ì•¨ë¦¬ìŠ¤ëŠ” ì—´ì‹¬íˆ ë§í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 93] ---\n",
      "  **ENG**: â€œThere is such a nice little dog near our house I should like to show you!\n",
      "  **KOR**: â€œì§„ì§œ ë©‹ì§„ ê°œê°€ ìš°ë¦¬ ì˜† ì§‘ì— ì‚¬ëŠ”ë°. ë‚œ ê·¸ ê°œë¥¼ ë³´ëŠ” ê²Œ ì •ë§ ì¢‹ì•„. ìˆì–ì•„, ê±˜ ëˆˆì´ ë°˜ì§ê±°ë¦¬ëŠ” í…Œë¦¬ì–´ì•¼.\n",
      "\n",
      "--- [ìŒ 94] ---\n",
      "  **ENG**: A little bright-eyed terrier, you know, with oh, such long curly brown hair!\n",
      "  **KOR**: ì•„, ê³±ìŠ¬ê±°ë¦¬ëŠ” ê°ˆìƒ‰ í„¸!\n",
      "\n",
      "--- [ìŒ 95] ---\n",
      "  **ENG**: And itâ€™ll fetch things when you throw them, and itâ€™ll sit up and beg for its dinner, and all sorts of thingsâ€”I canâ€™t remember half of themâ€”and it belongs to a farmer, you know, and he says itâ€™s so useful, itâ€™s worth a hundred pounds!\n",
      "  **KOR**: ê·¸ë¦¬ê³  ë©‹ì§„ ì ì´ ì•„ì£¼ ë§ì•„ -- ë°˜ë„ ê¸°ì–µì´ ì•ˆë‚œì§€ë§Œ. ìˆì–ì•„, ê·¸ë¦¬ê³  ê·¸ ê°œëŠ” ë†ë¶€ ì•„ì €ì”¨ê°€ ê¸¸ëŸ¬. ë†ë¶€ ì•„ì €ì”¨ëŠ” ê·¸ ê°œê°€ ì •ë§ ì“¸ëª¨ ìˆê³ , ê°’ë„ ëª‡ ë°± íŒŒìš´ë“œë‚˜ ë˜ëŠ” ì¢‹ì€ ê°œë¬ì–´!\n",
      "\n",
      "--- [ìŒ 96] ---\n",
      "  **ENG**: He says it kills all the rats andâ€”oh dear!â€ cried Alice in a sorrowful tone,\n",
      "  **KOR**: ë†ë¶€ ì•„ì €ì”¨ëŠ” ê·¸ ê°œê°€ ì¥ë„ ì˜ ì¡ê³  ë˜ -- ì•„ì´ì¿ !â€ ì•¨ë¦¬ìŠ¤ëŠ” ë¯¸ì•ˆí•œ ëª©ì†Œë¦¬ë¡œ ë§í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 97] ---\n",
      "  **ENG**: â€œIâ€™m afraid Iâ€™ve offended it again!â€ For the Mouse was swimming away from her as hard as it could go, and making quite a commotion in the pool as it went.\n",
      "  **KOR**: â€œë‚´ê°€ ë˜ ë„¤ ë§ˆìŒì„ ìƒí•˜ê²Œ í–ˆë‚˜ë´!â€ ìƒì¥ëŠ” ì²¨ë²™ê±°ë¦¬ë©° ë¬¼ì‚´ì„ ë§Œë“¤ë©´ì„œ ì˜¨ í˜ì„ ë‹¤í•´ ë©€ë¦¬ í—¤ì—„ì³ ê°€ê³  ìˆì—ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 98] ---\n",
      "  **ENG**: So she called softly after it,\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ëŠ” ë¶€ë“œëŸ¬ìš´ ëª©ì†Œë¦¬ë¡œ\n",
      "\n",
      "--- [ìŒ 99] ---\n",
      "  **ENG**: â€œMouse dear!\n",
      "  **KOR**: â€œìƒì¥ì•¼!\n",
      "\n",
      "--- [ìŒ 100] ---\n",
      "  **ENG**: Do come back again, and we wonâ€™t talk about cats or dogs either, if you donâ€™t like them!â€ When the Mouse heard this, it turned round and swam slowly back to her: its face was quite pale\n",
      "  **KOR**: ëŒì•„ì™€. ì‹«ì–´í•˜ë©´ ê³ ì–‘ì´ë‚˜ ê°œ ì–˜ê¸´ ì•ˆí• ê»˜.â€ í•˜ê³  ë§í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 101] ---\n",
      "  **ENG**: (with passion, Alice thought),\n",
      "  **KOR**: (ì•¨ë¦¬ìŠ¤ëŠ” í™”ë‚œ ê²ƒ ê°™ì•„ ë³´ì¸ë‹¤ê³  ìƒê°í–ˆë‹¤.)\n",
      "\n",
      "--- [ìŒ 102] ---\n",
      "  **ENG**: and it said in a low trembling voice,\n",
      "  **KOR**: ìƒì¥ëŠ” ë–¨ë¦¬ëŠ” ëª©ì†Œë¦¬ë¡œ ë§í–ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 103] ---\n",
      "  **ENG**: â€œLet us get to the shore, and then Iâ€™ll tell you my history, and youâ€™ll understand why it is I hate cats and dogs.â€ It was high time to go, for the pool was getting quite crowded with the birds and animals that had fallen into it: there were a Duck and a Dodo, a Lory and an Eaglet, and several other curious creatures.\n",
      "  **KOR**: â€œì¼ë‹¨ ì›…ë©ì´ë¥¼ ë²—ì–´ë‚˜ì. ê·¸ëŸ¼ ë‚´ ì´ì•¼ê¸°ë¥¼ í•´ ì¤„ê»˜. ê·¸ëŸ¬ë©´ ë„ˆë„ ë‚´ê°€ ì™œ ê³ ì–‘ì´ë‘ ê°œë¥¼ ì‹«ì–´í•˜ëŠ” ì§€ ì•Œê²Œ ë êº¼ì•¼.â€ í•œ ì°¸ì„ ê°€ë‹¤ë³´ë‹ˆ, ì›…ë©ì´ì—” ë‹¤ë¥¸ ë™ë¬¼ê³¼ ìƒˆë“¤ë„ ë¹ ì ¸ ìˆì—ˆë‹¤.\n",
      "\n",
      "--- [ìŒ 104] ---\n",
      "  **ENG**: Alice led the way, and the whole party swam to the shore.\n",
      "  **KOR**: ì•¨ë¦¬ìŠ¤ëŠ” ì•ì¥ì„œì„œ ì´ ë™ë¬¼ë“¤ê³¼ í—¤ì—„ì³ ì›…ë©ì´ë¥¼ ë¹ ì ¸ ë‚˜ì™”ë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- 0. ì„¤ì • ---\n",
    "FILE_NAME = 'day1_dp_aligned_data.npz'\n",
    "NUM_SAMPLES_TO_SHOW = 5 # í™•ì¸í•  ë¬¸ì¥ ìŒì˜ ê°œìˆ˜\n",
    "\n",
    "try:\n",
    "    # Day 1 ê²°ê³¼ íŒŒì¼ ë¡œë“œ\n",
    "    day1_data = np.load(FILE_NAME, allow_pickle=True)\n",
    "    \n",
    "    print(f\"--- Day 1 ë°ì´í„° '{FILE_NAME}' ë‚´ìš© í™•ì¸ ---\")\n",
    "    \n",
    "    # 1. íŒŒì¼ì— ì €ì¥ëœ ë³€ìˆ˜(í‚¤) ëª©ë¡ í™•ì¸\n",
    "    print(\"ì €ì¥ëœ ë³€ìˆ˜ ì´ë¦„:\", day1_data.files)\n",
    "\n",
    "    # 2. ì„ë² ë”© í¬ê¸° í™•ì¸\n",
    "    eng_embs_shape = day1_data['eng_embs'].shape\n",
    "    print(f\"ì „ì²´ ì •ë ¬ ìŒ ê°œìˆ˜ (N): {eng_embs_shape[0]}\")\n",
    "    print(f\"ì„ë² ë”© ì°¨ì› (D): {eng_embs_shape[1]}\")\n",
    "    \n",
    "    # 3. ì •ë ¬ëœ ë¬¸ì¥ ìŒ ë¡œë“œ\n",
    "    eng_sents = day1_data['eng_sents']\n",
    "    kor_sents = day1_data['kor_sents']\n",
    "    \n",
    "    # 4. ì •ë ¬ëœ ë¬¸ì¥ ìŒ ì¶œë ¥ (ë§¤í•‘ í™•ì¸)\n",
    "    print(f\"\\nâœ… ì •ë ¬ëœ ë¬¸ì¥ ìŒ {NUM_SAMPLES_TO_SHOW}ê°œ í™•ì¸ (ë§¤í•‘ ê²°ê³¼):\")\n",
    "    \n",
    "    for i in range(len(eng_sents)):\n",
    "        print(f\"\\n--- [ìŒ {i+1}] ---\")\n",
    "        print(f\"  **ENG**: {eng_sents[i]}\")\n",
    "        print(f\"  **KOR**: {kor_sents[i]}\")\n",
    "        \n",
    "    # 5. ë©”ëª¨ë¦¬ í•´ì œ\n",
    "    day1_data.close()\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"ì˜¤ë¥˜: '{FILE_NAME}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Day 1 ì½”ë“œë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ íŒŒì¼ì„ ìƒì„±í•˜ì‹­ì‹œì˜¤.\")\n",
    "except KeyError as e:\n",
    "    print(f\"ì˜¤ë¥˜: í•„ìš”í•œ ë³€ìˆ˜({e})ê°€ íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤. Day 1 ì½”ë“œê°€ ì •ìƒì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì‹­ì‹œì˜¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e3adcb",
   "metadata": {},
   "source": [
    "# DAY 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4764b8d",
   "metadata": {},
   "source": [
    "## Normal MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a15e9677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Day 2: ëª¨ë¸ í•™ìŠµ ë° ì´ˆê¸° ë¶„ì„ ì‹œì‘ ---\n",
      "\n",
      "--- Day 2 ì˜¤í›„: Projection Head í•™ìŠµ ì‹œì‘ (20 Epoch) ---\n",
      "  Epoch 5/20 Loss: 4.2605\n",
      "  Epoch 10/20 Loss: 3.4906\n",
      "  Epoch 15/20 Loss: 2.7662\n",
      "  Epoch 20/20 Loss: 2.3054\n",
      "âœ… Projection Head í•™ìŠµ ì™„ë£Œ.\n",
      "\n",
      "--- Day 2 ì €ë…: ì •ë ¬ ì„±ëŠ¥ ì •ëŸ‰ í‰ê°€ ---\n",
      "ë§¤í•‘ ì „ (Baseline) í‰ê·  Cosine Sim: 0.0087\n",
      "ë§¤í•‘ í›„ (Aligned) í‰ê·  Cosine Sim: 0.1608\n",
      "Rank-1 Accuracy: 26.67%\n",
      "--- Day 2 ì‘ì—… ì™„ë£Œ. 'day2_model_and_results.npz' ë° 'projection_head.pth' ì €ì¥ë¨ ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 0. ì„¤ì • ë° íŒŒì¼ ê²½ë¡œ ---\n",
    "INPUT_FILE = \"day1_dp_aligned_data.npz\"\n",
    "OUTPUT_FILE = \"day2_model_and_results.npz\"\n",
    "EMBEDDING_DIM = 768\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "TEMP = 0.07 # InfoNCE Loss Temperature\n",
    "\n",
    "# --- 1. ëª¨ë¸ ì •ì˜ (Day 2 ì˜¤ì „) ---\n",
    "\n",
    "class MLPProjectionHead(nn.Module):\n",
    "    \"\"\"ì˜ì–´ ì„ë² ë”©ì„ í•œêµ­ì–´ ì„ë² ë”© ê³µê°„ìœ¼ë¡œ íˆ¬ì˜í•˜ëŠ” MLP\"\"\"\n",
    "    def __init__(self, input_dim=EMBEDDING_DIM, output_dim=EMBEDDING_DIM):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(input_dim, 2*output_dim), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2*output_dim, output_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.proj(x)\n",
    "\n",
    "class InfoNCELoss(nn.Module):\n",
    "    \"\"\"InfoNCE Contrastive Loss\"\"\"\n",
    "    def __init__(self, temperature=TEMP):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, eng_emb, kor_emb):\n",
    "        eng_emb = F.normalize(eng_emb, p=2, dim=1)\n",
    "        kor_emb = F.normalize(kor_emb, p=2, dim=1)\n",
    "        score_matrix = torch.matmul(eng_emb, kor_emb.T) / self.temperature\n",
    "        batch_size = score_matrix.size(0)\n",
    "        labels = torch.arange(batch_size).to(score_matrix.device) \n",
    "        \n",
    "        loss_eng_to_kor = self.cross_entropy_loss(score_matrix, labels)\n",
    "        loss_kor_to_eng = self.cross_entropy_loss(score_matrix.T, labels)\n",
    "        \n",
    "        return (loss_eng_to_kor + loss_kor_to_eng) / 2\n",
    "\n",
    "# --- 2. í•™ìŠµ ë£¨í”„ (Day 2 ì˜¤í›„) ---\n",
    "\n",
    "def train_projection_head(projection_head, eng_embs, kor_embs, num_epochs=20, lr=1e-4):\n",
    "    \"\"\"MLP Projection Head í•™ìŠµ\"\"\"\n",
    "    projection_head.train()\n",
    "    optimizer = torch.optim.Adam(projection_head.parameters(), lr=lr)\n",
    "    loss_fn = InfoNCELoss(temperature=TEMP)\n",
    "    \n",
    "    eng_tensor = torch.tensor(eng_embs, dtype=torch.float32).to(DEVICE)\n",
    "    kor_tensor = torch.tensor(kor_embs, dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "    print(f\"\\n--- Day 2 ì˜¤í›„: Projection Head í•™ìŠµ ì‹œì‘ ({num_epochs} Epoch) ---\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        projected_eng_emb = projection_head(eng_tensor)\n",
    "        loss = loss_fn(projected_eng_emb, kor_tensor)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "             print(f\"  Epoch {epoch+1}/{num_epochs} Loss: {loss.item():.4f}\")\n",
    "        \n",
    "    print(\"âœ… Projection Head í•™ìŠµ ì™„ë£Œ.\")\n",
    "    return projection_head\n",
    "\n",
    "# --- 3. í‰ê°€ (Day 2 ì €ë…) ---\n",
    "\n",
    "def evaluate_alignment(projection_head, test_eng_embs, test_kor_embs):\n",
    "    \"\"\"ë§¤í•‘ ì „/í›„ ì •ëŸ‰ í‰ê°€\"\"\"\n",
    "    \n",
    "    # 1. ë§¤í•‘ í›„ (Aligned) ì„ë² ë”© ê³„ì‚°\n",
    "    projection_head.eval()\n",
    "    with torch.no_grad():\n",
    "        eng_tensor = torch.tensor(test_eng_embs, dtype=torch.float32).to(DEVICE)\n",
    "        projected_eng_embs = projection_head(eng_tensor).cpu().numpy()\n",
    "\n",
    "    # 2. ìœ ì‚¬ë„ ê³„ì‚°\n",
    "    baseline_sim_matrix = cosine_similarity(test_eng_embs, test_kor_embs)\n",
    "    aligned_sim_matrix = cosine_similarity(projected_eng_embs, test_kor_embs)\n",
    "    \n",
    "    baseline_scores = np.diag(baseline_sim_matrix) \n",
    "    aligned_scores = np.diag(aligned_sim_matrix)\n",
    "    \n",
    "    print(\"\\n--- Day 2 ì €ë…: ì •ë ¬ ì„±ëŠ¥ ì •ëŸ‰ í‰ê°€ ---\")\n",
    "    print(f\"ë§¤í•‘ ì „ (Baseline) í‰ê·  Cosine Sim: {np.mean(baseline_scores):.4f}\")\n",
    "    print(f\"ë§¤í•‘ í›„ (Aligned) í‰ê·  Cosine Sim: {np.mean(aligned_scores):.4f}\")\n",
    "    \n",
    "    rank_1_acc = np.mean(np.argmax(aligned_sim_matrix, axis=1) == np.arange(len(aligned_scores)))\n",
    "    print(f\"Rank-1 Accuracy: {rank_1_acc:.2%}\")\n",
    "\n",
    "    return projected_eng_embs, baseline_scores, aligned_scores\n",
    "\n",
    "# --- 4. ë©”ì¸ ì‹¤í–‰ ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"--- Day 2: ëª¨ë¸ í•™ìŠµ ë° ì´ˆê¸° ë¶„ì„ ì‹œì‘ ---\")\n",
    "    \n",
    "    # 1. Day 1 ë°ì´í„° ë¡œë“œ\n",
    "    try:\n",
    "        data = np.load(INPUT_FILE, allow_pickle=True)\n",
    "        final_eng_embs = data['eng_embs']\n",
    "        final_kor_embs = data['kor_embs']\n",
    "        eng_sents = data['eng_sents']\n",
    "        kor_sents = data['kor_sents']\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ì˜¤ë¥˜: {INPUT_FILE} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Day 1 ì‘ì—…ì„ ë¨¼ì € ì‹¤í–‰í•˜ì‹­ì‹œì˜¤.\")\n",
    "        exit()\n",
    "\n",
    "    # 2. ë°ì´í„° ë¶„í•  (í•™ìŠµ/í‰ê°€)\n",
    "    TOTAL_SIZE = len(final_eng_embs)\n",
    "    TRAIN_SIZE = int(TOTAL_SIZE * 0.8)\n",
    "    \n",
    "    train_eng_embs = final_eng_embs[:TRAIN_SIZE]\n",
    "    train_kor_embs = final_kor_embs[:TRAIN_SIZE]\n",
    "    test_eng_embs = final_eng_embs[TRAIN_SIZE:]\n",
    "    test_kor_embs = final_kor_embs[TRAIN_SIZE:]\n",
    "    \n",
    "    # 3. Projection Head í•™ìŠµ (ì˜¤í›„)\n",
    "    projection_head = MLPProjectionHead().to(DEVICE)\n",
    "    trained_projection_head = train_projection_head(projection_head, train_eng_embs, train_kor_embs)\n",
    "    \n",
    "    # 4. ì„±ëŠ¥ í‰ê°€ ë° ê²°ê³¼ ì¶”ì¶œ (ì €ë…)\n",
    "    projected_eng_embs_test, final_baseline_scores, final_aligned_scores = evaluate_alignment(\n",
    "        trained_projection_head, test_eng_embs, test_kor_embs\n",
    "    )\n",
    "    \n",
    "    # 5. ê²°ê³¼ ì €ì¥ (Day 3ì—ì„œ ì‚¬ìš©)\n",
    "    np.savez(OUTPUT_FILE, \n",
    "             test_eng_embs=test_eng_embs, \n",
    "             test_kor_embs=test_kor_embs, \n",
    "             projected_eng_embs=projected_eng_embs_test,\n",
    "             baseline_scores=final_baseline_scores, \n",
    "             aligned_scores=final_aligned_scores,\n",
    "             test_eng_sents=eng_sents[TRAIN_SIZE:],\n",
    "             test_kor_sents=kor_sents[TRAIN_SIZE:]\n",
    "    )\n",
    "    torch.save(trained_projection_head.state_dict(), \"projection_head.pth\")\n",
    "    \n",
    "    print(f\"--- Day 2 ì‘ì—… ì™„ë£Œ. '{OUTPUT_FILE}' ë° 'projection_head.pth' ì €ì¥ë¨ ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c475e7bf",
   "metadata": {},
   "source": [
    "## New MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "12dbd04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Day 2 ì‹œì‘ ---\n",
      "\n",
      "--- Day 2 ì˜¤í›„: Projection Head í•™ìŠµ ì‹œì‘ ---\n",
      "Epoch 4/20  Loss: 3.0990\n",
      "Epoch 8/20  Loss: 2.0876\n",
      "Epoch 12/20  Loss: 1.4277\n",
      "Epoch 16/20  Loss: 0.9735\n",
      "Epoch 20/20  Loss: 0.7055\n",
      "âœ… í•™ìŠµ ì™„ë£Œ.\n",
      "\n",
      "--- Day 2 ì €ë…: ì •ë ¬ ì„±ëŠ¥ ë¹„êµ ---\n",
      "Baseline cosine mean: 0.1029\n",
      "Aligned cosine mean:  0.1102\n",
      "Rank-1 Accuracy: 36.67%\n",
      "MRR: 0.5245\n",
      "Top-5 Accuracy: 73.33%\n",
      "\n",
      "--- Day 2 ì™„ë£Œ: 'day2_model_and_results.npz', 'projection_head.pth' ì €ì¥ë¨ ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ============================\n",
    "# 0. ì„¤ì •\n",
    "# ============================\n",
    "INPUT_FILE = \"day1_dp_aligned_data.npz\"\n",
    "OUTPUT_FILE = \"day2_model_and_results.npz\"\n",
    "EMBEDDING_DIM = 1536\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "TEMP = 0.07\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# ============================\n",
    "# 1. Projection Head ì •ì˜\n",
    "# ============================\n",
    "\n",
    "class MLPProjectionHead(nn.Module):\n",
    "    def __init__(self, input_dim=1536, output_dim=1536):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Linear(input_dim, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)\n",
    "        return F.normalize(x, p=2, dim=1)  # InfoNCEì— ì¤‘ìš”\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 2. InfoNCE Loss\n",
    "# ============================\n",
    "\n",
    "class InfoNCELoss(nn.Module):\n",
    "    def __init__(self, temperature=TEMP):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, eng_emb, kor_emb):\n",
    "        # L2 normalize\n",
    "        eng_emb = F.normalize(eng_emb, p=2, dim=1)\n",
    "        kor_emb = F.normalize(kor_emb, p=2, dim=1)\n",
    "\n",
    "        logits = torch.matmul(eng_emb, kor_emb.T) / self.temperature\n",
    "        labels = torch.arange(len(logits)).to(logits.device)\n",
    "\n",
    "        loss_i = self.cross_entropy(logits, labels)       # engâ†’kor\n",
    "        loss_j = self.cross_entropy(logits.T, labels)     # korâ†’eng\n",
    "\n",
    "        return (loss_i + loss_j) / 2\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 3. Training Loop (Batch ê¸°ë°˜)\n",
    "# ============================\n",
    "\n",
    "def train_projection_head(model, eng_embs, kor_embs, num_epochs=20, lr=1e-4):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    loss_fn = InfoNCELoss()\n",
    "\n",
    "    eng_tensor = torch.tensor(eng_embs, dtype=torch.float32)\n",
    "    kor_tensor = torch.tensor(kor_embs, dtype=torch.float32)\n",
    "\n",
    "    dataset = TensorDataset(eng_tensor, kor_tensor)\n",
    "    loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    print(\"\\n--- Day 2 ì˜¤í›„: Projection Head í•™ìŠµ ì‹œì‘ ---\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for eng_batch, kor_batch in loader:\n",
    "            eng_batch = eng_batch.to(DEVICE)\n",
    "            kor_batch = kor_batch.to(DEVICE)\n",
    "\n",
    "            projected_eng = model(eng_batch)\n",
    "            loss = loss_fn(projected_eng, kor_batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        if (epoch + 1) % 4 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}  Loss: {epoch_loss/len(loader):.4f}\")\n",
    "\n",
    "    print(\"âœ… í•™ìŠµ ì™„ë£Œ.\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 4. í‰ê°€ í•¨ìˆ˜\n",
    "# ============================\n",
    "\n",
    "def mean_reciprocal_rank(sim_matrix):\n",
    "    ranks = []\n",
    "    for i in range(len(sim_matrix)):\n",
    "        sorted_idx = np.argsort(-sim_matrix[i])\n",
    "        rank = np.where(sorted_idx == i)[0][0] + 1\n",
    "        ranks.append(1 / rank)\n",
    "    return np.mean(ranks)\n",
    "\n",
    "def accuracy_at_k(sim_matrix, k=5):\n",
    "    correct = 0\n",
    "    for i in range(len(sim_matrix)):\n",
    "        top_k = np.argsort(-sim_matrix[i])[:k]\n",
    "        if i in top_k:\n",
    "            correct += 1\n",
    "    return correct / len(sim_matrix)\n",
    "\n",
    "\n",
    "def evaluate_alignment(model, test_eng_embs, test_kor_embs):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        eng_tensor = torch.tensor(test_eng_embs, dtype=torch.float32).to(DEVICE)\n",
    "        projected_eng = model(eng_tensor).cpu().numpy()\n",
    "\n",
    "    # similarity\n",
    "    baseline_sim = cosine_similarity(test_eng_embs, test_kor_embs)\n",
    "    aligned_sim = cosine_similarity(projected_eng, test_kor_embs)\n",
    "\n",
    "    baseline_diag = np.diag(baseline_sim)\n",
    "    aligned_diag = np.diag(aligned_sim)\n",
    "\n",
    "    print(\"\\n--- Day 2 ì €ë…: ì •ë ¬ ì„±ëŠ¥ ë¹„êµ ---\")\n",
    "    print(f\"Baseline cosine mean: {baseline_diag.mean():.4f}\")\n",
    "    print(f\"Aligned cosine mean:  {aligned_diag.mean():.4f}\")\n",
    "\n",
    "    rank1 = np.mean(np.argmax(aligned_sim, axis=1) == np.arange(len(aligned_diag)))\n",
    "    mrr = mean_reciprocal_rank(aligned_sim)\n",
    "    acc5 = accuracy_at_k(aligned_sim, k=5)\n",
    "\n",
    "    print(f\"Rank-1 Accuracy: {rank1:.2%}\")\n",
    "    print(f\"MRR: {mrr:.4f}\")\n",
    "    print(f\"Top-5 Accuracy: {acc5:.2%}\")\n",
    "\n",
    "    return projected_eng, baseline_diag, aligned_diag, aligned_sim\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 5. Main ì‹¤í–‰\n",
    "# ============================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"--- Day 2 ì‹œì‘ ---\")\n",
    "\n",
    "    try:\n",
    "        data = np.load(INPUT_FILE, allow_pickle=True)\n",
    "        final_eng_embs = data[\"eng_embs\"]\n",
    "        final_kor_embs = data[\"kor_embs\"]\n",
    "        eng_sents = data[\"eng_sents\"]\n",
    "        kor_sents = data[\"kor_sents\"]\n",
    "    except:\n",
    "        print(\"âŒ Day 1 output íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        exit()\n",
    "\n",
    "    TOTAL = len(final_eng_embs)\n",
    "    TRAIN = int(TOTAL * 0.8)\n",
    "\n",
    "    train_eng = final_eng_embs[:TRAIN]\n",
    "    train_kor = final_kor_embs[:TRAIN]\n",
    "    test_eng = final_eng_embs[TRAIN:]\n",
    "    test_kor = final_kor_embs[TRAIN:]\n",
    "\n",
    "    # ëª¨ë¸ ìƒì„±\n",
    "    model = MLPProjectionHead().to(DEVICE)\n",
    "\n",
    "    # í•™ìŠµ\n",
    "    model = train_projection_head(model, train_eng, train_kor)\n",
    "\n",
    "    # í‰ê°€\n",
    "    projected_test_embs, baseline_scores, aligned_scores, aligned_sim_matrix = evaluate_alignment(\n",
    "        model, test_eng, test_kor\n",
    "    )\n",
    "\n",
    "    # ì €ì¥\n",
    "    np.savez(\n",
    "        OUTPUT_FILE,\n",
    "        test_eng_embs=test_eng,\n",
    "        test_kor_embs=test_kor,\n",
    "        projected_eng_embs=projected_test_embs,\n",
    "        baseline_scores=baseline_scores,\n",
    "        aligned_scores=aligned_scores,\n",
    "        aligned_sim_matrix=aligned_sim_matrix,\n",
    "        test_eng_sents=eng_sents[TRAIN:],\n",
    "        test_kor_sents=kor_sents[TRAIN:],\n",
    "    )\n",
    "    torch.save(model.state_dict(), \"projection_head.pth\")\n",
    "\n",
    "    print(f\"\\n--- Day 2 ì™„ë£Œ: '{OUTPUT_FILE}', 'projection_head.pth' ì €ì¥ë¨ ---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80a9896",
   "metadata": {},
   "source": [
    "# DAY 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "19c3b27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:350: RuntimeWarning: divide by zero encountered in matmul\n",
      "  Q, _ = normalizer(A @ Q)\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:350: RuntimeWarning: overflow encountered in matmul\n",
      "  Q, _ = normalizer(A @ Q)\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:350: RuntimeWarning: invalid value encountered in matmul\n",
      "  Q, _ = normalizer(A @ Q)\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:351: RuntimeWarning: divide by zero encountered in matmul\n",
      "  Q, _ = normalizer(A.T @ Q)\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:351: RuntimeWarning: overflow encountered in matmul\n",
      "  Q, _ = normalizer(A.T @ Q)\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:351: RuntimeWarning: invalid value encountered in matmul\n",
      "  Q, _ = normalizer(A.T @ Q)\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:355: RuntimeWarning: divide by zero encountered in matmul\n",
      "  Q, _ = qr_normalizer(A @ Q)\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:355: RuntimeWarning: overflow encountered in matmul\n",
      "  Q, _ = qr_normalizer(A @ Q)\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:355: RuntimeWarning: invalid value encountered in matmul\n",
      "  Q, _ = qr_normalizer(A @ Q)\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:577: RuntimeWarning: divide by zero encountered in matmul\n",
      "  B = Q.T @ M\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:577: RuntimeWarning: overflow encountered in matmul\n",
      "  B = Q.T @ M\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:577: RuntimeWarning: invalid value encountered in matmul\n",
      "  B = Q.T @ M\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:590: RuntimeWarning: divide by zero encountered in matmul\n",
      "  U = Q @ Uhat\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:590: RuntimeWarning: overflow encountered in matmul\n",
      "  U = Q @ Uhat\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/utils/extmath.py:590: RuntimeWarning: invalid value encountered in matmul\n",
      "  U = Q @ Uhat\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: divide by zero encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: overflow encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: invalid value encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: divide by zero encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: overflow encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: invalid value encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: divide by zero encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: overflow encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/sklearn/decomposition/_base.py:148: RuntimeWarning: invalid value encountered in matmul\n",
      "  X_transformed = X @ self.components_.T\n",
      "2025-11-20 16:33:12,353 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,354 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,355 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,355 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,356 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,356 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,356 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,357 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,357 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,357 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,362 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,362 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,364 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,365 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "/var/folders/4m/h90ddv7j3fddt74yl61sg_5c0000gn/T/ipykernel_36226/1231840115.py:84: UserWarning: Glyph 47588 (\\N{HANGUL SYLLABLE MAE}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "/var/folders/4m/h90ddv7j3fddt74yl61sg_5c0000gn/T/ipykernel_36226/1231840115.py:84: UserWarning: Glyph 54609 (\\N{HANGUL SYLLABLE PING}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "/var/folders/4m/h90ddv7j3fddt74yl61sg_5c0000gn/T/ipykernel_36226/1231840115.py:84: UserWarning: Glyph 51204 (\\N{HANGUL SYLLABLE JEON}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "/var/folders/4m/h90ddv7j3fddt74yl61sg_5c0000gn/T/ipykernel_36226/1231840115.py:84: UserWarning: Glyph 46021 (\\N{HANGUL SYLLABLE DOG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "/var/folders/4m/h90ddv7j3fddt74yl61sg_5c0000gn/T/ipykernel_36226/1231840115.py:84: UserWarning: Glyph 47549 (\\N{HANGUL SYLLABLE RIB}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "/var/folders/4m/h90ddv7j3fddt74yl61sg_5c0000gn/T/ipykernel_36226/1231840115.py:84: UserWarning: Glyph 51201 (\\N{HANGUL SYLLABLE JEOG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "/var/folders/4m/h90ddv7j3fddt74yl61sg_5c0000gn/T/ipykernel_36226/1231840115.py:84: UserWarning: Glyph 51076 (\\N{HANGUL SYLLABLE IM}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "/var/folders/4m/h90ddv7j3fddt74yl61sg_5c0000gn/T/ipykernel_36226/1231840115.py:84: UserWarning: Glyph 48288 (\\N{HANGUL SYLLABLE BE}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "/var/folders/4m/h90ddv7j3fddt74yl61sg_5c0000gn/T/ipykernel_36226/1231840115.py:84: UserWarning: Glyph 46377 (\\N{HANGUL SYLLABLE DING}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "/var/folders/4m/h90ddv7j3fddt74yl61sg_5c0000gn/T/ipykernel_36226/1231840115.py:84: UserWarning: Glyph 44277 (\\N{HANGUL SYLLABLE GONG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "/var/folders/4m/h90ddv7j3fddt74yl61sg_5c0000gn/T/ipykernel_36226/1231840115.py:84: UserWarning: Glyph 44036 (\\N{HANGUL SYLLABLE GAN}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "2025-11-20 16:33:12,368 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,369 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,373 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,374 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,374 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,374 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,375 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,375 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,380 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "/var/folders/4m/h90ddv7j3fddt74yl61sg_5c0000gn/T/ipykernel_36226/1231840115.py:84: UserWarning: Glyph 54980 (\\N{HANGUL SYLLABLE HU}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "/var/folders/4m/h90ddv7j3fddt74yl61sg_5c0000gn/T/ipykernel_36226/1231840115.py:84: UserWarning: Glyph 47484 (\\N{HANGUL SYLLABLE REUL}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "/var/folders/4m/h90ddv7j3fddt74yl61sg_5c0000gn/T/ipykernel_36226/1231840115.py:84: UserWarning: Glyph 53685 (\\N{HANGUL SYLLABLE TONG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "/var/folders/4m/h90ddv7j3fddt74yl61sg_5c0000gn/T/ipykernel_36226/1231840115.py:84: UserWarning: Glyph 54620 (\\N{HANGUL SYLLABLE HAN}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "/var/folders/4m/h90ddv7j3fddt74yl61sg_5c0000gn/T/ipykernel_36226/1231840115.py:84: UserWarning: Glyph 51221 (\\N{HANGUL SYLLABLE JEONG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "/var/folders/4m/h90ddv7j3fddt74yl61sg_5c0000gn/T/ipykernel_36226/1231840115.py:84: UserWarning: Glyph 47148 (\\N{HANGUL SYLLABLE RYEOL}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "2025-11-20 16:33:12,384 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,385 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,386 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "/var/folders/4m/h90ddv7j3fddt74yl61sg_5c0000gn/T/ipykernel_36226/1231840115.py:84: UserWarning: Glyph 49884 (\\N{HANGUL SYLLABLE SI}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "/var/folders/4m/h90ddv7j3fddt74yl61sg_5c0000gn/T/ipykernel_36226/1231840115.py:84: UserWarning: Glyph 44033 (\\N{HANGUL SYLLABLE GAG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "/var/folders/4m/h90ddv7j3fddt74yl61sg_5c0000gn/T/ipykernel_36226/1231840115.py:84: UserWarning: Glyph 54868 (\\N{HANGUL SYLLABLE HWA}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
      "2025-11-20 16:33:12,423 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,424 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,424 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,425 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,425 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,425 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,426 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,426 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 47588 (\\N{HANGUL SYLLABLE MAE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 54609 (\\N{HANGUL SYLLABLE PING}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 51204 (\\N{HANGUL SYLLABLE JEON}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 46021 (\\N{HANGUL SYLLABLE DOG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 47549 (\\N{HANGUL SYLLABLE RIB}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 51201 (\\N{HANGUL SYLLABLE JEOG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 51076 (\\N{HANGUL SYLLABLE IM}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 48288 (\\N{HANGUL SYLLABLE BE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 46377 (\\N{HANGUL SYLLABLE DING}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 44277 (\\N{HANGUL SYLLABLE GONG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 44036 (\\N{HANGUL SYLLABLE GAN}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "2025-11-20 16:33:12,430 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,431 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,431 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,432 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,432 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,432 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,433 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,433 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,433 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,434 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,434 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,435 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,435 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,436 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,436 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,438 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,438 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,439 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,439 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,440 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,441 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,442 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,442 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,445 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,447 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,449 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 54980 (\\N{HANGUL SYLLABLE HU}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 47484 (\\N{HANGUL SYLLABLE REUL}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 53685 (\\N{HANGUL SYLLABLE TONG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 54620 (\\N{HANGUL SYLLABLE HAN}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 51221 (\\N{HANGUL SYLLABLE JEONG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 47148 (\\N{HANGUL SYLLABLE RYEOL}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "2025-11-20 16:33:12,452 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,453 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,453 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,454 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,454 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,454 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,455 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,455 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,456 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,456 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,457 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,457 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,459 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,459 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,460 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,460 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,460 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,461 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,463 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,464 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,466 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,468 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "2025-11-20 16:33:12,468 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 49884 (\\N{HANGUL SYLLABLE SI}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 44033 (\\N{HANGUL SYLLABLE GAG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/Users/kyungmin/Desktop/Projects/simma/.venv/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 54868 (\\N{HANGUL SYLLABLE HWA}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "2025-11-20 16:33:12,470 - WARNING - findfont: Font family 'Malgun Gothic' not found.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Day 3: ë¶„ì„ ë° ì‹œê°í™” ì‹œì‘ ---\n",
      "\n",
      "--- Day 3 ì˜¤ì „: í•µì‹¬ ì‚¬ë¡€(Case Study) ë¶„ì„ ---\n",
      "ğŸ¥‡ ìœ ì‚¬ë„ ê°œì„  ìƒìœ„ ì‚¬ë¡€ (Projection Headì˜ ì„±ê³µ):\n",
      "[27.38% ê°œì„ ]\n",
      "  ENG: cried Alice in a sorrowful tone,\n",
      "  KOR: ì•¨ë¦¬ìŠ¤ëŠ” ë¯¸ì•ˆí•œ ëª©ì†Œë¦¬ë¡œ ë§í–ˆë‹¤.\n",
      "  Sim. Before: -0.0183 -> After: 0.2555\n",
      "\n",
      "[26.23% ê°œì„ ]\n",
      "  ENG: cried the Mouse, who was trembling down to the end of his tail.\n",
      "  KOR: í•˜ê³  ìƒì¥ê°€ ëŠ˜ì–´ëœ¨ë¦° ê¼¬ë¦¬ ëì„ ë–¨ë©´ì„œ í° ì†Œë¦¬ë¡œ ë§í–ˆë‹¤.\n",
      "  Sim. Before: -0.0341 -> After: 0.2283\n",
      "\n",
      "[25.93% ê°œì„ ]\n",
      "  ENG: â€œMouse dear!\n",
      "  KOR: â€œìƒì¥ì•¼!\n",
      "  Sim. Before: 0.0096 -> After: 0.2689\n",
      "\n",
      "[25.71% ê°œì„ ]\n",
      "  ENG: â€œAs if _I_ would talk on such a subject!\n",
      "  KOR: â€œê·¸ëŸ° ì–˜ê¸°ëŠ” ê´€ë‘ì!\n",
      "  Sim. Before: -0.0289 -> After: 0.2282\n",
      "\n",
      "[22.82% ê°œì„ ]\n",
      "  ENG: Donâ€™t let me hear the name again!â€\n",
      "  KOR: ë‹¤ì‹  ê·¸ ì–˜ê¸°í•˜ì§€ ë§ˆ!â€\n",
      "  Sim. Before: -0.0114 -> After: 0.2168\n",
      "\n",
      "âŒ ì”ì¡´ ì˜¤ë¥˜ í•˜ìœ„ ì‚¬ë¡€ (ì—°êµ¬ì˜ í•œê³„ ëª…ì‹œ):\n",
      "[-0.0380 ìµœì¢… ìœ ì‚¬ë„]\n",
      "  ENG: â€œdonâ€™t be angry about it.\n",
      "  KOR: â€œí™”ë‚´ì§€ ë§ˆ.\n",
      "  *ë¶„ì„: (ë©´ì ‘ ëŒ€ë¹„) ì´ ìŒì´ ì •ë ¬ì— ì‹¤íŒ¨í•œ ì´ìœ  (ì •ë ¬ ì˜¤ë¥˜, ë‰˜ì•™ìŠ¤ ì°¨ì´ ë“±)ë¥¼ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "\n",
      "[0.0587 ìµœì¢… ìœ ì‚¬ë„]\n",
      "  ENG: A little bright-eyed terrier, you know, with oh, such long curly brown hair!\n",
      "  KOR: ì•„, ê³±ìŠ¬ê±°ë¦¬ëŠ” ê°ˆìƒ‰ í„¸!\n",
      "  *ë¶„ì„: (ë©´ì ‘ ëŒ€ë¹„) ì´ ìŒì´ ì •ë ¬ì— ì‹¤íŒ¨í•œ ì´ìœ  (ì •ë ¬ ì˜¤ë¥˜, ë‰˜ì•™ìŠ¤ ì°¨ì´ ë“±)ë¥¼ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "\n",
      "[0.0927 ìµœì¢… ìœ ì‚¬ë„]\n",
      "  ENG: He says it kills all the rats andâ€”oh dear!â€\n",
      "  KOR: ë†ë¶€ ì•„ì €ì”¨ëŠ” ê·¸ ê°œê°€ ì¥ë„ ì˜ ì¡ê³  ë˜ -- ì•„ì´ì¿ !â€\n",
      "  *ë¶„ì„: (ë©´ì ‘ ëŒ€ë¹„) ì´ ìŒì´ ì •ë ¬ì— ì‹¤íŒ¨í•œ ì´ìœ  (ì •ë ¬ ì˜¤ë¥˜, ë‰˜ì•™ìŠ¤ ì°¨ì´ ë“±)ë¥¼ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "\n",
      "[0.0978 ìµœì¢… ìœ ì‚¬ë„]\n",
      "  ENG: Our family always _hated_ cats: nasty, low, vulgar things!\n",
      "  KOR: ìš°ë¦¬ ê°€ë¬¸ì€ ê³ ì–‘ì´ ê°™ì€ ë”ëŸ½ê³  ì²œí•œ ë¬´ì‹í•œ ê²ƒë“¤ì€ ì‹«ì–´í•´!\n",
      "  *ë¶„ì„: (ë©´ì ‘ ëŒ€ë¹„) ì´ ìŒì´ ì •ë ¬ì— ì‹¤íŒ¨í•œ ì´ìœ  (ì •ë ¬ ì˜¤ë¥˜, ë‰˜ì•™ìŠ¤ ì°¨ì´ ë“±)ë¥¼ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "\n",
      "[0.0989 ìµœì¢… ìœ ì‚¬ë„]\n",
      "  ENG: â€œThere is such a nice little dog near our house I should like to show you!\n",
      "  KOR: â€œì§„ì§œ ë©‹ì§„ ê°œê°€ ìš°ë¦¬ ì˜† ì§‘ì— ì‚¬ëŠ”ë°.\n",
      "  *ë¶„ì„: (ë©´ì ‘ ëŒ€ë¹„) ì´ ìŒì´ ì •ë ¬ì— ì‹¤íŒ¨í•œ ì´ìœ  (ì •ë ¬ ì˜¤ë¥˜, ë‰˜ì•™ìŠ¤ ì°¨ì´ ë“±)ë¥¼ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Day 3 ì‘ì—… ì™„ë£Œ. ë¯¸ë‹ˆ í”„ë¡œì íŠ¸ ë³´ê³ ì„œ í†µí•© ì¤€ë¹„ ì™„ë£Œ ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "\n",
    "# --- 0. ì„¤ì • ë° íŒŒì¼ ê²½ë¡œ ---\n",
    "INPUT_FILE = \"day2_model_and_results.npz\"\n",
    "EMBEDDING_DIM = 768\n",
    "\n",
    "# --- 1. ì •ì„± ë¶„ì„ (Day 3 ì˜¤ì „) ---\n",
    "\n",
    "def perform_nuance_analysis(eng_sents, kor_sents, baseline_scores, aligned_scores, top_k=5):\n",
    "    \"\"\"\n",
    "    ë§¤í•‘ í›„ ê°€ì¥ ë§ì´ ê°œì„ ë˜ê±°ë‚˜ ì˜¤ë¥˜ê°€ í° ë¬¸ì¥ ìŒì„ ë¶„ì„\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({\n",
    "        'eng': eng_sents,\n",
    "        'kor': kor_sents,\n",
    "        'baseline_sim': baseline_scores,\n",
    "        'aligned_sim': aligned_scores,\n",
    "        'sim_diff': aligned_scores - baseline_scores\n",
    "    })\n",
    "    \n",
    "    print(\"\\n--- Day 3 ì˜¤ì „: í•µì‹¬ ì‚¬ë¡€(Case Study) ë¶„ì„ ---\")\n",
    "    \n",
    "    # 1. ìœ ì‚¬ë„ ê°œì„  ìƒìœ„ ì‚¬ë¡€ (Success Cases)\n",
    "    top_improved = df.sort_values(by='sim_diff', ascending=False).head(top_k)\n",
    "    print(\"ğŸ¥‡ ìœ ì‚¬ë„ ê°œì„  ìƒìœ„ ì‚¬ë¡€ (Projection Headì˜ ì„±ê³µ):\")\n",
    "    for i, row in top_improved.iterrows():\n",
    "        print(f\"[{row['sim_diff']*100:.2f}% ê°œì„ ]\")\n",
    "        print(f\"  ENG: {row['eng']}\")\n",
    "        print(f\"  KOR: {row['kor']}\")\n",
    "        print(f\"  Sim. Before: {row['baseline_sim']:.4f} -> After: {row['aligned_sim']:.4f}\\n\")\n",
    "\n",
    "    # 2. ì”ì¡´ ì˜¤ë¥˜ í•˜ìœ„ ì‚¬ë¡€ (Limitation Cases)\n",
    "    bottom_error = df.sort_values(by='aligned_sim', ascending=True).head(top_k)\n",
    "    print(\"âŒ ì”ì¡´ ì˜¤ë¥˜ í•˜ìœ„ ì‚¬ë¡€ (ì—°êµ¬ì˜ í•œê³„ ëª…ì‹œ):\")\n",
    "    for i, row in bottom_error.iterrows():\n",
    "        print(f\"[{row['aligned_sim']:.4f} ìµœì¢… ìœ ì‚¬ë„]\")\n",
    "        print(f\"  ENG: {row['eng']}\")\n",
    "        print(f\"  KOR: {row['kor']}\")\n",
    "        print(f\"  *ë¶„ì„: (ë©´ì ‘ ëŒ€ë¹„) ì´ ìŒì´ ì •ë ¬ì— ì‹¤íŒ¨í•œ ì´ìœ  (ì •ë ¬ ì˜¤ë¥˜, ë‰˜ì•™ìŠ¤ ì°¨ì´ ë“±)ë¥¼ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤.\\n\")\n",
    "\n",
    "# --- 2. ì‹œê°í™” (Day 3 ì˜¤í›„) ---\n",
    "\n",
    "def visualize_embeddings(eng_embs, kor_embs, projected_eng_embs):\n",
    "    \"\"\"\n",
    "    PCAë¥¼ ì‚¬ìš©í•˜ì—¬ ë§¤í•‘ ì „/í›„ ì„ë² ë”© ê³µê°„ ë³€í™” ì‹œê°í™”\n",
    "    \"\"\"\n",
    "    # í°íŠ¸ ì„¤ì • (Mac/Linux í™˜ê²½ì— ë§ê²Œ í°íŠ¸ëª… ë³€ê²½ í•„ìš”)\n",
    "    try:\n",
    "        plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    all_data = np.vstack([eng_embs, kor_embs, projected_eng_embs])\n",
    "    \n",
    "    # PCA í•™ìŠµ ë° íˆ¬ì˜\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(all_data)\n",
    "    \n",
    "    eng_pca = pca.transform(eng_embs)\n",
    "    kor_pca = pca.transform(kor_embs)\n",
    "    proj_eng_pca = pca.transform(projected_eng_embs)\n",
    "    \n",
    "    # ì‹œê°í™” \n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # A. ë§¤í•‘ ì „ (Baseline)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(eng_pca[:, 0], eng_pca[:, 1], alpha=0.6, label='English (BERT)')\n",
    "    plt.scatter(kor_pca[:, 0], kor_pca[:, 1], alpha=0.6, label='Korean (KoBERT Target)')\n",
    "    plt.title('ë§¤í•‘ ì „: ë…ë¦½ì  ì„ë² ë”© ê³µê°„ (Baseline)')\n",
    "    plt.legend()\n",
    "\n",
    "    # B. ë§¤í•‘ í›„ (Aligned)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(proj_eng_pca[:, 0], proj_eng_pca[:, 1], alpha=0.6, label='English (Projected)')\n",
    "    plt.scatter(kor_pca[:, 0], kor_pca[:, 1], alpha=0.6, label='Korean (Target)')\n",
    "    plt.title('ë§¤í•‘ í›„: Projection Headë¥¼ í†µí•œ ê³µê°„ ì •ë ¬')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.suptitle(\"Day 3: ì„ë² ë”© ê³µê°„ ì •ë ¬ ì‹œê°í™” (PCA 2D)\")\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# --- 3. ë©”ì¸ ì‹¤í–‰ ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"--- Day 3: ë¶„ì„ ë° ì‹œê°í™” ì‹œì‘ ---\")\n",
    "    \n",
    "    # 1. Day 2 í•™ìŠµ ê²°ê³¼ ë¡œë“œ\n",
    "    try:\n",
    "        results = np.load(INPUT_FILE, allow_pickle=True)\n",
    "        test_eng_embs = results['test_eng_embs']\n",
    "        test_kor_embs = results['test_kor_embs']\n",
    "        projected_eng_embs = results['projected_eng_embs']\n",
    "        baseline_scores = results['baseline_scores']\n",
    "        aligned_scores = results['aligned_scores']\n",
    "        eng_sents = results['test_eng_sents']\n",
    "        kor_sents = results['test_kor_sents']\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ì˜¤ë¥˜: {INPUT_FILE} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Day 2 ì‘ì—…ì„ ë¨¼ì € ì‹¤í–‰í•˜ì‹­ì‹œì˜¤.\")\n",
    "        exit()\n",
    "\n",
    "    # 2. ì •ì„± ë¶„ì„ ì‹¤í–‰ (ì˜¤ì „)\n",
    "    perform_nuance_analysis(eng_sents, kor_sents, baseline_scores, aligned_scores, top_k=5)\n",
    "    \n",
    "    # 3. ì‹œê°í™” ì‹¤í–‰ (ì˜¤í›„)\n",
    "    visualize_embeddings(test_eng_embs, test_kor_embs, projected_eng_embs)\n",
    "    \n",
    "    print(\"--- Day 3 ì‘ì—… ì™„ë£Œ. ë¯¸ë‹ˆ í”„ë¡œì íŠ¸ ë³´ê³ ì„œ í†µí•© ì¤€ë¹„ ì™„ë£Œ ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68e4d945",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kobert'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkobert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_pytorch_kobert_model\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgluonnlp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentencepieceTokenizer\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kobert'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from kobert import get_pytorch_kobert_model\n",
    "from gluonnlp.data import SentencepieceTokenizer\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# -----------------------------\n",
    "# 1. ëª¨ë¸ êµ¬ì¡° ì •ì˜\n",
    "# -----------------------------\n",
    "class KoSentenceBERT(nn.Module):\n",
    "    def __init__(self, model, vocab):\n",
    "        super(KoSentenceBERT, self).__init__()\n",
    "        self.kobert = model\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        sequence_output, pooled_output = self.kobert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        # Mean Pooling\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(sequence_output.size()).float()\n",
    "        sum_embeddings = torch.sum(sequence_output * input_mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        return sum_embeddings / sum_mask\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2. KoSentenceBERT ë¡œë“œ í•¨ìˆ˜\n",
    "# -----------------------------\n",
    "def load_kosentbert(model_dir=\"./KoSentenceBERT-SKT\", device=\"cpu\"):\n",
    "\n",
    "    # 2-1. KoBERT ëª¨ë¸ ë¡œë“œ\n",
    "    kobert_model, vocab = get_pytorch_kobert_model()\n",
    "\n",
    "    # 2-2. SentencePiece í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "    sp_path = os.path.join(model_dir, \"tokenizer_78b3253a26.model\")\n",
    "    tokenizer = SentencepieceTokenizer(sp_path)\n",
    "\n",
    "    # 2-3. KSBERT êµ¬ì¡° ìƒì„±\n",
    "    model = KoSentenceBERT(kobert_model, vocab)\n",
    "    model.to(device)\n",
    "\n",
    "    # 2-4. í•™ìŠµëœ KoSentenceBERT-SKT ê°€ì¤‘ì¹˜ ë¡œë“œ\n",
    "    ckpt_path = os.path.join(model_dir, \"KSBERT_SKT_NLI_STS.pth\")\n",
    "    state_dict = torch.load(ckpt_path, map_location=device)\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    print(\"âœ” KoSentenceBERT-SKT loaded successfully!\")\n",
    "    return model, tokenizer, vocab\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3. ë¬¸ì¥ â†’ ì„ë² ë”©\n",
    "# -----------------------------\n",
    "def get_embeddings(model, tokenizer, vocab, sentences, device=\"cpu\"):\n",
    "\n",
    "    embeddings = []\n",
    "\n",
    "    for sent in tqdm(sentences, desc=\"Encoding\"):\n",
    "        # í† í°í™”\n",
    "        tokens = tokenizer(sent)\n",
    "        tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
    "\n",
    "        # ID ë³€í™˜\n",
    "        input_ids = torch.tensor([vocab[t] for t in tokens]).unsqueeze(0).to(device)\n",
    "        attention_mask = torch.ones_like(input_ids).to(device)\n",
    "        token_type_ids = torch.zeros_like(input_ids).to(device)\n",
    "\n",
    "        # ì„ë² ë”© ì¶”ì¶œ\n",
    "        with torch.no_grad():\n",
    "            emb = model(input_ids, attention_mask, token_type_ids)\n",
    "            embeddings.append(emb.cpu().numpy()[0])\n",
    "\n",
    "    return np.array(embeddings)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 4. í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    model, tokenizer, vocab = load_kosentbert(\"./KoSentenceBERT-SKT\", device)\n",
    "\n",
    "    test_sentences = [\n",
    "        \"ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì°¸ ì¢‹ë„¤ìš”.\",\n",
    "        \"ë°¥ì„ ë¨¹ê³  ì‚°ì±…ì„ í–ˆìŠµë‹ˆë‹¤.\"\n",
    "    ]\n",
    "\n",
    "    embs = get_embeddings(model, tokenizer, vocab, test_sentences, device)\n",
    "    print(\"\\nFinal Embeddings Shape:\", embs.shape)\n",
    "    print(embs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
